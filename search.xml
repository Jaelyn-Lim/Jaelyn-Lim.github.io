<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Mac 下制作 Ubuntu 启动盘]]></title>
    <url>%2F2018%2F07%2F05%2Fcreate-ubuntu-u%2F</url>
    <content type="text"><![CDATA[在 Mac 下使用 dd 命令制作 Ubuntu 系统的启动盘。 Mac OS制作Ubuntu安装U盘 在 Mac 下安装软件，主要采用的是 dd 命令，但是在那之前还是需要进行一些操作。 hdiutil12cd Downloads/hdiutil convert -format UDRW -o ubuntu.iso ubuntu-14.04.5-desktop-amd64.iso 首先，进入下载好的iOS镜像下的目录使用 hdiutil 命令1hdiutil convert -format UDRW -o ubuntu.iso ubuntu-14.04.5-desktop-amd64.iso 其中 ubuntu.iso 表示生成之后的文件名称，ubuntu-14.04.5-desktop-amd64.iso 表示的是原来的镜像名称。 这命令是在 Mac 上对镜像文件进行制作，验证和转换等工作的命令。-format 为生成文件的权限，UDRW :表示转换成有read/write的权限的镜像。 diskutil第二步需要需要对U盘进行操作，而diskutil就是用来对Mac OS的磁盘操作的命令。diskutil: 操作本地磁盘，可以对磁盘进行卸载，挂载等操作。列出当前挂载的磁盘: 1diskutil list 其中找到自己的u盘。 1234567891011121314151617dev/disk0 (internal, physical): #: TYPE NAME SIZE IDENTIFIER 0: GUID_partition_scheme *251.0 GB disk0 1: EFI EFI 209.7 MB disk0s1 2: Apple_CoreStorage Macintosh HD 250.1 GB disk0s2 3: Apple_Boot Recovery HD 650.0 MB disk0s3/dev/disk1 (internal, virtual): #: TYPE NAME SIZE IDENTIFIER 0: Apple_HFS Macintosh HD +249.8 GB disk1 Logical Volume on disk0s2 45CD1187-14DE-4203-9895-FBB1B3770F1E Unencrypted/dev/disk2 (external, physical): #: TYPE NAME SIZE IDENTIFIER 0: Apple_partition_scheme *8.1 GB disk2 1: Apple_partition_map 4.1 KB disk2s1 2: Apple_HFS 2.4 MB disk2s2 一般来说，如果电脑只插了一个u盘的话，最后一个就是那个锁需要的u盘，而且如果u盘设置了名称的话，在信息中也是会显示出来的，如果不确定的话，将u盘名称换一下，就能看出来了。 由图看的话，其中/dev/disk2就是U盘。需要先卸载掉U盘，然后在把安装文件写入到U盘中，这样就需要用到卸载命令： 1diskutil unmountDisk /dev/disk2 dddd: 是Unix和类Unix系统上的命令，作用就是用指定大小的块拷贝一个文件，并在拷贝的同时进行指定的转换。 在进行拷贝之前，还需要做的一件时间,因为使用hdiutil转换的文件后缀名为.dmg,所以需要把文件重命名为.iso，在安装的时候系统才能够更好的识别。 1mv ubuntu.iso.dmg ubuntu.iso 之后就可以执行了 1sudo dd if=./ubuntu.iso of=/dev/rdisk2 bs=1m 这行命令必须使用root权限， if: 输入的文件名 of: 输出的文件名 bs: 是块大小，这里使用1m的块大小。 之后需要等待比较久的时间。 直到等到控制台输出下面相似的信息后才完成。 1231052+1 records in1052+1 records out1104052224 bytes transferred in 249.471583 secs (4425563 bytes/sec) 这个时候就会弹出一个框框说明u盘不能识别，是否要退出之类的提示，就直接弹出就行了。 也可使用命令弹出u盘。 1sudo eject /dev/rdisk2 这个时候，Ubuntu的启动盘就制作完了。 最后u盘如果这样安装的话，可能会无法正常使用，这个时候就可以直接用 Mac 自带的磁盘管理软件，直接抹掉。 有时候不能直接抹掉，会出现一些报错和问题出现，这个时候就要用dd命令去销毁u盘数据，其实就是重复写一些无序的数据在u盘，进行不停的覆盖。 1sudo dd if=/dev/urandom of=/dev/rdisk2 表示使用随机数填充U盘，这个命令执行几分钟就行，就手动停止，之后在进行磁盘的格式化就能成功了。]]></content>
      <categories>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>Mac</tag>
        <tag>ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac 下的 PyCharm 快捷键]]></title>
    <url>%2F2018%2F06%2F05%2Fmac-pycharm-quick-click%2F</url>
    <content type="text"><![CDATA[记录快捷键，方便自己查看。 参考 Mac 下Pycharm快捷键 Pycharm快捷键整理(Mac) Mac 下 Pycharm快捷键 Mac上IDEA的常用快捷键 Mac键盘符号和修饰键说明 ⌘ Command ⇧ Shift ⌥ Option ⌃ Control ↩︎ Return/Enter ⌫ Delete ⌦ 向前删除键（Fn+Delete） ↑ 上箭头 ↓ 下箭头 ← 左箭头 → 右箭头 ⇞ Page Up（Fn+↑） ⇟ Page Down（Fn+↓） Home Fn + ← End Fn + → ⇥ 右制表符（Tab键） ⇤ 左制表符（Shift+Tab） ⎋ Escape (Esc) Editing（编辑） ⌃Space 基本的代码补全（补全任何类、方法、变量） ⌃⇧Space 智能代码补全（过滤器方法列表和变量的预期类型） ⌘⇧↩ 自动结束代码，行末自动添加分号 ⌘P 显示方法的参数信息 ⌃J, Mid. button click 快速查看文档 ⇧F1 查看外部文档（在某些代码上会触发打开浏览器显示相关文档） ⌘+鼠标放在代码上 显示代码简要信息 ⌘F1 在错误或警告处显示具体描述信息 ⌘N, ⌃↩, ⌃N 生成代码（getter、setter、构造函数、hashCode/equals,toString） ⌃O 覆盖方法（重写父类方法） ⌃I 实现方法（实现接口中的方法） ⌘⌥T 包围代码（使用if..else, try..catch, for, synchronized等包围选中的代码） ⌘/ 注释/取消注释与行注释 ⌘⌥/ 注释/取消注释与块注释 ⌥↑ 连续选中代码块 ⌥↓ 减少当前选中的代码块 ⌃⇧Q 显示上下文信息 ⌥↩ 显示意向动作和快速修复代码 ⌘⌥L 格式化代码 ⌃⌥O 优化import ⌃⌥I 自动缩进线 ⇥ / ⇧⇥ 缩进代码 / 反缩进代码 ⌘X 剪切当前行或选定的块到剪贴板 ⌘C 复制当前行或选定的块到剪贴板 ⌘V 从剪贴板粘贴 ⌘⇧V 从最近的缓冲区粘贴 ⌘D 复制当前行或选定的块 ⌘⌫ 删除当前行或选定的块的行 ⌃⇧J 智能的将代码拼接成一行 ⌘↩ 智能的拆分拼接的行 ⇧↩ 开始新的一行 ⌘⇧U 大小写切换 ⌘⇧] / ⌘⇧[ 选择直到代码块结束/开始 ⌥⌦ 删除到单词的末尾（⌦键为Fn+Delete） ⌥⌫ 删除到单词的开头 ⌘+ / ⌘- 展开 / 折叠代码块 ⌘⇧+ 展开所以代码块 ⌘⇧- 折叠所有代码块 ⌘W 关闭活动的编辑器选项卡 Search/Replace（查询/替换） Double ⇧ 查询任何东西 ⌘F 文件内查找 ⌘G 查找模式下，向下查找 ⌘⇧G 查找模式下，向上查找 ⌘R 文件内替换 ⌘⇧F 全局查找（根据路径） ⌘⇧R 全局替换（根据路径） ⌘⇧S 查询结构（Ultimate Edition 版专用，需要在Keymap中设置） ⌘⇧M 替换结构（Ultimate Edition 版专用，需要在Keymap中设置） Usage Search（使用查询） ⌥F7 / ⌘F7 在文件中查找用法 / 在类中查找用法 ⌘⇧F7 在文件中突出显示的用法 ⌘⌥F7 显示用法 Compile and Run（编译和运行） ⌘F9 编译Project ⌘⇧F9 编译选择的文件、包或模块 ⌃⌥R 弹出 Run 的可选择菜单 ⌃⌥D 弹出 Debug 的可选择菜单 ⌃R 运行 ⌃D 调试 ⌃⇧R, ⌃⇧D 从编辑器运行上下文环境配置 Debugging（调试） F8 进入下一步，如果当前行断点是一个方法，则不进入当前方法体内 F7 进入下一步，如果当前行断点是一个方法，则进入当前方法体内，如果该方法体还有方法，则不会进入该内嵌的方法中 ⇧F7 智能步入，断点所在行上有多个方法调用，会弹出进入哪个方法 ⇧F8 跳出 ⌥F9 运行到光标处，如果光标前有其他断点会进入到该断点 ⌥F8 计算表达式（可以更改变量值使其生效） ⌘⌥R 恢复程序运行，如果该断点下面代码还有断点则停在下一个断点上 ⌘F8 切换断点（若光标当前行有断点则取消断点，没有则加上断点） ⌘⇧F8 查看断点信息 Navigation（导航） ⌘O 查找类文件 ⌘⇧O 查找所有类型文件、打开文件、打开目录，打开目录需要在输入的内容前面或后面加一个反斜杠/ ⌘⌥O 前往指定的变量 / 方法 ⌃← / ⌃→ 左右切换打开的编辑tab页 F12 返回到前一个工具窗口 ⎋ 从工具窗口进入代码文件窗口 ⇧⎋ 隐藏当前或最后一个活动的窗口，且光标进入代码文件窗口 ⌘⇧F4 关闭活动run/messages/find/… tab ⌘L 在当前文件跳转到某一行的指定处 ⌘E 显示最近打开的文件记录列表 ⌘⌥← / ⌘⌥→ 退回 / 前进到上一个操作的地方 ⌘⇧⌫ 跳转到最后一个编辑的地方 ⌥F1 显示当前文件选择目标弹出层，弹出层中有很多目标可以进行选择(如在代码编辑窗口可以选择显示该文件的Finder) ⌘B / ⌘ 鼠标点击 进入光标所在的方法/变量的接口或是定义处 ⌘⌥B 跳转到实现处，在某个调用的方法名上使用会跳到具体的实现处，可以跳过接口 ⌥ Space, ⌘Y 快速打开光标所在方法、类的定义 ⌃⇧B 跳转到类型声明处 ⌘U 前往当前光标所在方法的父类的方法 / 接口定义 ⌃↓ / ⌃↑ 当前光标跳转到当前文件的前一个/后一个方法名位置 ⌘] / ⌘[ 移动光标到当前所在代码的花括号开始/结束位置 ⌘F12 弹出当前文件结构层，可以在弹出的层上直接输入进行筛选（可用于搜索类中的方法） ⌃H 显示当前类的层次结构 ⌘⇧H 显示方法层次结构 ⌃⌥H 显示调用层次结构 F2 / ⇧F2 跳转到下一个/上一个突出错误或警告的位置 F4 / ⌘↓ 编辑/查看代码源 ⌥ Home 显示到当前文件的导航条 F3选中文件/文件夹/代码行，添加/取消书签 ⌥F3 选中文件/文件夹/代码行，使用助记符添加/取消书签 ⌃0...⌃9 定位到对应数值的书签位置 ⌘F3 显示所有书签 Refactoring（重构） F5 复制文件到指定目录 F6 移动文件到指定目录 ⌘⌫ 在文件上为安全删除文件，弹出确认框 ⇧F6 重命名文件 ⌘F6 更改签名 ⌘⌥N 一致性 ⌘⌥M 将选中的代码提取为方法 ⌘⌥V 提取变量 ⌘⌥F 提取字段 ⌘⌥C 提取常量 ⌘⌥P 提取参数 VCS/Local History（版本控制/本地历史记录） ⌘K 提交代码到版本控制器 ⌘T 从版本控制器更新代码 ⌥⇧C 查看最近的变更记录 ⌃C 快速弹出版本控制器操作面板 Live Templates（动态代码模板） ⌘⌥J 弹出模板选择窗口，将选定的代码使用动态模板包住 ⌘J 插入自定义动态代码模板 General（通用） ⌘1...⌘9 打开相应编号的工具窗口 ⌘S 保存所有 ⌘⌥Y 同步、刷新 ⌃⌘F 切换全屏模式 ⌘⇧F12 切换最大化编辑器 ⌥⇧F 添加到收藏夹 ⌥⇧I 检查当前文件与当前的配置文件 `§⌃, ⌃“ 快速切换当前的scheme（切换主题、代码样式等） ⌘, 打开IDEA系统设置 ⌘; 打开项目结构对话框 ⇧⌘A 查找动作（可设置相关选项） ⌃⇥ 编辑窗口标签和工具窗口之间切换（如果在切换的过程加按上delete，则是关闭对应选中的窗口） Other（一些官方文档上没有体现的快捷键） ⌘⇧8 竖编辑模式 导航 ⌘O 查找类文件 Ctrl + N ⌘⌥O 前往指定的变量 / 方法 Ctrl + Shift + Alt + N ⌃← / ⌃→ 左右切换打开的编辑tab页Alt←/Alt→ ⎋ 从工具窗口进入代码文件窗口 ESC ⌘L 在当前文件跳转到某一行的指定处 Ctrl + G ⌘E 显示最近打开的文件记录列表 Ctrl + E ⌘⌥←/ ⌘⌥→退回 / 前进到上一个操作的地方 Ctrl + Alt + ←/Ctrl + Alt + → ⌘⇧⌫ 跳转到最后一个编辑的地方 ⌃H 显示当前类的层次结构Ctrl + H ⌘⇧H 显示方法层次结构 ⌃⌥H 显示调用层次结构 F4 /⌘↓ 编辑/查看代码源 ⌘⌥U 显示类UML图 ⌃J 查看注释 编辑 ⌥⌦ 删除到单词的末尾（⌦键为Fn+Delete） ⌥⌫ 删除到单词的开头 ⌘+ /⌘- 展开 / 折叠代码块 ⌘F1 在错误或警告处显示具体描述信息 ⌘⌥L 格式化代码 ⌃⌥O 优化import ⇧↩ 开始新的一行 ⌘⇧↩ 自动结束代码，行末自动添加分号 ⌃I 实现方法（实现接口中的方法） ⇧F6 重命名文件或者变量 ⌘N,⌃↩,⌃N 生成代码（getter、setter、构造函数、hashCode/equals,toString） ⌘P 显示方法的参数信息 查找 Double⇧ 查找任何东西 ⌘⇧F 全局查找（根据路径） ⌘F 文件内查找 ⌘G 查找模式下，向下查找 ⌘⇧G 查找模式下，向上查找 导航 ⌘⌥B 跳转到接口的实现 ⌘U 查看接口定义 ⌘⌥← /⌘⌥→ 退回 / 前进到上一个操作的地方 ⌘B /⌘ 鼠标点击 进入光标所在的方法/变量的接口或是定义处 ⌃⇧B 跳转到类型声明处 ⌥ Space,⌘Y 快速打开光标所在方法、类的定义 ⌘O 查找类文件 ⌘⇧O 查找所有类型文件、打开文件、打开目录，打开目录需要在输入的内容前面或后面加一个反斜杠/ F12 返回到前一个工具窗口 ⎋ 从工具窗口进入代码文件窗口 ⇧⎋ 隐藏当前或最后一个活动的窗口，且光标进入代码文件窗口 F3选中文件/文件夹/代码行，添加/取消书签 ⌥F3 选中文件/文件夹/代码行，使用助记符添加/取消书签 ⌃0…⌃9 定位到对应数值的书签位置 ⌘F3 显示所有书签 ⌥F1 显示当前文件选择目标弹出层，弹出层中有很多目标可以进行选择(如在代码编辑窗口可以选择显示该文件的Finder) ⌘F12 弹出当前文件结构层，可以在弹出的层上直接输入进行筛选（可用于搜索类中的方法） 通用 ⌃⌘F 切换全屏模式 自动代码⚠注：⌘+J可以调出所有提供的代码补全↩即可]]></content>
      <categories>
        <category>pycharm</category>
      </categories>
      <tags>
        <tag>Mac</tag>
        <tag>python</tag>
        <tag>pycharm</tag>
        <tag>快捷键</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python Cookbook 笔记]]></title>
    <url>%2F2018%2F05%2F29%2Fpython-cookbook-learning%2F</url>
    <content type="text"><![CDATA[《Python CookBook 3》 这个文章是在我学习这本书过程的笔记（复制粘贴），主要用于自己方便查看。还有记录了我的觉得比较有用（没学过）的操作。 数据结构和算法星号（*）表达式 解压可迭代对象赋值给多个变量 可以使用 * （星号表达式）来匹配不确定数量的数据。 1234567def drop_first_last(grades): first, *middle, last = grades print(middle) # 输出： [3, 4, 5] return middleif __name__ == '__main__': drop_first_last([12,3,4,5,6]) 带有星号的变量永远都是列表类型，包括长度是0的空列表，所以用到该变量的代码就不需要做多余的类型检查去确认它是否是列表类型。 扩展的迭代解压语法是专门为解压不确定个数或任意个数元素的可迭代对象而设计的。 通常，这些可迭代对象的元素结构有确定的规则（比如第 1 个元素后面都是电话号码）， 星号表达式让开发人员可以很容易的利用这些规则来解压出元素来。 而不是通过一些比较复杂的手段去获取这些关联的元素值。 星号表达式能做很多事情，包括对字符串的处理，对可变长数组，元组的处理。 xrange在Python 3中，range()与xrange()合并为range( )。 如果直接使用 range ，会直接占用内存的空间，例如如果要加载一个很大的文件，就有可能会照成内存的爆满。这时候可以使用 xrange 在代替，这个返回的是一个生成器，而不是数列，每次只会返回其中的一个值。 yield Python yield 使用浅析 123456789101112131415from inspect import isgeneratorfunctiondef fab(max): n, a, b = 0, 0, 1 print("++++++++++") while n &lt; max: yield b print("12312312---"+str(b)) a, b = b, a+b n = n+1if __name__ == '__main__': print(isgeneratorfunction(fab)) for n in fab(5): print(n) 输出： 123456789101112True++++++++++112312312---1112312312---1212312312---2312312312---3512312312---5 一个带有 yield 的函数就是一个 generator，它和普通函数不同，生成一个 generator 看起来像函数调用，但不会执行任何函数代码，直到对其调用 next()（在 for 循环中会自动调用 next()）才开始执行。虽然执行流程仍按函数的流程执行，但每执行到一个 yield 语句就会中断，并返回一个迭代值，下次执行时从 yield 的下一个语句继续执行。看起来就好像一个函数在正常执行的过程中被 yield 中断了数次，每次中断都会通过 yield 返回当前的迭代值。 其中，可以使用 isgeneratorfunction 来判断函数是否是一个特殊的 generator 函数。 其中 yield 的例子来源于文件读取。如果直接对文件对象调用 read() 方法，会导致不可预测的内存占用。好的方法是利用固定长度的缓冲区来不断读取文件内容。通过 yield，我们不再需要编写读文件的迭代类，就可以轻松实现文件读取： 123456789def read_file(fpath): BLOCK_SIZE = 1024 with open(fpath, 'rb') as f: while True: block = f.read(BLOCK_SIZE) if block: yield block else: return collections.deque 保留最后 N 个元素 使用 deque(maxlen=N) 构造函数会新建一个固定大小的队列。当新的元素加入并且这个队列已满的时候， 最老的元素会自动被移除掉。 1234567891011from collections import dequelines = deque(maxlen=3) lines.append("1") lines.append("2") lines.append("3") lines.append("4") lines.append("5") print(lines)# 输出： deque(['3', '4', '5'], maxlen=3) 还可以在队列的两端插入和弹出元素，（左边插入：q.appendleft；左边弹出：q.popleft） 在队列两端插入或删除元素时间复杂度都是 O(1) ，区别于列表，在列表的开头插入或删除元素的时间复杂度为 O(N) 。 heapq 查找最大或最小的 N 个元素 123456789import heapqnums = [1,2,34,5,43,523,423,423,4,234,24,1,3,1,3,53,5654,6,4356,12]print(heapq.nlargest(3, nums))print(heapq.nsmallest(2, nums))# 输出：# [5654, 4356, 523]# [1, 1] 还可以接受一个关键字参数，来进行更高级的对比：12345678910111213141516portfolio = [ &#123;'name': 'IBM', 'shares': 100, 'price': 91.1&#125;, &#123;'name': 'AAPL', 'shares': 50, 'price': 543.22&#125;, &#123;'name': 'FB', 'shares': 200, 'price': 21.09&#125;, &#123;'name': 'HPQ', 'shares': 35, 'price': 31.75&#125;, &#123;'name': 'YHOO', 'shares': 45, 'price': 16.35&#125;, &#123;'name': 'ACME', 'shares': 75, 'price': 115.65&#125;]cheap = heapq.nsmallest(3, portfolio, key=lambda s: s['price'])expensive = heapq.nlargest(3, portfolio, key=lambda s: s['price'])print(cheap)print(expensive)输出：[&#123;'name': 'YHOO', 'shares': 45, 'price': 16.35&#125;, &#123;'name': 'FB', 'shares': 200, 'price': 21.09&#125;, &#123;'name': 'HPQ', 'shares': 35, 'price': 31.75&#125;][&#123;'name': 'AAPL', 'shares': 50, 'price': 543.22&#125;, &#123;'name': 'ACME', 'shares': 75, 'price': 115.65&#125;, &#123;'name': 'IBM', 'shares': 100, 'price': 91.1&#125;] 堆数据结构最重要的特征是 heap[0] 永远是最小的元素。并且剩余的元素可以很容易的通过调用 heapq.heappop() 方法得到， 该方法会先将第一个元素弹出来，然后用下一个最小的元素来取代被弹出元素（这种操作时间复杂度仅仅是 O(log N)，N 是堆大小）。 123456&gt;&gt;&gt; nums = [1, 8, 2, 23, 7, -4, 18, 23, 42, 37, 2]&gt;&gt;&gt; import heapq&gt;&gt;&gt; heap = list(nums)&gt;&gt;&gt; heapq.heapify(heap)&gt;&gt;&gt; heap[-4, 2, 1, 23, 7, 2, 18, 23, 42, 37, 8] 如果只是获取一个最大值（最小值），使用 max()（min()）函数会快一些。 collections.defaultdict 字典中的键映射多个值 defaultdict 的一个特征是它会自动初始化每个 key 刚开始对应的值，所以你只需要关注添加元素操作了。 12345678910from collections import defaultdictd = defaultdict(list)d['a'].append(1)d['a'].append(2)d['b'].append(4)print(d)# 输出： defaultdict(&lt;class 'list'&gt;, &#123;'a': [1, 2], 'b': [4]&#125;) 12345678910from collections import defaultdictd = defaultdict(set)d['a'].add(1)d['a'].add(2)d['b'].add(4)print(d)# 输出： defaultdict(&lt;class 'set'&gt;, &#123;'a': &#123;1, 2&#125;, 'b': &#123;4&#125;&#125;) defaultdict 会自动为将要访问的键（就算目前字典中并不存在这样的键）创建映射实体。 collections.OrderedDict 字典排序 创建一个字典，并且在迭代或序列化这个字典的时候能够控制元素的顺序。 1234567891011121314from collections import OrderedDictimport jsond = OrderedDict()d['foo'] = 1d['bar'] = 2d['spam'] = 3d['grok'] = 4d['foo'] = 12# Outputs "foo 1", "bar 2", "spam 3", "grok 4"for key in d: print(key, d[key])j = json.dumps(d)print(j) 输出： 12345foo 12bar 2spam 3grok 4&#123;&quot;foo&quot;: 12, &quot;bar&quot;: 2, &quot;spam&quot;: 3, &quot;grok&quot;: 4&#125; OrderedDict 内部维护着一个根据键插入顺序排序的双向链表。每次当一个新的元素插入进来的时候， 它会被放到链表的尾部。对于一个已经存在的键的重复赋值不会改变键的顺序。 需要注意的是，一个 OrderedDict 的大小是一个普通字典的两倍，因为它内部维护着另外一个链表。 zip 字典的运算 对字典值执行计算操作，通常需要使用 zip() 函数先将键和值反转过来。 123456789101112131415prices = &#123; 'ACME': 45.23, 'AAPL': 612.78, 'IBM': 205.55, 'HPQ': 37.20, 'FB': 10.75&#125;min_price = min(zip(prices.values(), prices.keys()))print(min_price)max_price = max(zip(prices.values(), prices.keys()))print(max_price)prices_sort = sorted(zip(prices.values(), prices.keys()))print(prices_sort) 输出： 123(10.75, &apos;FB&apos;)(612.78, &apos;AAPL&apos;)[(10.75, &apos;FB&apos;), (37.2, &apos;HPQ&apos;), (45.23, &apos;ACME&apos;), (205.55, &apos;IBM&apos;), (612.78, &apos;AAPL&apos;)] 在使用zip()的时候，在使用zip()给一个变量赋值的时候，就不能再次使用该变量做其他操作，例如：a = zip(prices.values(), prices.keys())，之后调用max(a)，后面如果再次调用min(a)的话就会报错。# ValueError: max() arg is an empty sequence keys and values 查找两字典的相同点 一个字典就是一个键集合与值集合的映射关系。 字典的 keys() 方法返回一个展现键集合的键视图对象。 键视图的一个很少被了解的特性就是它们也支持集合操作，比如集合并、交、差运算。 所以，如果你想对集合的键执行一些普通的集合操作，可以直接使用键视图对象而不用先将它们转换成一个 set。 123456789101112131415161718192021a = &#123; 'x': 1, 'y': 2, 'z': 3&#125;b = &#123; 'w': 10, 'x': 11, 'y': 2&#125;print(a.keys() &amp; b.keys())# &#123;'x', 'y'&#125; 在a字典和b字典中相同的keyprint(a.keys() - b.keys())# &#123;'z'&#125; 在a字典中有的在b字典中没有的keyprint(a.items() &amp; b.items())# &#123;('y', 2)&#125; 在a字典和在b字典中相同的健值对c = &#123;key: a[key] for key in a.keys() - &#123;'z'&#125;&#125;print(c)# &#123;'x': 1, 'y': 2&#125; 字典的 items() 方法返回一个包含 (键，值) 对的元素视图对象。 这个对象同样也支持集合操作，并且可以被用来查找两个字典有哪些相同的键值对。 尽管字典的 values() 方法也是类似，但是它并不支持这里介绍的集合操作。 collections.Counter 序列中出现次数最多的元素 Counter 对象可以接受任意的由可哈希（hashable）元素构成的序列对象。 1234567891011121314from collections import Counterwords = [ 'look', 'into', 'my', 'eyes', 'look', 'into', 'my', 'eyes', 'the', 'eyes', 'the', 'eyes', 'the', 'eyes', 'not', 'around', 'the', 'eyes', "don't", 'look', 'around', 'the', 'eyes', 'look', 'into', 'my', 'eyes', "you're", 'under']word_counts = Counter(words)# 计算列表中出现频率最多的三个单词top_three = word_counts.most_common(3)print(top_three)# [('eyes', 8), ('the', 5), ('look', 4)] 同样的，也可增加新的列表来跟新新的列表中的元素的个数。 123morewords = ['why','are','you','not','looking','in','my','eyes']word_counts.update(morewords)print(word_counts.most_common(3)) 并且，Counter这个类也可以和数学运算符操作相结合。 123456789a = Counter(words)b = Counter(morewords)c = a + bprint(c)# Counter(&#123;'eyes': 9, 'the': 5, 'look': 4, 'my': 4, 'into': 3, 'not': 2, 'around': 2, "don't": 1, "you're": 1, 'under': 1, 'why': 1, 'are': 1, 'you': 1, 'looking': 1, 'in': 1&#125;)c = a - bprint(c)# Counter(&#123;'eyes': 7, 'the': 5, 'look': 4, 'into': 3, 'my': 2, 'around': 2, "don't": 1, "you're": 1, 'under': 1&#125;) operator.itemgetter 通过某个关键字排序一个字典列表 可以利用itemgetter的模块对列表中以某个字段来排序。 123456789101112131415161718192021from operator import itemgetterrows = [ &#123;'fname': 'Brian', 'lname': 'Jones', 'uid': 1003&#125;, &#123;'fname': 'David', 'lname': 'Beazley', 'uid': 1002&#125;, &#123;'fname': 'John', 'lname': 'Cleese', 'uid': 1001&#125;, &#123;'fname': 'Big', 'lname': 'Jones', 'uid': 1004&#125;]rows_by_fname = sorted(rows, key=itemgetter('fname'))rows_by_uid = sorted(rows, key=itemgetter('uid'))print(rows_by_fname)# [&#123;'fname': 'Big', 'lname': 'Jones', 'uid': 1004&#125;,# &#123;'fname': 'Brian', 'lname': 'Jones', 'uid': 1003&#125;,# &#123;'fname': 'David', 'lname': 'Beazley', 'uid': 1002&#125;,# &#123;'fname': 'John', 'lname': 'Cleese', 'uid': 1001&#125;]print(rows_by_uid)# [&#123;'fname': 'John', 'lname': 'Cleese', 'uid': 1001&#125;,# &#123;'fname': 'David', 'lname': 'Beazley', 'uid': 1002&#125;,# &#123;'fname': 'Brian', 'lname': 'Jones', 'uid': 1003&#125;,# &#123;'fname': 'Big', 'lname': 'Jones', 'uid': 1004&#125;] 同样，也能存在多个key 123456rows_by_lfname = sorted(rows, key=itemgetter('lname','fname'))print(rows_by_lfname)# [&#123;'fname': 'David', 'lname': 'Beazley', 'uid': 1002&#125;,# &#123;'fname': 'John', 'lname': 'Cleese', 'uid': 1001&#125;,# &#123;'fname': 'Big', 'lname': 'Jones', 'uid': 1004&#125;,# &#123;'fname': 'Brian', 'lname': 'Jones', 'uid': 1003&#125;] rows 被传递给接受一个关键字参数的 sorted() 内置函数。 这个参数是 callable 类型，并且从 rows 中接受一个单一元素，然后返回被用来排序的值。 itemgetter() 函数就是负责创建这个 callable 对象的。 operator.itemgetter() 函数有一个被 rows 中的记录用来查找值的索引参数。可以是一个字典键名称， 一个整形值或者任何能够传入一个对象的 __getitem__() 方法的值。 如果你传入多个索引参数给 itemgetter() ，它生成的 callable 对象会返回一个包含所有元素值的元组， 并且 sorted() 函数会根据这个元组中元素顺序去排序。 但你想要同时在几个字段上面进行排序（比如通过姓和名来排序，也就是例子中的那样）的时候这种方法是很有用的。 该模块也同样适用于 min() 和 max() 等函数。min(rows, key=itemgetter(&#39;uid&#39;)) 或者 max(rows, key=itemgetter(&#39;uid&#39;)) operator.attrgetter 排序不支持原生比较的对象 1234567891011121314151617181920from operator import attrgetterclass User: def __init__(self, user_id): self.user_id = user_id def __repr__(self): return 'User(&#123;&#125;)'.format(self.user_id)users = [User(34), User(23), User(12)]print(users)# [User(34), User(23), User(12)]print(sorted(users, key=lambda u: u.user_id))# [User(12), User(23), User(34)]s = sorted(users, key=attrgetter('user_id'))print(s)# [User(12), User(23), User(34)] 可以直接使用lambda表达式的计算来代替attrgetter，但是如果更加在意速度的话，attrgetter() 函数通常会运行的快点，并且还能同时允许多个字段进行比较。 这个跟 operator.itemgetter() 函数作用于字典类型很类似。也同样支持min和max的操作。 itertools.groupby 通过某个字段将记录分组 groupby() 函数扫描整个序列并且查找连续相同值（或者根据指定 key 函数返回值相同）的元素序列。 在每次迭代的时候，它会返回一个值和一个迭代器对象， 这个迭代器对象可以生成元素值全部等于上面那个值的组中所有对象。 一个非常重要的准备步骤是要根据指定的字段将数据排序。 因为 groupby() 仅仅检查连续的元素，如果事先并没有排序完成的话，分组函数将得不到想要的结果。 12345678910111213141516171819from operator import itemgetterfrom itertools import groupbyrows = [ &#123;'address': '5412 N CLARK', 'date': '07/01/2012'&#125;, &#123;'address': '5148 N CLARK', 'date': '07/04/2012'&#125;, &#123;'address': '5800 E 58TH', 'date': '07/02/2012'&#125;, &#123;'address': '2122 N CLARK', 'date': '07/03/2012'&#125;, &#123;'address': '5645 N RAVENSWOOD', 'date': '07/02/2012'&#125;, &#123;'address': '1060 W ADDISON', 'date': '07/02/2012'&#125;, &#123;'address': '4801 N BROADWAY', 'date': '07/01/2012'&#125;, &#123;'address': '1039 W GRANVILLE', 'date': '07/04/2012'&#125;,]rows.sort(key=itemgetter('date'))a = groupby(rows, key=itemgetter('date'))for date, items in a: print(date) for item in items: print(' ', item) 如果需要按照分组来访问，可以使用defaultdict()来构建多值字典。 filter() 过滤序列元素 一般来说，如果我们需要对一个列表遍历，取出其中的某些特定的元素，我们可以使用列表推导。 1234mylist = [1, 4, -5, 10, -7, 2, 3, -1]m = [i for i in mylist if i &gt; 0]print(m)# [1, 4, 10, 2, 3] 使用列表推导的一个潜在缺陷就是如果输入非常大的时候会产生一个非常大的结果集，占用大量内存。 如果对内存比较敏感，可以使用生成器表达式迭代产生过滤的元素。 123456pos = (n for n in mylist if n &gt; 0)print(pos)# &lt;generator object &lt;genexpr&gt; at 0x101fa69e8&gt;for i in pos: print(i, end=' ')# 1 4 10 2 3 如果过滤规则比较复杂，不能简单的在列表推导或者生成器表达式中表达出来。 比如，假设过滤的时候需要处理一些异常或者其他复杂情况。这时候可以将过滤代码放到一个函数中， 然后使用内建的 filter() 函数。 1234567891011121314values = ['1', '2', '-3', '-', '4', 'N/A', '5']def is_int(val): try: x = int(val) return True except ValueError: return Falseivals = list(filter(is_int, values))print(ivals)# ['1', '2', '-3', '4', '5'] filter() 函数创建了一个迭代器，因此如果你想得到一个列表的话，就得像示例那样使用 list() 去转换。 另外一个值得关注的过滤工具就是 itertools.compress() ， 它以一个 iterable 对象和一个相对应的 Boolean 选择器序列作为输入参数。 然后输出 iterable 对象中对应选择器为 True 的元素。 当你需要用另外一个相关联的序列来过滤某个序列的时候，这个函数是非常有用的。 12345678from itertools import compressmore5 = [n &gt; 5 for n in counts]print(more5)# [False, False, True, False, False, True, True, False]more6 = list(compress(addresses, more5))print(more6)# ['5800 E 58TH', '1060 W ADDISON', '4801 N BROADWAY'] 这里的关键点在于先创建一个 Boolean 序列，指示哪些元素符合条件。 然后 compress() 函数根据这个序列去选择输出对应位置为 True 的元素。 和 filter() 函数类似， compress() 也是返回的一个迭代器。因此，如果你需要得到一个列表， 那么你需要使用 list() 来将结果转换为列表类型。 字典推导12345678910111213prices = &#123; 'ACME': 45.23, 'AAPL': 612.78, 'IBM': 205.55, 'HPQ': 37.20, 'FB': 10.75&#125;p1 = &#123;key: value for key, value in prices.items() if value &gt; 200&#125;print(p1)tech_names = &#123;'AAPL', 'IBM', 'HPQ', 'MSFT'&#125;p2 = &#123;key: value for key, value in prices.items() if key in tech_names&#125;print(p2) 大多数情况下字典推导能做到的，通过创建一个元组序列然后把它传给 dict() 函数也能实现。 12p3 = dict((key, value) for key, value in prices.items() if value &gt; 200)print(p3) 字典推导方式表意更清晰，并且实际上也会运行的更快些 collections.namedtuple() 映射名称到序列元素 collections.namedtuple() 函数通过使用一个普通的元组对象来解决这个问题。 这个函数实际上是一个返回 Python 中标准元组类型子类的一个工厂方法。 你需要传递一个类型名和你需要的字段给它，然后它就会返回一个类，你可以初始化这个类，为你定义的字段传递值等。 12345678910from collections import namedtupleSubscriber = namedtuple('Subscriber', ['addr', 'joined'])sub = Subscriber('jonesy@example.com', '2012-10-19')print(sub)# Subscriber(addr='jonesy@example.com', joined='2012-10-19')print(sub.addr)# jonesy@example.comprint(sub.joined)# 2012-10-19 尽管 namedtuple 的实例看起来像一个普通的类实例，但是它跟元组类型是可交换的，支持所有的普通元组操作，比如索引和解压。 12345678s = len(sub)print(s)# 2addr, joined = subprint(addr)# jonesy@example.comprint(joined)# 2012-10-19 因此，如果你从数据库调用中返回了一个很大的元组列表，通过下标去操作其中的元素， 当你在表中添加了新的列的时候你的代码可能就会出错了。但是如果你使用了命名元组，那么就不会有这样的顾虑。 123456789from collections import namedtupleStock = namedtuple('Stock', ['name', 'shares', 'price'])def compute_cost(records): total = 0.0 for rec in records: s = Stock(*rec) total += s.shares * s.price return total 命名元组另一个用途就是作为字典的替代，因为字典存储需要更多的内存空间。 如果你需要构建一个非常大的包含字典的数据结构，那么使用命名元组会更加高效。 但是需要注意的是，不像字典那样，一个命名元组是不可更改的。 如果你真的需要改变属性的值，那么可以使用命名元组实例的 _replace() 方法， 它会创建一个全新的命名元组并将对应的字段用新的值取代。 s = s._replace(shares=75) _replace() 方法还有一个很有用的特性就是当你的命名元组拥有可选或者缺失字段时候， 它是一个非常方便的填充数据的方法。 你可以先创建一个包含缺省值的原型元组，然后使用 _replace() 方法创建新的值被更新过的实例。 12345678910from collections import namedtupleStock = namedtuple('Stock', ['name', 'shares', 'price', 'date', 'time'])# Create a prototype instancestock_prototype = Stock('', 0, 0.0, None, None)# Function to convert a dictionary to a Stockdef dict_to_stock(s): return stock_prototype._replace(**s) 最后要说的是，如果你的目标是定义一个需要更新很多实例属性的高效数据结构，那么命名元组并不是你的最佳选择。 这时候你应该考虑定义一个包含 __slots__ 方法的类 collections.ChainMap 合并多个字典或映射 一个 ChainMap 接受多个字典并将它们在逻辑上变为一个字典。 然后，这些字典并不是真的合并在一起了， ChainMap 类只是在内部创建了一个容纳这些字典的列表 并重新定义了一些常见的字典操作来遍历这个列表。 1234567891011a = &#123;'x': 1, 'z': 3 &#125;b = &#123;'y': 2, 'z': 4 &#125;from collections import ChainMapc = ChainMap(a, b)print(c)# ChainMap(&#123;'x': 1, 'z': 3&#125;, &#123;'y': 2, 'z': 4&#125;)print(c['x']) # 1print(c['z']) # 3print(c['y']) # 2 如果出现重复键，那么第一次出现的映射值会被返回。对于字典的更新或删除操作总是影响的是列表中第一个字典。 123456789101112131415value = ChainMap()value['x'] = 0value = value.new_child()value['x'] = 1value = value.new_child()value['y'] = 2value = value.new_child()value['z'] = 3print(value)# ChainMap(&#123;'z': 3&#125;, &#123;'y': 2&#125;, &#123;'x': 1&#125;, &#123;'x': 0&#125;)value = value.parents# 删除最后加入的字典value = value.parentsprint(value)# ChainMap(&#123;'x': 1&#125;, &#123;'x': 0&#125;) 在原字典中的修改会直接反应到 ChainMap 中。 字符串和文本字符串开头或结尾匹配检查字符串开头或结尾的一个简单方法是使用 str.startswith() 或者是 str.endswith() 方法。 123456789101112131415import osfile_list = os.listdir('.')print(file_list)# ['startandendwith.py', '__init__.py']end_with = [name for name in file_list if name.endswith('.py')]print(end_with)# ['startandendwith.py', '__init__.py']start_with = [name for name in file_list if name.startswith('s')]print(start_with)# ['startandendwith.py']has_end = any(name.endswith('.py') for name in file_list)print(has_end)# Trueprint(any([False, True, False]))# True startswith() 和 endswith() 方法提供了一个非常方便的方式去做字符串开头和结尾的检查。 类似的操作也可以使用切片来实现，但是代码看起来没有那么优雅。 123choices = ['http:', 'ftp:']t = tuple(choices)print(t) tuple() 可以将 list 或者 set 类型的选择项转换为元组类型。 当和其他操作比如普通数据聚合相结合的时候 startswith() 和 endswith() 方法是很不错的。 比如，下面这个语句检查某个文件夹中是否存在指定的文件类型： if any(name.endswith((‘.c’, ‘.h’)) for name in listdir(dirname)): fnmatch() 和 fnmatchcase() 用Shell通配符匹配字符串 123456789101112131415from fnmatch import fnmatch, fnmatchcaseis_fnmatch_1 = fnmatch('foo.txt', '*.txt')print(is_fnmatch_1)# Trueis_fnmatch_2 = fnmatch('foo.txt', '?oo.txt')print(is_fnmatch_2)# Trueis_fnmatch_3 = fnmatch('Dat45.csv', 'Dat[0-9]*')print(is_fnmatch_3)# Truenames = ['Dat1.csv', 'Dat2.csv', 'config.ini', 'foo.py']name_list = [name for name in names if fnmatch(name, 'Dat*.csv')]print(name_list)# ['Dat1.csv', 'Dat2.csv'] fnmatch() 函数使用底层操作系统的大小写敏感规则(不同的系统是不一样的)来匹配模式。 123456&gt;&gt;&gt; # On OS X (Mac)&gt;&gt;&gt; fnmatch('foo.txt', '*.TXT')False&gt;&gt;&gt; # On Windows&gt;&gt;&gt; fnmatch('foo.txt', '*.TXT')True 如果对这个区别很在意，可以使用 fnmatchcase() 来代替。它完全使用所规定的模式大小写匹配。 fnmatch() 函数匹配能力介于简单的字符串方法和强大的正则表达式之间。 如果在数据处理操作中只需要简单的通配符就能完成的时候，这通常是一个比较合理的方案。 re.sub() 字符串搜索和替换 sub() 函数中的第一个参数是被匹配的模式，第二个参数是替换模式。反斜杠数字比如 \3 指向前面模式的捕获组号。 123456import retext = 'Today is 11/27/2012. PyCon starts 3/13/2013.'s = re.sub(r'(\d+)/(\d+)/(\d+)', r'\3-\1-\2', text)print(s)# Today is 2012-11-27. PyCon starts 2013-3-13. 如果打算用相同的模式做多次替换，考虑先编译它来提升性能。 1234datepat = re.compile(r'(\d+)/(\d+)/(\d+)')s2 = datepat.sub(r'\3-\1-\2', text)print(s2)# Today is 2012-11-27. PyCon starts 2013-3-13. 对于更加复杂的替换，可以传递一个替换回调函数来代替。 123456789from calendar import month_abbrdef chane_date(m): mon_name = month_abbr[int(m.group(1))] return '&#123;&#125; &#123;&#125; &#123;&#125;'.format(m.group(2), mon_name, m.group(3))s3 = datepat.sub(chane_date, text)print(s3)# Today is 27 Nov 2012. PyCon starts 13 Mar 2013. 一个替换回调函数的参数是一个 match 对象，也就是 match() 或者 find() 返回的对象。 使用 group() 方法来提取特定的匹配部分。回调函数最后返回替换字符串。 如果除了替换后的结果外，还想知道有多少替换发生了，可以使用 re.subn() 来代替。函数返回一个元组来表示替换后的值和一共替换的数量。 123s4, n = datepat.subn(chane_date, text)print(s4, n)# Today is 27 Nov 2012. PyCon starts 13 Mar 2013. 2 re.IGNORECASE 字符串忽略大小写的搜索替换 以忽略大小写的方式搜索与替换文本字符串 1234text = 'UPPER PYTHON, lower python, Mixed Python'a = re.findall('python', text, flags=re.IGNORECASE)print(a)# ['PYTHON', 'python', 'Python'] sub() 函数除了接受替换字符串外，还能接受一个回调函数。 re.DOTALLre.compile() 函数接受一个标志参数叫 re.DOTALL ，在这里非常有用。 它可以让正则表达式中的点(.)匹配包括换行符在内的任意字符。 12345678import retext2 = '''/* this is a multiline comment */ '''comment = re.compile(r'/\*(.*?)\*/', re.DOTALL)a = comment.findall(text2)print(a)# [' this is a\n multiline comment '] 这样的对于那些需要换行的字符串就能很好的匹配， 同时，适用于那些文件的读取。也可以用re.compile(r&#39;/\*((?:.|\n)*?)\*/&#39;)来代替，也能达到跨行匹配字符串的效果。 unicodedata 将Unicode文本标准化 123456789101112s1 = 'Spicy Jalape\u00f1o'print(s1)# Spicy Jalapeños2 = 'Spicy Jalapen\u0303o'print(s2)# Spicy Jalapeñoprint(s1==s2)# Falseprint(len(s1))# 14print(len(s2))# 15 这里的文本”Spicy Jalapeño”使用了两种形式来表示。 第一种使用整体字符”ñ”(U+00F1)，第二种使用拉丁字母”n”后面跟一个”~”的组合字符(U+0303)。 在需要比较字符串的程序中使用字符的多种表示会产生问题。 为了修正这个问题，可以使用unicodedata模块先将文本标准化： 123456789101112131415import unicodedatat1 = unicodedata.normalize('NFC', s1)t2 = unicodedata.normalize('NFC', s2)print(t1 == t2)# Trueprint(ascii(t1))# 'Spicy Jalape\xf1o't1 = unicodedata.normalize('NFD', s1)t2 = unicodedata.normalize('NFD', s2)print(t1 == t2)# Trueprint(ascii(t1))# 'Spicy Jalapen\u0303o' normalize() 第一个参数指定字符串标准化的方式。 NFC表示字符应该是整体组成(比如可能的话就使用单一编码)，而NFD表示字符应该分解为多个组合字符表示。 Python同样支持扩展的标准化形式NFKC和NFKD，它们在处理某些字符的时候增加了额外的兼容特性。 标准化对于任何需要以一致的方式处理Unicode文本的程序都是非常重要的。 当处理来自用户输入的字符串而你很难去控制编码的时候尤其如此。 strip主要用来去除多余的空格，当然，也可也以去除多余的其他字符。strip() 方法能用于删除开始或结尾的字符。 lstrip() 和 rstrip() 分别从左和从右执行删除操作。 1234567s = ' hello world \n'print(s.strip())# hello worldprint(s.lstrip())# hello world \nprint(s.rstrip())# hello world 添加参数就可以对应去除参数中的字符。 12345t = '-----hello====='print(t.lstrip('-'))# hello=====print(t.strip('-='))# hello 这些 strip() 方法在读取和清理数据以备后续处理的时候是经常会被用到的。 比如，你可以用它们来去掉空格，引号和完成其他任务。 但是需要注意的是去除操作不会对字符串的中间的文本产生任何影响。如果想处理中间的空格，那么你需要求助其他技术。比如使用 replace() 方法或者是用正则表达式替换。 ljust、rjust、center 字符串对齐 通过参数的设定，可以指定字符串的长度，如果字符串长度不足，就不会添加字符进行填充。否则就会根据参数添加对应的字符进行添加填充，使得整个的字符串的长度达到参数所规定的长度。 123456789101112s = 'Hellow World'text = s.ljust(20)print(text)# Hellow Worldtext = s.rjust(20)print(text)# Hellow Worldtext = s.rjust(20, '-')print(text)# --------Hellow World 并且，format函数也可以对字符串进行填充。 12345678print(format(s, '+&gt;20s'))print(format(s, '-&lt;20s'))print(format(s, '=&gt;20s'))print(format(s, '*^20s'))# ++++++++Hellow World# Hellow World--------# ========Hellow World# ****Hellow World**** 也可以同时格式化多个值： 12s = '&#123;:+&gt;10s&#125; &#123;:-&gt;10s&#125;'.format('Hello', 'World')print(s) 注意：需要写：号，后面的s只是表明变量是字符串类型的，当然，format也可以格式化其他的类型。 所以，在需要对字符串进行格式化的时候，尽量使用format函数来格式化字符串，而不应该采用原来的代码%s类似的形式格式化。同时，这一种形式也可以替代ljust、rjust、center。 format_map 和 vars123456name = 'lim'age = 12s = '&#123;name&#125; is &#123;age&#125; years old.'print(s.format_map(vars()))# lim is 12 years old. 这样可以直接在变量域中寻找字符串中碎对应的变量，与字符串相结合。 vars() 还有一个有意思的特性就是它也适用于对象实例。 12345678910class People: def __init__(self, name, age): self.name = name self.age = ageme = People('jaelyn', 17)output = s.format_map(vars(me))print(output)# jaelyn is 17 years old. format 和 format_map() 的一个缺陷就是它们并不能很好的处理变量缺失的情况， 一种避免这种错误的方法是另外定义一个含有 __missing__() 方法的字典对象 123456789101112131415161718class People(): def __init__(self, name, age): self.name = name # self.age = age def __missing__(self, key): return '&#123;' + key + '&#125;'class safesub(dict): def __missing__(self, key): return '&#123;' + key + '&#125;'me = People('jaelyn', 17)output = s.format_map(safesub(vars(me)))print(output)# jaelyn is &#123;age&#125; years old. textwrap使用 textwrap 模块来格式化字符串的输出。 123456789101112131415161718192021222324252627282930313233343536import textwraps = "Look into my eyes, look into my eyes, the eyes, the eyes, \the eyes, not around the eyes, don't look around the eyes, \look into my eyes, you're under."print(textwrap.fill(s, 70), end='\n\n')"""Look into my eyes, look into my eyes, the eyes, the eyes, the eyes,not around the eyes, don't look around the eyes, look into my eyes,you're under."""print(textwrap.fill(s, 30), end='\n\n')"""Look into my eyes, look intomy eyes, the eyes, the eyes,the eyes, not around the eyes,don't look around the eyes,look into my eyes, you'reunder."""print(textwrap.fill(s, 40, initial_indent='++++++'), end='\n\n')"""++++++Look into my eyes, look into myeyes, the eyes, the eyes, the eyes, notaround the eyes, don't look around theeyes, look into my eyes, you're under."""print(textwrap.fill(s, 40, subsequent_indent='======'), end='\n\n')"""Look into my eyes, look into my eyes,======the eyes, the eyes, the eyes, not======around the eyes, don't look around======the eyes, look into my eyes,======you're under.""" textwrap 模块对于字符串打印是非常有用的，特别是当你希望输出自动匹配终端大小的时候。 你可以使用 os.get_terminal_size() 方法来获取终端的大小尺寸。 12345import osterminal_colum = os.get_terminal_size().columnsprint(terminal_colum)# 261 注意，上面的那条语句需要在控制台执行，不然会报 OSError: [WinError 6] 句柄无效。 的错误。 html.escape 在字符串中处理html和xml 想将HTML或者XML实体如 &amp;entity; 或 &amp;#code; 替换为对应的文本。 再者，需要转换文本中特定的字符(比如&lt;, &gt;, 或 &amp;)。 12345678910import htmls = 'Elements are written as "&lt;tag&gt;text&lt;/tag&gt;".'print(s)# Elements are written as "&lt;tag&gt;text&lt;/tag&gt;".print(html.escape(s))# Elements are written as &amp;quot;&amp;lt;tag&amp;gt;text&amp;lt;/tag&amp;gt;&amp;quot;.print(html.escape(s, quote=False))# Elements are written as "&amp;lt;tag&amp;gt;text&amp;lt;/tag&amp;gt;". 如果正在处理的是ASCII文本，并且想将非ASCII文本对应的编码实体嵌入进去， 可以给某些I/O函数传递参数 errors=&#39;xmlcharrefreplace&#39; 来达到这个目。 123s = 'Spicy Jalapeño'print(s.encode('ascii', errors='xmlcharrefreplace'))# b'Spicy Jalape&amp;#241;o' 为了替换文本中的编码实体，需要使用另外一种方法。 如果正在处理HTML或者XML文本，试着先使用一个合适的HTML或者XML解析器。 通常情况下，这些工具会自动替换这些编码值，你无需担心。 有时候，如果你接收到了一些含有编码值的原始文本，需要手动去做替换， 通常你只需要使用HTML或者XML解析器的一些相关工具函数/方法即可。 字符串令牌解析 字符串令牌解析 第一步就是利用命名捕获组的正则表达式来定义所有可能的令牌。?P&lt;TOKENNAME&gt; 用于给一个模式命名，供后面使用。 为了令牌化，使用模式对象很少被人知道的 scanner() 方法。 这个方法会创建一个 scanner 对象， 在这个对象上不断的调用 match() 方法会一步步的扫描目标文本，每步一个匹配。 123456789101112131415161718192021222324252627282930313233343536373839404142import refrom collections import namedtupleNAME = r'(?P&lt;NAME&gt;[a-zA-Z_][a-zA-Z_0-9]*)'NUM = r'(?P&lt;NUM&gt;\d+)'PLUS = r'(?P&lt;PLUS&gt;\+)'TIMES = r'(?P&lt;TIMES&gt;\*)'EQ = r'(?P&lt;EQ&gt;=)'WS = r'(?P&lt;WS&gt;\s+)'master_pat = re.compile('|'.join([NAME, NUM, PLUS, TIMES, EQ, WS]))print(master_pat)# re.compile('(?P&lt;NAME&gt;[a-zA-Z_][a-zA-Z_0-9]*)|(?P&lt;NUM&gt;\\d+)|(?P&lt;PLUS&gt;\\+)|(?P&lt;TIMES&gt;\\*)|(?P&lt;EQ&gt;=)|(?P&lt;WS&gt;\\s+)')scanner = master_pat.scanner('foo = 23 + 42 * 10')result = scanner.match()print(result)# &lt;_sre.SRE_Match object; span=(0, 3), match='foo'&gt;def generate_tokens(pat, text): Token = namedtuple('Token', ['type', 'value']) scanner = pat.scanner(text) for m in iter(scanner.match, None): yield Token(m.lastgroup, m.group())for tok in generate_tokens(master_pat, 'foo = 23 + 42 * 10'): print(tok)"""Token(type='NAME', value='foo')Token(type='WS', value=' ')Token(type='EQ', value='=')Token(type='WS', value=' ')Token(type='NUM', value='23')Token(type='WS', value=' ')Token(type='PLUS', value='+')Token(type='WS', value=' ')Token(type='NUM', value='42')Token(type='WS', value=' ')Token(type='TIMES', value='*')Token(type='WS', value=' ')Token(type='NUM', value='10')""" 通常来讲令牌化是很多高级文本解析与处理的第一步。 为了使用上面的扫描方法，你需要记住这里一些重要的几点。 第一点就是你必须确认你使用正则表达式指定了所有输入中可能出现的文本序列。 如果有任何不可匹配的文本出现了，扫描就会直接停止。这也是为什么上面例子中必须指定空白字符令牌的原因。 令牌的顺序也是有影响的。 re 模块会按照指定好的顺序去做匹配。 因此，如果一个模式恰好是另一个更长模式的子字符串，那么你需要确定长模式写在前面。 namedtuple 这个函数是用来实例化一个对象用的，这样对于一些比较简单的对象，没有太多的内容的话，就可以用这个函数去实例化出来。namedtuple 是一个函数，它用来创建一个自定义的 tuple 对象，并且规定了 tuple 元素的个数，并可以用属性而不是索引来引用 tuple 的某个元素。 实现一个简单的递归下降分析器 实现一个简单的递归下降分析器 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132#!/usr/bin/env python# -*- encoding: utf-8 -*-"""Topic: 下降解析器Desc :"""import reimport collections# Token specificationNUM = r'(?P&lt;NUM&gt;\d+)'PLUS = r'(?P&lt;PLUS&gt;\+)'MINUS = r'(?P&lt;MINUS&gt;-)'TIMES = r'(?P&lt;TIMES&gt;\*)'DIVIDE = r'(?P&lt;DIVIDE&gt;/)'LPAREN = r'(?P&lt;LPAREN&gt;\()'RPAREN = r'(?P&lt;RPAREN&gt;\))'WS = r'(?P&lt;WS&gt;\s+)'master_pat = re.compile('|'.join([NUM, PLUS, MINUS, TIMES, DIVIDE, LPAREN, RPAREN, WS]))# TokenizerToken = collections.namedtuple('Token', ['type', 'value'])def generate_tokens(text): scanner = master_pat.scanner(text) for m in iter(scanner.match, None): tok = Token(m.lastgroup, m.group()) if tok.type != 'WS': yield tok# Parserclass ExpressionEvaluator: ''' Implementation of a recursive descent parser. Each method implements a single grammar rule. Use the ._accept() method to test and accept the current lookahead token. Use the ._expect() method to exactly match and discard the next token on on the input (or raise a SyntaxError if it doesn't match). ''' def parse(self, text): self.tokens = generate_tokens(text) self.tok = None # Last symbol consumed self.nexttok = None # Next symbol tokenized self._advance() # Load first lookahead token return self.expr() def _advance(self): 'Advance one token ahead' self.tok, self.nexttok = self.nexttok, next(self.tokens, None) def _accept(self, toktype): 'Test and consume the next token if it matches toktype' if self.nexttok and self.nexttok.type == toktype: self._advance() return True else: return False def _expect(self, toktype): 'Consume next token if it matches toktype or raise SyntaxError' if not self._accept(toktype): raise SyntaxError('Expected ' + toktype) # Grammar rules follow def expr(self): "expression ::= term &#123; ('+'|'-') term &#125;*" exprval = self.term() while self._accept('PLUS') or self._accept('MINUS'): op = self.tok.type right = self.term() if op == 'PLUS': exprval += right elif op == 'MINUS': exprval -= right return exprval def term(self): "term ::= factor &#123; ('*'|'/') factor &#125;*" termval = self.factor() while self._accept('TIMES') or self._accept('DIVIDE'): op = self.tok.type right = self.factor() if op == 'TIMES': termval *= right elif op == 'DIVIDE': termval /= right return termval def factor(self): "factor ::= NUM | ( expr )" if self._accept('NUM'): return int(self.tok.value) elif self._accept('LPAREN'): exprval = self.expr() self._expect('RPAREN') return exprval else: raise SyntaxError('Expected NUMBER or LPAREN')def descent_parser(): e = ExpressionEvaluator() print(e.parse('2')) print(e.parse('2 + 3')) print(e.parse('2 + 3 * 4')) print(e.parse('2 + (3 + 4) * 5')) # print(e.parse('2 + (3 + * 4)')) # Traceback (most recent call last): # File "&lt;stdin&gt;", line 1, in &lt;module&gt; # File "exprparse.py", line 40, in parse # return self.expr() # File "exprparse.py", line 67, in expr # right = self.term() # File "exprparse.py", line 77, in term # termval = self.factor() # File "exprparse.py", line 93, in factor # exprval = self.expr() # File "exprparse.py", line 67, in expr # right = self.term() # File "exprparse.py", line 77, in term # termval = self.factor() # File "exprparse.py", line 97, in factor # raise SyntaxError("Expected NUMBER or LPAREN") # SyntaxError: Expected NUMBER or LPARENif __name__ == '__main__': descent_parser() 待研究学习，字符串相关 数字日期和时间round 数字的四舍五入 对浮点数执行指定精度的舍入运算。对于简单的舍入运算，使用内置的 round(value, ndigits) 函数即可。 123456print(round(1.23, 1))# 1.2print(round(1.27, 1))# 1.3print(round(1.25361,3))# 1.254 当一个值刚好在两个边界的中间的时候， round 函数返回离它最近的偶数。 也就是说，对1.5或者2.5的舍入运算都会得到2。 传给 round() 函数的 ndigits 参数可以是负数，这种情况下， 舍入运算会作用在十位、百位、千位等上面。 1234567a = 1627731print(round(a, -1))# 1627730print(round(a, -2))# 1627700print(round(a, -3))# 1628000 不要将舍入和格式化输出搞混淆了。 如果你的目的只是简单的输出一定宽度的数，你不需要使用 round() 函数。 而仅仅只需要在格式化的时候指定精度即可。 123x = 1.23456print(format(x, '0.2f'))# 1.23 decimal 执行精确的浮点数运算 对浮点数执行精确的计算操作，并且不希望有任何小误差的出现。 浮点数的一个普遍问题是它们并不能精确的表示十进制数。 并且，即使是最简单的数学运算也会产生小的误差。这些错误是由底层CPU和IEEE 754标准通过自己的浮点单位去执行算术时的特征。 由于Python的浮点数据类型使用底层表示存储数据，因此你没办法去避免这样的误差。 12345678from decimal import Decimala = Decimal('4.2')b = Decimal('2.1')print(a + b)# 6.3print((a + b) == Decimal('6.3'))# True 初看起来，上面的代码好像有点奇怪，比如我们用字符串来表示数字。 然而， Decimal 对象会像普通浮点数一样的工作(支持所有的常用数学运算)。 如果你打印它们或者在字符串格式化函数中使用它们，看起来跟普通数字没什么两样。 Python新手会倾向于使用 decimal 模块来处理浮点数的精确运算。 然而，先理解你的应用程序目的是非常重要的。 如果你是在做科学计算或工程领域的计算、电脑绘图，或者是科学领域的大多数运算， 那么使用普通的浮点类型是比较普遍的做法。 其中一个原因是，在真实世界中很少会要求精确到普通浮点数能提供的17位精度。 因此，计算过程中的那么一点点的误差是被允许的。 第二点就是，原生的浮点数计算要快的多-有时候你在执行大量运算的时候速度也是非常重要的。 总的来说， decimal 模块主要用在涉及到金融的领域。 在这类程序中，哪怕是一点小小的误差在计算过程中蔓延都是不允许的。 因此， decimal 模块为解决这类问题提供了方法。 当Python和数据库打交道的时候也通常会遇到 Decimal 对象，并且，通常也是在处理金融数据的时候。 fractions 分数运算 用来执行包含分数的数学运算。 123456from fractions import Fractiona = Fraction(5, 4)b = Fraction(7, 16)print(a + b)# 27/16 也可以用 numerator 显示分子，用denominator显示分母。或者也可以使用float函数显示分数的浮点类型。 12345678910c = a * bprint(c)# 35/64print(c.numerator)# 35print(c.denominator)# 64print(float(c))# 0.546875 这个函数同样也有很多用法，例如，求出一个分数，该分数的分母不超过所设定的数，并且该分数的值最接近所求的浮点数。 12print(c.limit_denominator(10))# 5/9 或者给出一个小数，求原来的分数，当然，求出来的值是最为接近的值，不代表完全一致。 1234x = 3.75y = Fraction(*x.as_integer_ratio())print(y)# 15/4 在大多数程序中一般不会出现分数的计算问题，但是有时候还是需要用到的。 比如，在一个允许接受分数形式的测试单位并以分数形式执行运算的程序中， 直接使用分数可以减少手动转换为小数或浮点数的工作。 NumPy 大型数组运算 123456x = [1, 2, 3, 4]y = [5, 6, 7, 8]print(x * 2)# [1, 2, 3, 4, 1, 2, 3, 4]print(x + y)# [1, 2, 3, 4, 5, 6, 7, 8] 由此我们可以看出，python 原生的对与数列的处理就是普通的对于数列上的操作，由此看来，像 * 、 + 等操作，是以整个数列为最小单位的操作。 123456789101112import numpy as npax = np.array([1, 2, 3, 4])ay = np.array([5, 6, 7, 8])print(ax * 2)# [2 4 6 8]print(ax + 10)# [11 12 13 14]print(ax + ay)# [ 6 8 10 12]print(ax * ay)# [ 5 12 21 32] 与原生的不同，numpy 的数列操作则是对应里面的每一个元素的操作。 NumPy 中的标量运算(比如 ax * 2 或 ax + 10 )会作用在每一个元素上。 另外，当两个操作数都是数组的时候执行元素对等位置计算，并最终生成一个新的数组。 NumPy 还为数组操作提供了大量的通用函数，这些函数可以作为 math 模块中类似函数的替代。 使用这些通用函数要比循环数组并使用 math 模块中的函数执行计算要快的多。 因此，只要有可能的话尽量选择 NumPy 的数组方案。 底层实现中， NumPy 数组使用了C或者Fortran语言的机制分配内存。 也就是说，它们是一个非常大的连续的并由同类型数据组成的内存区域。 所以，你可以构造一个比普通Python列表大的多的数组。 NumPy 是Python领域中很多科学与工程库的基础，同时也是被广泛使用的最大最复杂的模块。 即便如此，在刚开始的时候通过一些简单的例子和玩具程序也能帮我们完成一些有趣的事情。 通常我们导入 NumPy 模块的时候会使用语句 import numpy as np 。 这样的话你就不用再你的程序里面一遍遍的敲入 numpy ，只需要输入 np 就行了，节省了不少时间。 矩阵与线性代数运算 NumPy 库有一个矩阵对象可以用来解决这个问题。 1234567891011121314m = np.matrix([[1, -2, 3], [0, 4, 5], [7, 8, -9]])print(m)"""[[ 1 -2 3] [ 0 4 5] [ 7 8 -9]]"""print(m.T)"""# 输出矩阵的转置[[ 1 0 7] [-2 4 8] [ 3 5 -9]]""" 可以在 numpy.linalg 子包中找到更多的操作函数。 这个函数有很多强大的功能，如果需要用到一些关于矩阵和线性代数相关的知识和运算的时候，可以参考这个函数，能轻松解决很多问题。 random 随机选择 主要用于生成随机数的函数。 random 模块有大量的函数用来产生随机数和随机选择元素。 1234567891011121314151617181920212223242526272829303132333435import randomvalues = [1, 2, 3, 4, 5, 6]# 在列表中随机生成一个数字a = random.choice(values)print(a)# 1# 在列表中随机生成多个数字组成的新列表b = random.sample(values, 2)print(b)# [1, 2]# 随机打乱列表的位置，没有返回值，会直接在原来的数组上修改，属于原地操作random.shuffle(values)print(values)# [6, 5, 1, 2, 3, 4]print(values[0])# 6# 在1到10之间随机生成一个数字c = random.randint(1, 10)print(c)# 9# 在0到1之间随机生成浮点数d = random.random()print(d)# 0.19051868016253204# 获取N位随机位(二进制)的整数e = random.getrandbits(20)print(e)# 293829 random 模块使用 Mersenne Twister 算法来计算生成随机数。 除了上述介绍的功能，random模块还包含基于均匀分布、高斯分布和其他分布的随机数生成函数。 比如， random.uniform() 计算均匀分布随机数， random.gauss() 计算正态分布随机数。 在 random 模块中的函数不应该用在和密码学相关的程序中。 如果你确实需要类似的功能，可以使用ssl模块中相应的函数。 比如， ssl.RAND_bytes() 可以用来生成一个安全的随机字节序列。 datetime &amp; timedelta 基本的日期与时间转换 执行不同时间单位的转换和计算，请使用 datetime 模块。 如果你想表示指定的日期和时间，先创建一个 datetime 实例然后使用标准的数学运算来操作它们。 12345678910111213141516171819202122232425262728293031323334353637from datetime import timedeltafrom datetime import datetimea = timedelta(days=2, hours=6)b = timedelta(hours=4.5)c = a + bprint(c)# 2 days, 10:30:00print(c.days)# 2print(c.seconds)# 37800print(c.microseconds)# 0print(c.total_seconds())# 210600.0a = datetime(2012, 9, 23)print(a + timedelta(days=10))# 2012-10-03 00:00:00b = datetime(2012, 12, 21)d = b - aprint(d.days)# 89now = datetime.today()print(now)# 2018-05-28 18:44:35.190897print(now + timedelta(minutes=10))# 2018-05-28 18:54:35.190897a = datetime(2012, 3, 1)b = datetime(2012, 2, 28)print(a - b)# 2 days, 0:00:00print((a-b).days)# 2 在计算的时候，需要注意的是 datetime 会自动处理闰年。 对大多数基本的日期和时间处理问题， datetime 模块已经足够了。 如果你需要执行更加复杂的日期操作，比如处理时区，模糊时间范围，节假日计算等等， 可以考虑使用 dateutil 模块。 如果要执行大量的日期计算的话，最好安装第三方包 python-dateutil 来代替。 1234567891011from datetime import datetimefrom dateutil.relativedelta import relativedeltafrom dateutil.rrule import *d = datetime.now()print(d)# 2018-05-28 23:39:37.526316print(d + relativedelta(weekday=FR))# 2018-06-01 23:39:37.526316print(d + relativedelta(weekday=FR(-1)))# 2018-05-25 23:39:37.526316 计算当前月份的日期范围 计算对应的月份的天数，可以用到calendar.monthrange()函数，这个函数会根据所传入的年份和月数量，返回一个元组，包括对应月份的的星期和天数。 这样的话就可以使用循环等操作，获得当月份的所有日期。 12345678910111213141516171819202122from datetime import datetime, date, timedeltaimport calendardef get_month_range(start_date=None): if start_date is None: start_date = date.today().replace(month=2, day=1) # Return weekday (0-6 ~ Mon-Sun) and number of days (28-31) for year, month. temp, days_in_month = calendar.monthrange(start_date.year, start_date.month) print(temp) # 3 print(days_in_month) # 28 end_date = start_date + timedelta(days=days_in_month) return (start_date, end_date)a_day = timedelta(days=1)first_day, last_day = get_month_range()while first_day &lt; last_day: print(first_day) first_day += a_day 同样的，也可以采用生成器的方式： 1234567def date_range(start, stop, step): while start &lt; stop: yield start start += stepfor d in date_range(datetime(2012, 9, 1), datetime(2012, 10, 1), timedelta(hours=6)): print(d) 字符串转换为日期 123456text = '2012-09-20'y = datetime.strptime(text, '%Y-%m-%d')z = datetime.now()diff = z- yprint(diff)# 2077 days, 11:13:12.631424 datetime.strptime() 方法支持很多的格式化代码， 比如 %Y 代表4位数年份， %m 代表两位数月份。 还有一点值得注意的是这些格式化占位符也可以反过来使用，将日期输出为指定的格式字符串形式。 1234z = datetime.now()nice_z = datetime.strftime(z, '%Y年%m月%d日')print(nice_z)# 2018年05月29日 还有一点需要注意的是， strptime() 的性能要比你想象中的差很多， 因为它是使用纯Python实现，并且必须处理所有的系统本地设置。 如果你要在代码中需要解析大量的日期并且已经知道了日期字符串的确切格式，可以自己实现一套解析方案来获取更好的性能。 datetime.strptime(text, &#39;%Y-%m-%d&#39;) 将字符串转为日期格式。 datetime.strftime(z, &#39;%Y年%m月%d日&#39;) 将日期格式按照自己所设定的格式转为字符串。（这个函数运行的会很慢，如果需要大量的对字符串的操作，并且有很多格式相似，可以自己用字符串拆分等方式，拆字符串拼接，这样的方式可以比这个函数快7倍） 结合时区的日期操作 pytz 模块一个主要用途是将 datetime 库创建的简单日期对象本地化。 123456789101112131415from datetime import datetimefrom pytz import timezoned = datetime(2018, 5, 28, 11, 22, 41)print(d)d = datetime.now()central = timezone('Asia/Shanghai')loc_d = central.localize(d)print(loc_d)# 2018-05-29 11:28:56.614715+08:00bang_d = loc_d.astimezone(timezone('US/Central'))print(bang_d)# 2018-05-28 22:28:56.614715-05:00 首先需要先本地化时间（localize方法），之后再调用 astimezone 方法用于切换时区时间。 在使用的时候需要注意，在本地化时间上操作的时候，要考虑到夏令时的相关问题，不然会出现时间差 1 小时的情况。 在使用的时候，如果不记得时区的表达方式，可以使用 country_timezones 来获得时区。 123456789import pytzp = pytz.country_timezones['IN']print(p)# ['Asia/Kolkata']p = pytz.country_timezones['CN']print(p)# ['Asia/Shanghai', 'Asia/Urumqi'] 迭代器和生成器next()遍历迭代下一个元素，在文件中表示一行。在执行的时候，如果捕获到最后一行，或者捕获到自定义的结束字符的时候，就会返回StopIteration异常，结束读取。 1234567891011items = [1, 2, 3]it = iter(items)print(next(it))# 1print(next(it))# 2print(next(it))# 3print(next(it))# StopIteration iter() 代理迭代 如果在自己定义的类中需要有自己的定义的迭代，可以定义一个 __iter__() 方法，将迭代操作代理到容器内部的对象上去。 123456789101112131415161718192021222324class Node: def __init__(self, value): self._value = value self._children = [] def __repr__(self): # &#123;!r&#125; 其中 “!r” 对应 repr()； “!s” 对应 str(); “!a” 对应 ascii()。 return 'Node(&#123;!r&#125;)'.format(self._value) def add_children(self, node): self._children.append(node) def __iter__(self): return iter(self._children)if __name__ == '__main__': root = Node(0) child1 = Node(1) child2 = Node(2) root.add_children(child1) root.add_children(child2) for ch in root: print(ch) 这里的 iter() 函数的使用简化了代码， iter(s) 只是简单的通过调用 s.__iter__() 方法来返回对应的迭代器对象， 就跟 len(s) 会调用 s.__len__() 原理是一样的。 实现深度优先的遍历的树形结构 可以在类中迭代方法的方式 1234567891011121314151617181920212223242526272829303132class Node: def __init__(self, value): self._value = value self._children = [] def __repr__(self): return 'Node(&#123;!r&#125;)'.format(self._value) def add_child(self, node): self._children.append(node) def __iter__(self): return iter(self._children) def depth_first(self): yield self for c in self: yield from c.depth_first()if __name__ == '__main__': root = Node(0) child1 = Node(1) child2 = Node(2) root.add_child(child1) root.add_child(child2) child1.add_child(Node(3)) child1.add_child(Node(4)) child2.add_child(Node(5)) for ch in root.depth_first(): print(ch) 在 depth_first 方法中，首先迭代自己，之后在 __iter__ 的迭代中，开始迭代自己的下级，最后在循环中，yield from c.depth_first()放回自己的下级。 在这段代码中，depth_first() 方法简单直观。 它首先返回自己本身并迭代每一个子节点并 通过调用子节点的 depth_first() 方法(使用 yield from 语句)返回对应元素。 reversed() 反向迭代 1234a = [1, 2, 3, 4]for i in reversed(a): print(i, end=' ') # 4 3 2 1 反向迭代仅仅当对象的大小可预先确定或者对象实现了 __reversed__() 的特殊方法时才能生效。 如果两者都不符合，那必须先将对象转换为一个列表才行。 可以通过在自定义类上实现 __reversed__() 方法来实现反向迭代。 12345678910111213141516171819202122class Countdown: def __init__(self, start): self.start = start # Forward iterator def __iter__(self): n = self.start while n &gt; 0: yield n n -= 1 # Reverse iterator def __reversed__(self): n = 1 while n &lt;= self.start: yield n n += 1for rr in reversed(Countdown(30)): print(rr)for rr in Countdown(30): print(rr) 定义一个反向迭代器可以使得代码非常的高效， 因为它不再需要将数据填充到一个列表中然后再去反向迭代这个列表。 带有外部状态的生成器函数 带有外部状态的生成器函数 12345678910111213141516171819202122from collections import dequeclass linehistory: def __init__(self, lines, histlen=3): self.lines = lines self.history = deque(maxlen=histlen) def __iter__(self): for lineno, line in enumerate(self.lines, 1): self.history.append((lineno, line)) yield line def clear(self): self.history.clear()with open('somefile.txt') as f: lines = linehistory(f) for line in lines: if 'python' in line: for lineno, hline in lines.history: print('&#123;&#125;:&#123;&#125;'.format(lineno, hline), end='') 为了使用这个类，你可以将它当做是一个普通的生成器函数。 然而，由于可以创建一个实例对象，于是你可以访问内部属性值， 比如 history 属性或者是 clear() 方法。 一个需要注意的小地方是，如果你在迭代操作时不使用for循环语句，那么你得先调用 iter() 函数。 itertools.islice() 迭代器切片 123456789101112import itertoolsdef count(n, end=10): while n &lt; end: yield n n += 1 yield endc = count(1, end=20)for x in itertools.islice(c, 2, 100): print(x) itertools.islice表示对迭代器或者生成器进行切片，不过不能使用标准的切片方法，标准的切片方法是基于原来的数组是固定长度的情况下才能使用的。这个切片是以函数的形式，接收开始的值和结束的值，位置（长度），之后将切片之后的迭代器返回。 迭代器和生成器不能使用标准的切片操作，因为它们的长度事先我们并不知道(并且也没有实现索引)。 函数 islice() 返回一个可以生成指定元素的迭代器，它通过遍历并丢弃直到切片开始索引位置的所有元素。 然后才开始一个个的返回元素，并直到切片结束索引位置。 这里要着重强调的一点是 islice() 会消耗掉传入的迭代器中的数据。 必须考虑到迭代器是不可逆的这个事实。 所以如果你需要之后再次访问这个迭代器的话，那你就得先将它里面的数据放入一个列表中。 itertools.dropwhileitertools.dropwhile() 函数。使用时，传递一个函数对象和一个可迭代对象。会返回一个迭代器对象，丢弃原有序列中直到函数返回Flase之前的所有元素，然后返回后面所有元素。 12345from itertools import dropwhilewith open('__init__.py') as f: for line in dropwhile(lambda line: line.startswith('#'), f): print(line, end=' ') 如果已经明确知道了要跳过的元素的个数的话，那么可以使用 itertools.islice() 来代替。 1234from itertools import isliceitems = ['a', 'b', 'c', 1, 4, 10, 15]for x in islice(items, 3, None): print(x) 这个函数会根据所传入的参数，跳过前面几个迭代。islice() 函数最后那个 None 参数指定了你要获取从第3个到最后的所有元素， 如果 None 和3的位置对调，意思就是仅仅获取前三个元素恰恰相反， (这个跟切片的相反操作 [3:] 和 [:3] 原理是一样的)。 解决方案是仅仅跳过开始部分满足测试条件的行，在那以后，所有的元素不再进行测试和过滤了。 itertools.permutations 和 itertools.combinations对数列进行排列组合 123456from itertools import permutationsitems = ['a', 'b', 'c']for p in permutations(items): print(p) itertools.permutations() ， 它接受一个集合并产生一个元组序列，每个元组由集合中所有元素的一个可能排列组成。 也就是说通过打乱集合中元素排列顺序生成一个元组。 如果想得到指定长度的所有排列，可以传递一个可选的长度参数。 123456789101112131415161718192021from itertools import combinationsfor p in combinations(items, 3): print(p) # ('a', 'b', 'c')for p in combinations(items, 2): print(p)"""('a', 'b')('a', 'c')('b', 'c')"""for p in combinations(items, 1): print(p)"""('a',)('b',)('c',)""" 对于 combinations() 来讲，元素的顺序已经不重要了。 也就是说，组合 (‘a’, ‘b’) 跟 (‘b’, ‘a’) 其实是一样的(最终只会输出其中一个)。 在计算组合的时候，一旦元素被选取就会从候选中剔除掉(比如如果元素’a’已经被选取了，那么接下来就不会再考虑它了)。 而函数 itertools.combinations_with_replacement() 允许同一个元素被选择多次。 12345678910111213141516from itertools import combinations_with_replacementfor p in combinations_with_replacement(items, 3): print(p)"""('a', 'a', 'a')('a', 'a', 'b')('a', 'a', 'c')('a', 'b', 'b')('a', 'b', 'c')('a', 'c', 'c')('b', 'b', 'b')('b', 'b', 'c')('b', 'c', 'c')('c', 'c', 'c')""" enumerate在迭代的时候，获得迭代的索引。 1234567891011121314151617my_list = ['a', 'b', 'c']for idx, val in enumerate(my_list): print(idx, val)"""0 a1 b2 c"""for idx, val in enumerate(my_list, 1): print(idx, val)"""1 a2 b3 c""" 如果加入一个参数，则会当作索引的开始。这样在例如有错误的时候，就能很快速的定位错误所在。 enumerate() 函数返回的是一个 enumerate 对象实例， 它是一个迭代器，返回连续的包含一个计数和一个值的元组， 元组中的值通过在传入序列上调用 next() 返回。 还有一点可能并不很重要，但是也值得注意， 有时候在一个已经解压后的元组序列上使用 enumerate() 函数时很容易调入陷阱。 12345678910data = [ (1, 2), (3, 4), (5, 6), (7, 8) ]for n, (x, y) in enumerate(data): print(n, x, y)"""0 1 21 3 42 5 63 7 8""" 同时迭代多个序列 同时迭代多个序列 12345678910111213xpts = [1, 5, 4, 2, 10, 7]ypts = [101, 78, 37, 15, 62, 99]for x, y in zip(xpts, ypts): print(x, y)"""1 1015 784 372 1510 627 99""" zip(a, b) 会生成一个可返回元组 (x, y) 的迭代器，其中x来自a，y来自b。 一旦其中某个序列到底结尾，迭代宣告结束。 因此迭代长度跟参数中最短序列长度一致。 12345678910a = [1, 2, 3]b = ['w', 'x', 'y', 'z']for i in zip(a, b): print(i)"""(1, 'w')(2, 'x')(3, 'y')""" 如果需要以最长的字段输出，可以采用itertools.zip_longest的方法 123456789from itertools import zip_longestfor i in zip_longest(a, b): print(i)for i in zip_longest(a, b, fillvalue=0): print(i)for i in zip_longest(a, b, fillvalue="asd"): print(i) 如果没有指定填充值（fillvalue）的话，就会以None的方式代替，可以采用指定fillvalue的方式填充。 在处理成对的数据的时候，zip会变得很有用，他可以把两个列表编程字典的形式。 12345678910headers = ['name', 'shares', 'price']values = ['ACME', 100, 490.1]coll_dict = dict(zip(headers, values))print(coll_dict)# &#123;'name': 'ACME', 'shares': 100, 'price': 490.1&#125;for h, v in zip(headers, values): print(h, ' = ', v) 当然，zip可以接收多余两个列表的参数。 zip() 会创建一个迭代器来作为结果返回。 如果你需要将结对的值存储在列表中，要使用 list() 函数。 itertools.chain 不同集合上元素的迭代 这个函数可以让我们在操作几个数列的时候，进行相同操作的时候，使得我们的代码会更加优雅，减少循环的次数，减少多余的代码。 函数itertools.chain可以将所传入的函数连接成链表一样，在操作循环的时候，代码在不失可读性的情况下避免写重复的循环。 12345678910from itertools import chaina = [1, 2, 3, 4]b = ['x', 'y', 'z']for i in chain(a, b): print(i, end=' ')"""1 2 3 4 x y z """ itertools.chain() 接受一个或多个可迭代对象作为输入参数。 然后创建一个迭代器，依次连续的返回每个可迭代对象中的元素。 这种方式要比先将序列合并再迭代要高效的多。 在使用itertools.chain的时候，会比直接将两个列表进行相加（a + b）这样的操作的效率会更高，这种相加的操作会生成一个新的列表，而使用itertools.chain会将不仅效率更高，对于两个不同对象的列表也能很好的进行操作。 yield from 展开嵌套的序列 将一个多层嵌套的序列展开成一个单层列表 12345678910111213from collections import Iterabledef flatten(items, ignore_types=(str, bytes)): for x in items: if isinstance(x, Iterable) and not isinstance(x, ignore_types): yield from flatten(x) else: yield xitems = [1, 2, [3, 4, [5, 6], 7], 8]# Produces 1 2 3 4 5 6 7 8for x in flatten(items): print(x) 在上面代码中， isinstance(x, Iterable) 检查某个元素是否是可迭代的。 如果是的话， yield from 就会返回所有子例程的值。最终返回结果就是一个没有嵌套的简单序列了。 在上面代码中， isinstance(x, Iterable) 检查某个元素是否是可迭代的。 如果是的话， yield from 就会返回所有子例程的值。最终返回结果就是一个没有嵌套的简单序列了。 额外的参数 ignore_types 和检测语句 isinstance(x, ignore_types) 用来将字符串和字节排除在可迭代对象外，防止将它们再展开成单个的字符。 这样的话字符串数组就能最终返回我们所期望的结果了。 1234items = ['Dave', 'Paula', ['Thomas', 'Lewis']]for x in flatten(items): print(x, end=' ')# Dave Paula Thomas Lewis 语句 yield from 在你想在生成器中调用其他生成器作为子例程的时候非常有用。 如果你不使用它的话，那么就必须写额外的 for 循环了。 1234567def flatten(items, ignore_types=(str, bytes)): for x in items: if isinstance(x, Iterable) and not isinstance(x, ignore_types): for i in flatten(x): yield i else: yield x 最后要注意的一点是， yield from 在涉及到基于协程和生成器的并发编程中扮演着更加重要的角色。 heapq.merge 顺序迭代合并后的排序迭代对象 将两个列表合成一个列表，并且排序。 1234567import heapqa = [1, 4, 7, 10]b = [2, 5, 6, 11]for c in heapq.merge(a, b): print(c) heapq.merge 可迭代特性意味着它不会立马读取所有序列。 这就意味着你可以在非常长的序列中使用它，而不会有太大的开销。 有一点要强调的是 heapq.merge() 需要所有输入序列必须是排过序的。 特别的，它并不会预先读取所有数据到堆栈中或者预先排序，也不会对输入做任何的排序检测。 它仅仅是检查所有序列的开始部分并返回最小的那个，这个过程一直会持续直到所有输入序列中的元素都被遍历完。 迭代器代替while无限循环一般的IO操作可能会用到while循环。 12345678CHUNKSIZE = 8192def reader(s): while True: data = s.recv(CHUNKSIZE) if data == b'': break process_data(data) 这种代码通常可以使用 iter() 来代替。 1234def reader2(s): for chunk in iter(lambda: s.recv(CHUNKSIZE), b''): pass # process_data(data) iter 函数一个鲜为人知的特性是它接受一个可选的 callable 对象和一个标记(结尾)值作为输入参数。 当以这种方式使用的时候，它会创建一个迭代器， 这个迭代器会不断调用 callable 对象直到返回值和标记值相等为止。 这种特殊的方法对于一些特定的会被重复调用的函数很有效果，比如涉及到I/O调用的函数。 举例来讲，如果你想从套接字或文件中以数据块的方式读取数据，通常你得要不断重复的执行 read() 或 recv() ， 并在后面紧跟一个文件结尾测试来决定是否终止。这节中的方案使用一个简单的 iter() 调用就可以将两者结合起来了。 其中 lambda 函数参数是为了创建一个无参的 callable 对象，并为 recv 或 read() 方法提供了 size 参数。 文件与IO读写文本数据 读写文本数据 使用带有 rt 模式的 open() 函数读取文本文件。 12with open('somefile.txt', 'rt') as f: data = f.read() 类似的，为了写入一个文本文件，使用带有 wt 模式的 open() 函数， 如果之前文件内容存在则清除并覆盖掉。 123with open('somefile.txt', 'wt') as f: f.write(text1) f.write(text2) 如果是在已存在文件中添加内容，使用模式为 at 的 open() 函数。 文件的读写操作默认使用系统编码，可以通过调用 sys.getdefaultencoding() 来得到。 在大多数机器上面都是utf-8编码。 12345import syss = sys.getdefaultencoding()print(s)# utf-8 如果你已经知道你要读写的文本是其他编码方式， 那么可以通过传递一个可选的 encoding 参数给open()函数。 12with open('somefile.txt', 'rt', encoding='latin-1') as f: pass Python支持非常多的文本编码。几个常见的编码是ascii, latin-1, utf-8和utf-16。 在web应用程序中通常都使用的是UTF-8。 ascii对应从U+0000到U+007F范围内的7位字符。 latin-1是字节0-255到U+0000至U+00FF范围内Unicode字符的直接映射。当读取一个未知编码的文本时使用latin-1编码永远不会产生解码错误。 使用latin-1编码读取一个文件的时候也许不能产生完全正确的文本解码数据， 但是它也能从中提取出足够多的有用数据。同时，如果你之后将数据回写回去，原先的数据还是会保留的。 读写文本文件一般来讲是比较简单的。但是也几点是需要注意的。 首先，在例子程序中的with语句给被使用到的文件创建了一个上下文环境， 但 with 控制块结束时，文件会自动关闭。你也可以不使用 with 语句，但是这时候你就必须记得手动关闭文件： 123f = open('somefile.txt', 'rt')data = f.read()f.close() 另外一个问题是关于换行符的识别问题，在Unix和Windows中是不一样的(分别是 \n 和 \r\n )。 默认情况下，Python会以统一模式处理换行符。 这种模式下，在读取文本的时候，Python可以识别所有的普通换行符并将其转换为单个 \n 字符。 类似的，在输出时会将换行符 \n 转换为系统默认的换行符。 如果你不希望这种默认的处理方式，可以给 open() 函数传入参数 newline=’’ ，就像下面这样： 123# Read with disabled newline translationwith open('somefile.txt', 'rt', newline='') as f: ... 如果出现编码错误的时候，优先去查看文件的编码，用encoding指定相对应的编码进行文件的读取，如果编码错误还是存在的话，你可以给 open() 函数传递一个可选的 errors 参数来处理这些错误。 12345f = open('sample.txt', 'rt', encoding='ascii', errors='replace') passf = open('sample.txt', 'rt', encoding='ascii', errors='ignore') pass 如果想用print()函数将结果输入到一个文件中，可以在print函数中指定file的参数。 12with open('d:/work/test.txt', 'wt') as f: print('Hello World!', file=f) sep在print函数中指定两个输出的连接。 123for i in range(10): print(i, i, sep='+', end=' ')# 0+0 1+1 2+2 3+3 4+4 5+5 6+6 7+7 8+8 9+9 如果想要用str.join()的方式连接的话，就应该要注意，这种连接需要在保证输出的内容是字符串，也就是说如果输出内容不是字符串类型的时候，需要多一个步骤去转换。 读写字节数据读写二进制文件，比如图片，声音文件等等，使用模式为 rb 或 wb 的 open() 函数来读取或写入二进制数据。 12345with open('somefile.bin', 'rb') as f: data = f.read()with open('somefile.bin', 'wb') as f: f.write(b'Hello World') 在读取二进制数据时，需要指明的是所有返回的数据都是字节字符串格式的，而不是文本字符串。 类似的，在写入的时候，必须保证参数是以字节形式对外暴露数据的对象(比如字节字符串，字节数组对象等)。 如果你想从二进制模式的文件中读取或写入文本数据，必须确保要进行解码和编码操作。 1234567with open('somefile.bin', 'rb') as f: data = f.read(16) text = data.decode('utf-8')with open('somefile.bin', 'wb') as f: text = 'Hello World' f.write(text.encode('utf-8')) io.StringIO 和 io.BytesIO 字符串的I/O操作 12345678910111213141516import ios = io.StringIO()s.write('Hello World\n')print('This is a test', file=s)print(s.getvalue())# Hello World# This is a tests = io.StringIO('Hello\nWorld\n')print(s.read(4))# Hellprint(s.read())# o# World 当你想模拟一个普通的文件的时候 StringIO 和 BytesIO 类是很有用的。 比如，在单元测试中，你可以使用 StringIO 来创建一个包含测试数据的类文件对象， 这个对象可以被传给某个参数为普通文件对象的函数。 gzip 和 bz2 读写压缩文件 读写一个gzip或bz2格式的压缩文件 123456789101112131415161718192021# 读取# gzip compressionimport gzipwith gzip.open('somefile.gz', 'rt') as f: text = f.read()# bz2 compressionimport bz2with bz2.open('somefile.bz2', 'rt') as f: text = f.read()# 写入# gzip compressionimport gzipwith gzip.open('somefile.gz', 'wt') as f: f.write(text)# bz2 compressionimport bz2with bz2.open('somefile.bz2', 'wt') as f: f.write(text) 当写入压缩数据时，可以使用 compresslevel 这个可选的关键字参数来指定一个压缩级别。 functools.partial 固定大小记录的文件迭代 在固定长度记录或者数据块的集合上迭代，而不是在一个文件中一行一行的迭代。 12345678from functools import partialRECORD_SIZE = 32with open('somefile.txt', 'rt') as f: records = iter(partial(f.read, RECORD_SIZE), "") for r in records: print(r, '\n\n\n') 这个例子中的 records 对象是一个可迭代对象，它会不断的产生固定大小的数据块，直到文件末尾。 要注意的是如果总记录大小不是块大小的整数倍的话，最后一个返回元素的字节数会比期望值少。 iter() 函数有一个鲜为人知的特性就是，如果你给它传递一个可调用对象和一个标记值，它会创建一个迭代器。 这个迭代器会一直调用传入的可调用对象直到它返回标记值为止，这时候迭代终止。 在例子中， functools.partial 用来创建一个每次被调用时从文件中读取固定数目字节的可调用对象。 标记值 “” 就是当到达文件结尾时的返回值。 一般来说，这种读取固定大小的做法对于读取二进制文件来说比较普遍，对于读取文本文件，更多的做法是一行行读取。 os.path 文件路径名的操作 12345678910111213141516171819import ospath = '/Users/beazley/Data/data.csv's1 = os.path.basename(path)print(s1)# data.csvs2 = os.path.dirname(path)print(s2)# /Users/beazley/Datas3 = os.path.join('tmp', 'data', os.path.basename(path))print(s3)# tmp/data/data.csvpath = '~/Data/data.csv's4 = os.path.expanduser(path)print(s4)# /Users/apple/Data/data.csvs5 = os.path.splitext(path)print(s5)# ('~/Data/data', '.csv') 对于任何的文件名的操作，你都应该使用 os.path 模块，而不是使用标准字符串操作来构造自己的代码。 特别是为了可移植性考虑的时候更应如此， 因为 os.path 模块知道Unix和Windows系统之间的差异并且能够可靠地处理类似 Data/data.csv 和 Data\data.csv 这样的文件名。 其次，你真的不应该浪费时间去重复造轮子。通常最好是直接使用已经为你准备好的功能。 测试一个文件或目录是否存在。 1234567891011121314151617181920212223242526272829303132&gt;&gt;&gt; import os&gt;&gt;&gt; os.path.exists('/etc/passwd')True&gt;&gt;&gt; os.path.exists('/tmp/spam')False&gt;&gt;&gt;&gt;&gt;&gt; # Is a regular file&gt;&gt;&gt; os.path.isfile('/etc/passwd')True&gt;&gt;&gt; # Is a directory&gt;&gt;&gt; os.path.isdir('/etc/passwd')False&gt;&gt;&gt; # Is a symbolic link&gt;&gt;&gt; os.path.islink('/usr/local/bin/python3')True&gt;&gt;&gt; # Get the file linked to&gt;&gt;&gt; os.path.realpath('/usr/local/bin/python3')'/usr/local/bin/python3.3'&gt;&gt;&gt;&gt;&gt;&gt; os.path.getsize('/etc/passwd')3669&gt;&gt;&gt; os.path.getmtime('/etc/passwd')1272478234.0&gt;&gt;&gt; import time&gt;&gt;&gt; time.ctime(os.path.getmtime('/etc/passwd'))'Wed Apr 28 13:10:34 2010'&gt;&gt;&gt; os.listdir获取文件系统中某个目录下的所有文件列表。 使用 os.listdir() 函数来获取某个目录中的文件列表： 12import osnames = os.listdir('somedir') 结果会返回目录中所有文件列表，包括所有文件，子目录，符号链接等等。 如果你需要通过某种方式过滤数据，可以考虑结合 os.path 库中的一些函数来使用列表推导。 123456789import os.path# Get all regular filesnames = [name for name in os.listdir('somedir') if os.path.isfile(os.path.join('somedir', name))]# Get all dirsdirnames = [name for name in os.listdir('somedir') if os.path.isdir(os.path.join('somedir', name))] 字符串的 startswith() 和 endswith() 方法对于过滤一个目录的内容也是很有用的。 12pyfiles = [name for name in os.listdir('somedir') if name.endswith('.py')] 文件名的匹配，也可以考虑用 glob 或者 fnmatch 模块。 123456import globpyfiles = glob.glob('somedir/*.py')from fnmatch import fnmatchpyfiles = [name for name in os.listdir('somedir') if fnmatch(name, '*.py')] tempfile 创建临时文件和文件夹 用于创建一个临时的文件或文件夹。 123456789101112from tempfile import TemporaryFilewith TemporaryFile('w+t') as f: # Read/write to the file f.write('Hello World\n') f.write('Testing\n') # Seek back to beginning and read the data f.seek(0) data = f.read()# Temporary file is destroyed TemporaryFile() 的第一个参数是文件模式，通常来讲文本模式使用 w+t ，二进制模式使用 w+b 。 这个模式同时支持读和写操作，在这里是很有用的，因为当你关闭文件去改变模式的时候，文件实际上已经不存在了。 TemporaryFile() 另外还支持跟内置的 open() 函数一样的参数。 12with TemporaryFile('w+t', encoding='utf-8', errors='ignore') as f: ... 为了创建一个临时目录，可以使用 tempfile.TemporaryDirectory() 。 1234567from tempfile import TemporaryDirectorywith TemporaryDirectory() as dirname: print('dirname is:', dirname) # Use the directory ...# Directory and all contents destroyed pickle 序列化Python对象 12345678910import pickleclass person(): def __init__(self, age): self.age = agedata = person(12)f = open('data_file', 'wb')pickle.dump(data, f) 如果要将对象转为字符串，可以使用 pickle.dumps() 12s = pickle.dumps(data)print(s) 为了从字节流中恢复一个对象，使用 pickle.load() 或 pickle.loads() 函数。 123456# Restore from a filef = open('somefile', 'rb')data = pickle.load(f)# Restore from a stringdata = pickle.loads(s) 对于大多数应用程序来讲，dump() 和 load() 函数的使用就是你有效使用 pickle 模块所需的全部了。 它可适用于绝大部分Python数据类型和用户自定义类的对象实例。 如果你碰到某个库可以让你在数据库中保存/恢复Python对象或者是通过网络传输对象的话， 那么很有可能这个库的底层就使用了 pickle 模块。 pickle 是一种Python特有的自描述的数据编码。 通过自描述，被序列化后的数据包含每个对象开始和结束以及它的类型信息。 因此，你无需担心对象记录的定义，它总是能工作。 当数据反序列化回来的时候，会先假定所有的源数据时可用的。 模块、类和函数会自动按需导入进来。对于Python数据被不同机器上的解析器所共享的应用程序而言， 数据的保存可能会有问题，因为所有的机器都必须访问同一个源代码。 千万不要对不信任的数据使用pickle.load()。pickle在加载时有一个副作用就是它会自动加载相应模块并构造实例对象。但是某个坏人如果知道pickle的工作原理，他就可以创建一个恶意的数据导致Python执行随意指定的系统命令。因此，一定要保证pickle只在相互之间可以认证对方的解析器的内部使用。 有些类型的对象是不能被序列化的。这些通常是那些依赖外部系统状态的对象， 比如打开的文件，网络连接，线程，进程，栈帧等等。 用户自定义类可以通过提供 __getstate__() 和 __setstate__() 方法来绕过这些限制。 如果定义了这两个方法，pickle.dump() 就会调用 __getstate__() 获取序列化的对象。 类似的，__setstate__() 在反序列化时被调用。 pickle 对于大型的数据结构比如使用 array 或 numpy 模块创建的二进制数组效率并不是一个高效的编码方式。 如果你需要移动大量的数组数据，你最好是先在一个文件中将其保存为数组数据块或使用更高级的标准编码方式如HDF5 (需要第三方库的支持)。 由于 pickle 是Python特有的并且附着在源码上，所有如果需要长期存储数据的时候不应该选用它。 例如，如果源码变动了，你所有的存储数据可能会被破坏并且变得不可读取。 坦白来讲，对于在数据库和存档文件中存储数据时，你最好使用更加标准的数据编码格式如XML，CSV或JSON。 这些编码格式更标准，可以被不同的语言支持，并且也能很好的适应源码变更。 最后一点要注意的是 pickle 有大量的配置选项和一些棘手的问题。 对于最常见的使用场景，你不需要去担心这个，但是如果你要在一个重要的程序中使用pickle去做序列化的话， 最好去查阅一下 官方文档 。 数据编码和处理csv 读写CSV数据 csv 文件可以看成是逗号分隔文件（逗号分隔值文件格式），里面的数据会以纯文本形式存储表格数据（数字和文本）。当然也不一定要用逗号，也可以用别的字符进行分隔。 1234567Symbol,Price,Date,Time,Change,Volume&quot;AA&quot;,39.48,&quot;6/11/2007&quot;,&quot;9:36am&quot;,-0.18,181800&quot;AIG&quot;,71.38,&quot;6/11/2007&quot;,&quot;9:36am&quot;,-0.15,195500&quot;AXP&quot;,62.58,&quot;6/11/2007&quot;,&quot;9:36am&quot;,-0.46,935000&quot;BA&quot;,98.31,&quot;6/11/2007&quot;,&quot;9:36am&quot;,+0.12,104800&quot;C&quot;,53.08,&quot;6/11/2007&quot;,&quot;9:36am&quot;,-0.25,360900&quot;CAT&quot;,78.29,&quot;6/11/2007&quot;,&quot;9:36am&quot;,-0.23,225400 通过csv模块，可以将csv文件逐行读取。 12345678import csvwith open('csv_file.csv') as f: f_csv = csv.reader(f) headers = next(f_csv) print(headers) for row in f_csv: print(row) 但是为了更好的理解所获得值，可以使用namedtuple的方式，使用命名元组的形式。 1234567891011import csvfrom collections import namedtuplewith open('csv_file.csv') as f: f_csv = csv.reader(f) headers = next(f_csv) Row = namedtuple('Row', headers) print(headers) for r in f_csv: row = Row(*r) print(row) 它允许你使用列名如 row.Symbol 和 row.Change 代替下标访问。 需要注意的是这个只有在列名是合法的Python标识符的时候才生效。如果不是的话， 你可能需要修改下原始的列名(如将非标识符字符替换成下划线之类的)。 另外一个选择就是将数据读取到一个字典序列中去。 12345import csvwith open('csv_file.csv') as f: f_csv = csv.DictReader(f) for row in f_csv: print(row['Price']) 这样就可以直接使用字典的名字去访问字段。例如：row[&#39;Symbol&#39;] 或者 row[&#39;Change&#39;] 如果要写入，也可以直接使用这个模块。 不过这时候先创建一个 writer 对象。 12345678910headers = ['Symbol','Price','Date','Time','Change','Volume']rows = [('AA', 39.48, '6/11/2007', '9:36am', -0.18, 181800), ('AIG', 71.38, '6/11/2007', '9:36am', -0.15, 195500), ('AXP', 62.58, '6/11/2007', '9:36am', -0.46, 935000), ]with open('stocks.csv','w') as f: f_csv = csv.writer(f) f_csv.writerow(headers) f_csv.writerows(rows) 如果有一个字典序列的数据，可以直接使用csv.DictWriter 12345678910111213headers = ['Symbol', 'Price', 'Date', 'Time', 'Change', 'Volume']rows = [&#123;'Symbol':'AA', 'Price':39.48, 'Date':'6/11/2007', 'Time':'9:36am', 'Change':-0.18, 'Volume':181800&#125;, &#123;'Symbol':'AIG', 'Price': 71.38, 'Date':'6/11/2007', 'Time':'9:36am', 'Change':-0.15, 'Volume': 195500&#125;, &#123;'Symbol':'AXP', 'Price': 62.58, 'Date':'6/11/2007', 'Time':'9:36am', 'Change':-0.46, 'Volume': 935000&#125;, ]with open('stocks.csv','w') as f: f_csv = csv.DictWriter(f, headers) f_csv.writeheader() f_csv.writerows(rows) 默认情况下，csv 库可识别Microsoft Excel所使用的CSV编码规则。 这或许也是最常见的形式，并且也会给你带来最好的兼容性。 然而，如果你查看csv的文档，就会发现有很多种方法将它应用到其他编码格式上(如修改分割字符等)。 123456# Example of reading tab-separated valueswith open('stock.tsv') as f: f_tsv = csv.reader(f, delimiter='\t') for row in f_tsv: # Process row ... 最后，如果你读取CSV数据的目的是做数据分析和统计的话， 你可能需要看一看 Pandas 包。Pandas 包含了一个非常方便的函数叫 pandas.read_csv() ， 它可以加载CSV数据到一个 DataFrame 对象中去。 然后利用这个对象你就可以生成各种形式的统计、过滤数据以及执行其他高级操作了。 读写JSON数据 读写JSON数据 json.dumps() 和 json.loads() 处理字符串的转换。 1234567891011import jsondata = &#123; 'name' : 'ACME', 'shares' : 100, 'price' : 542.23&#125;json_str = json.dumps(data)data = json.loads(json_str) json.dump() 和 json.load() 处理文件。 1234567# Writing JSON datawith open('data.json', 'w') as f: json.dump(data, f)# Reading data backwith open('data.json', 'r') as f: data = json.load(f) JSON编码支持的基本数据类型为 None ， bool ， int ， float 和 str ， 以及包含这些类型数据的lists，tuples和dictionaries。 对于dictionaries，keys需要是字符串类型(字典中任何非字符串类型的key在编码时会先转换为字符串)。 为了遵循JSON规范，你应该只编码Python的lists和dictionaries。 而且，在web应用程序中，顶层对象被编码为一个字典是一个标准做法。 JSON编码的格式对于Python语法而已几乎是完全一样的，除了一些小的差异之外。 比如，True会被映射为true，False被映射为false，而None会被映射为null。 如果你试着去检查JSON解码后的数据，你通常很难通过简单的打印来确定它的结构， 特别是当数据的嵌套结构层次很深或者包含大量的字段时。 为了解决这个问题，可以考虑使用pprint模块的 pprint() 函数来代替普通的 print() 函数。 它会按照key的字母顺序并以一种更加美观的方式输出。 1234567891011121314151617181920212223242526272829303132&gt;&gt;&gt; from urllib.request import urlopen&gt;&gt;&gt; import json&gt;&gt;&gt; u = urlopen('http://search.twitter.com/search.json?q=python&amp;rpp=5')&gt;&gt;&gt; resp = json.loads(u.read().decode('utf-8'))&gt;&gt;&gt; from pprint import pprint&gt;&gt;&gt; pprint(resp)&#123;'completed_in': 0.074,'max_id': 264043230692245504,'max_id_str': '264043230692245504','next_page': '?page=2&amp;max_id=264043230692245504&amp;q=python&amp;rpp=5','page': 1,'query': 'python','refresh_url': '?since_id=264043230692245504&amp;q=python','results': [&#123;'created_at': 'Thu, 01 Nov 2012 16:36:26 +0000', 'from_user': ... &#125;, &#123;'created_at': 'Thu, 01 Nov 2012 16:36:14 +0000', 'from_user': ... &#125;, &#123;'created_at': 'Thu, 01 Nov 2012 16:36:13 +0000', 'from_user': ... &#125;, &#123;'created_at': 'Thu, 01 Nov 2012 16:36:07 +0000', 'from_user': ... &#125; &#123;'created_at': 'Thu, 01 Nov 2012 16:36:04 +0000', 'from_user': ... &#125;],'results_per_page': 5,'since_id': 0,'since_id_str': '0'&#125;&gt;&gt;&gt; 一般来讲，JSON解码会根据提供的数据创建dicts或lists。 如果你想要创建其他类型的对象，可以给 json.loads() 传递object_pairs_hook或object_hook参数。 例如，下面是演示如何解码JSON数据并在一个OrderedDict中保留其顺序的例子： 123456&gt;&gt;&gt; s = '&#123;"name": "ACME", "shares": 50, "price": 490.1&#125;'&gt;&gt;&gt; from collections import OrderedDict&gt;&gt;&gt; data = json.loads(s, object_pairs_hook=OrderedDict)&gt;&gt;&gt; dataOrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])&gt;&gt;&gt; 将一个JSON字典转换为一个Python对象 12345678910111213&gt;&gt;&gt; class JSONObject:... def __init__(self, d):... self.__dict__ = d...&gt;&gt;&gt;&gt;&gt;&gt; data = json.loads(s, object_hook=JSONObject)&gt;&gt;&gt; data.name'ACME'&gt;&gt;&gt; data.shares50&gt;&gt;&gt; data.price490.1&gt;&gt;&gt; 在编码JSON的时候，还有一些选项很有用。 如果你想获得漂亮的格式化字符串后输出，可以使用 json.dumps() 的indent参数。 它会使得输出和pprint()函数效果类似。 123456789&gt;&gt;&gt; print(json.dumps(data))&#123;"price": 542.23, "name": "ACME", "shares": 100&#125;&gt;&gt;&gt; print(json.dumps(data, indent=4))&#123; "price": 542.23, "name": "ACME", "shares": 100&#125;&gt;&gt;&gt; 一般来说，对象实例通常并不是JSON可序列化的。但是，可以提供一个函数，它的输入是一个实例，返回一个可序列化的字典。 1234def serialize_instance(obj): d = &#123; '__classname__' : type(obj).__name__ &#125; d.update(vars(obj)) return d 如果你想反过来获取这个实例，可以这样做： 123456789101112131415# Dictionary mapping names to known classesclasses = &#123; 'Point' : Point&#125;def unserialize_object(d): clsname = d.pop('__classname__', None) if clsname: cls = classes[clsname] obj = cls.__new__(cls) # Make instance without calling __init__ for key, value in d.items(): setattr(obj, key, value) return obj else: return d 使用 123456789101112&gt;&gt;&gt; p = Point(2,3)&gt;&gt;&gt; s = json.dumps(p, default=serialize_instance)&gt;&gt;&gt; s'&#123;"__classname__": "Point", "y": 3, "x": 2&#125;'&gt;&gt;&gt; a = json.loads(s, object_hook=unserialize_object)&gt;&gt;&gt; a&lt;__main__.Point object at 0x1017577d0&gt;&gt;&gt;&gt; a.x2&gt;&gt;&gt; a.y3&gt;&gt;&gt; xml.etree.ElementTree 解析简单的XML数据 1234567891011121314151617from urllib.request import urlopenfrom xml.etree.ElementTree import parse# Download the RSS feed and parse itu = urlopen('http://planet.python.org/rss20.xml')doc = parse(u)# Extract and output tags of interestfor item in doc.iterfind('channel/item'): title = item.findtext('title') date = item.findtext('pubDate') link = item.findtext('link') print(title) print(date) print(link) print() xml.etree.ElementTree.parse() 函数解析整个XML文档并将其转换成一个文档对象。 然后，你就能使用 find() 、iterfind() 和 findtext() 等方法来搜索特定的XML元素了。 这些函数的参数就是某个指定的标签名，例如 channel/item 或 title 。 每次指定某个标签时，你需要遍历整个文档结构。每次搜索操作会从一个起始元素开始进行。 同样，每次操作所指定的标签名也是起始元素的相对路径。 例如，执行 doc.iterfind(&#39;channel/item&#39;) 来搜索所有在 channel 元素下面的 item 元素。 doc 代表文档的最顶层(也就是第一级的 rss 元素)。 然后接下来的调用 item.findtext() 会从已找到的 item 元素位置开始搜索。 ElementTree 模块中的每个元素有一些重要的属性和方法，在解析的时候非常有用。 tag 属性包含了标签的名字，text 属性包含了内部的文本，而 get() 方法能获取属性值。 增量式解析大型XML文件 1234567891011121314151617181920212223from xml.etree.ElementTree import iterparsedef parse_and_remove(filename, path): path_parts = path.split('/') doc = iterparse(filename, ('start', 'end')) # Skip the root element next(doc) tag_stack = [] elem_stack = [] for event, elem in doc: if event == 'start': tag_stack.append(elem.tag) elem_stack.append(elem) elif event == 'end': if tag_stack == path_parts: yield elem elem_stack[-2].remove(elem) try: tag_stack.pop() elem_stack.pop() except IndexError: pass 这一节的技术会依赖 ElementTree 模块中的两个核心功能。 第一，iterparse() 方法允许对XML文档进行增量操作。 使用时，你需要提供文件名和一个包含下面一种或多种类型的事件列表： start , end, start-ns 和 end-ns 。 由 iterparse() 创建的迭代器会产生形如 (event, elem) 的元组， 其中 event 是上述事件列表中的某一个，而 elem 是相应的XML元素。 123456789pothole_by_zip = Counter()doc = parse('potholes.xml')for pothole in doc.iterfind('row/row'): pothole_by_zip[pothole.findtext('zip')] += 1for zipcode, num in pothole_by_zip.most_common(): print(zipcode, num) 使用这个方式的话（doc.iterfind），会将xml文件一次性全部读取出来，先将整个XML文件加载到内存中然后解析，这样会大量使用内存的资源。 1234567data = parse_and_remove('potholes.xml', 'row/row')for pothole in data: pothole_by_zip[pothole.findtext('zip')] += 1for zipcode, num in pothole_by_zip.most_common(): print(zipcode, num) 这里调用了上面的函数 ，在队列中的保存找到的tag，之后在获得需要的标签后，就将结果返回，同时将结果删除（就是删除掉对应的标签），这样就能保证内存不会溢出，能保证系统在占用很小的内存的时候就能找到所需要的数据。 start 事件在某个元素第一次被创建并且还没有被插入其他数据(如子元素)时被创建。 而 end 事件在某个元素已经完成时被创建。 尽管没有在例子中演示， start-ns 和 end-ns 事件被用来处理XML文档命名空间的声明。 start 和 end 事件被用来管理元素和标签栈。 栈代表了文档被解析时的层次结构， 还被用来判断某个元素是否匹配传给函数 parse_and_remove() 的路径。 如果匹配，就利用 yield 语句向调用者返回这个元素。 比较这两个版本，可以看出，第一个全部读取完的版本会比较占用内存，不过在效率上能得到很大的提高，如果更加注重内存的消耗，应该优先选择第二个版本，采用增量式的方式获得需要的节点。 将字典转换为XML 12345678910111213141516171819202122232425262728from xml.etree.ElementTree import Elementfrom xml.etree.ElementTree import tostringdef dict_to_xlm(tag, d): elem = Element(tag) for key, val in d.items(): child = Element(key) child.text = str(val) elem.append(child) return elems = &#123; 'name': 'GGO', 'status': 100, 'count': 12&#125;e = dict_to_xlm('stock', s)print(e)# &lt;Element 'stock' at 0x10400eb88&gt;string_stocks = tostring(e)print(string_stocks)# b'&lt;stock&gt;&lt;name&gt;GGO&lt;/name&gt;&lt;status&gt;100&lt;/status&gt;&lt;count&gt;12&lt;/count&gt;&lt;/stock&gt;'e.set('_id', '123456')string_stocks = tostring(e)print(string_stocks)# b'&lt;stock _id="123456"&gt;&lt;name&gt;GGO&lt;/name&gt;&lt;status&gt;100&lt;/status&gt;&lt;count&gt;12&lt;/count&gt;&lt;/stock&gt;' 通过Element可以将元素设置为tag，之后用child.text的方法设置该标签的内容，这样就能获得一个Element元素，之后通过tostring函数，将Element转为字符串。 也可以通过set函数为某个元素添加属性值。 如果传入的内容中有特殊字符，会自动进行转译，例如：字符 ‘&lt;’ 和 ‘&gt;’ 被替换成了 &amp;lt; 和 &amp;gt;。 如果你需要手动去转换这些字符， 可以使用 xml.sax.saxutils 中的 escape() 和 unescape() 函数。 123456&gt;&gt;&gt; from xml.sax.saxutils import escape, unescape&gt;&gt;&gt; escape('&lt;spam&gt;')'&amp;lt;spam&amp;gt;'&gt;&gt;&gt; unescape(_)'&lt;spam&gt;'&gt;&gt;&gt; 解析和修改XML 利用命名空间解析XML文档 与关系型数据库的交互SQL语句字符串的构造。 你千万不要使用Python字符串格式化操作符(如%)或者 .format() 方法来创建这样的字符串。 如果传递给这些格式化操作符的值来自于用户的输入，那么你的程序就很有可能遭受SQL注入攻击(参考 http://xkcd.com/327 )。 查询语句中的通配符 ? 指示后台数据库使用它自己的字符串替换机制，这样更加的安全。 不幸的是，不同的数据库后台对于通配符的使用是不一样的。大部分模块使用 ? 或 %s ， 还有其他一些使用了不同的符号，比如:0或:1来指示参数。 同样的，你还是得去参考你使用的数据库模块相应的文档。 一个数据库模块的 paramstyle 属性包含了参数引用风格的信息。 base64 编码和解码十六进制数 编码解码Base64数据 简单的解码或编码一个十六进制的原始字符串 1234567891011121314151617import base64s = b'hello'h = base64.b16encode(s)print(h)# b'68656C6C6F'b = base64.b64encode(s)print(b)# b'aGVsbG8='n = base64.b16decode(h)print(n)# b'hello'm = base64.b64decode(b)print(m)# b'hello' 读取嵌套和可变长二进制数据二进制数据文件处理 pandas对于任何涉及到统计、时间序列以及其他相关技术的数据分析问题，都可以考虑使用 Pandas库 。 Pandas是一个拥有很多特性的大型函数库，我在这里不可能介绍完。 但是只要你需要去分析大型数据集合、对数据分组、计算各种统计量或其他类似任务的话，这个函数库真的值得你去看一看。 函数接受任意数量参数的函接收任意参数用*， 接收任意关键字参数用** 一个参数只能出现在函数定义中最后一个位置参数后面，而 **参数只能出现在最后一个参数。 有一点要注意的是，在参数后面仍然可以定义其他参数。 12345def a(x, *args, y): passdef b(x, *args, y, **kwargs): pass 只接受关键字参数的函数 将强制关键字参数放到某个*参数或者单个*后面就能达到这种效果。 123456def recv(maxsize, *, block): 'Receives a message' passrecv(1024, True) # TypeErrorrecv(1024, block=True) # Ok 我们可以在接受任意参数的函数中接受指定的关键字参数。 12345678def mininum(*values, clip=None): m = min(values) if clip is not None: m = clip if clip &gt; m else m return mminimum(1, 5, 2, -5, 10) # Returns -5minimum(1, 5, 2, -5, 10, clip=0) # Returns 0 很多情况下，使用强制关键字参数会比使用位置参数表意更加清晰，程序也更加具有可读性。 这样在使用help的时候也会使得函数更容易理解。 123456help(recv)"""Help on function recv in module __main__:recv(maxsize, *, block)""" 给函数参数增加元信息12def add(x:int, y:int) -&gt; int: return x + y python解释器不会对这些注解添加任何的语义。它们不会被类型检查，运行时跟没有加注解之前的效果也没有任何差距。 然而，对于那些阅读源码的人来讲就很有帮助啦。第三方工具和框架可能会对这些注解添加语义。同时它们也会出现在文档中。 尽管你可以使用任意类型的对象给函数添加注解(例如数字，字符串，对象实例等等)，不过通常来讲使用类或者字符串会比较好点。 函数注解只存储在函数的 __annotations__ 属性中。 12print(adda.__annotations__)# &#123;'x': &lt;class 'int'&gt;, 'y': &lt;class 'int'&gt;, 'return': &lt;class 'int'&gt;&#125; 尽管注解的使用方法可能有很多种，但是它们的主要用途还是文档。 因为python并没有类型声明，通常来讲仅仅通过阅读源码很难知道应该传递什么样的参数给这个函数。 这时候使用注解就能给程序员更多的提示，让他们可以正确的使用函数。 定义有默认参数的函数 定义有默认参数的函数 默认参数的值仅仅在函数定义的时候赋值一次。 12345678910x = 42def spam(a, b=x): print(a, b)spam(1)# 1 42x = 12spam(1)# 1 42 注意到当我们改变x的值的时候对默认参数值并没有影响，这是因为在函数定义的时候就已经确定了它的默认值了。 默认参数的值应该是不可变的对象，比如None、True、False、数字或字符串。 注意在使用默认参数，使用None作为默认，并且对参数进行None判断的时候，应该使用is not None之类的，而不应该直接使用not b，尽管None值确实是被当成False， 但是还有其他的对象(比如长度为0的字符串、列表、元组、字典等)都会被当做False。 因此，上面的代码会误将一些其他输入也当成是没有输入。 最后一个问题比较微妙，那就是一个函数需要测试某个可选参数是否被使用者传递进来。 这时候需要小心的是你不能用某个默认值比如None、 0或者False值来测试用户提供的值(因为这些值都是合法的值，是可能被用户传递进来的)。 因此，你需要其他的解决方案了。 为了解决这个问题，你可以创建一个独一无二的私有对象实例，就像上面的_no_value变量那样。 在函数里面，你可以通过检查被传递参数值跟这个实例是否一样来判断。 这里的思路是用户不可能去传递这个_no_value实例作为输入。 因此，这里通过检查这个值就能确定某个参数是否被传递进来了。 这里对 object() 的使用看上去有点不太常见。object 是python中所有类的基类。 你可以创建 object 类的实例，但是这些实例没什么实际用处，因为它并没有任何有用的方法， 也没有任何实例数据(因为它没有任何的实例字典，你甚至都不能设置任何属性值)。 你唯一能做的就是测试同一性。这个刚好符合我的要求，因为我在函数中就只是需要一个同一性的测试而已。 lambda表达式123add = lambda x, y: x+yprint(add(1, 6))# 7 lambda表达式典型的使用场景是排序或数据reduce等。 尽管lambda表达式允许你定义简单函数，但是它的使用是有限制的。 你只能指定单个表达式，它的值就是最后的返回值。也就是说不能包含其他的语言特性了， 包括多个语句、条件表达式、迭代以及异常处理等等。 你可以不使用lambda表达式就能编写大部分python代码。 但是，当有人编写大量计算表达式值的短小函数或者需要用户提供回调函数的程序的时候， 你就会看到lambda表达式的身影了。 12345678910x = 10a = lambda y: x + yprint(a(10))# 20x = 20b = lambda y: x + yprint(a(10))# 30print(b(10))# 30 这其中的奥妙在于lambda表达式中的x是一个自由变量， 在运行时绑定值，而不是定义时就绑定，这跟函数的默认值参数定义是不同的。 因此，在调用这个lambda表达式的时候，x的值是执行时的值。 1234567&gt;&gt;&gt; x = 15&gt;&gt;&gt; a(10)25&gt;&gt;&gt; x = 3&gt;&gt;&gt; a(10)13&gt;&gt;&gt; 如果需要在定义的时候就将变量x固定下来，就可以在定义lambda的时候使用x=x的方式。 12345678&gt;&gt;&gt; x = 10&gt;&gt;&gt; a = lambda y, x=x: x + y&gt;&gt;&gt; x = 20&gt;&gt;&gt; b = lambda y, x=x: x + y&gt;&gt;&gt; a(10)20&gt;&gt;&gt; b(10)30 如果需要在一开始的时候时候就开始使用所规定的值，就应该一开始就定义，不然在使用的时候就有可能在使用的时候，由于变量的改变，导致函数的变化，导致与期望的值不相符。 1234567891011funcs = [lambda x: x+n for n in range(5)]for i in funcs: print(i(0), end=' ') # 4 4 4 4 4 print()funcs1 = [lambda x, n=n: x+n for n in range(5)]for i in funcs1: print(i(0), end=' ') # 0 1 2 3 4 使用的时候，第一种的n就只会保留最后一次的4，所以输出的时候都是4。 functools.partial 减少可调用对象的参数个数 partial() 函数允许你给一个或多个参数设置固定的值，减少接下来被调用时的参数个数。 12345678910111213141516171819&gt;&gt;&gt; from functools import partial&gt;&gt;&gt; s1 = partial(spam, 1) # a = 1&gt;&gt;&gt; s1(2, 3, 4)1 2 3 4&gt;&gt;&gt; s1(4, 5, 6)1 4 5 6&gt;&gt;&gt; s2 = partial(spam, d=42) # d = 42&gt;&gt;&gt; s2(1, 2, 3)1 2 3 42&gt;&gt;&gt; s2(4, 5, 5)4 5 5 42&gt;&gt;&gt; s3 = partial(spam, 1, 2, d=42) # a = 1, b = 2, d = 42&gt;&gt;&gt; s3(3)1 2 3 42&gt;&gt;&gt; s3(4)1 2 4 42&gt;&gt;&gt; s3(5)1 2 5 42&gt;&gt;&gt; 此外有很多功能看文档。 将单方法的类转换为函数 将单方法的类转换为函数 你有一个除 __init__() 方法外只定义了一个方法的类。为了简化代码，你想将它转换成一个函数。 大多数情况下，可以使用闭包来将单个方法的类转换成函数。 12345678910111213from urllib.request import urlopenclass UrlTemplate: def __init__(self, template): self.template = template def open(self, **kwargs): return urlopen(self.template.format_map(kwargs))# Example use. Download stock data from yahooyahoo = UrlTemplate('http://finance.yahoo.com/d/quotes.csv?s=&#123;names&#125;&amp;f=&#123;fields&#125;')for line in yahoo.open(names='IBM,AAPL,FB', fields='sl1c1v'): print(line.decode('utf-8')) 这个类可以被函数直接代替。 123456789def urltemplate(template): def opener(**kwargs): return urlopen(template.format_map(kwargs)) return opener# Example useyahoo = urltemplate('http://finance.yahoo.com/d/quotes.csv?s=&#123;names&#125;&amp;f=&#123;fields&#125;')for line in yahoo(names='IBM,AAPL,FB', fields='sl1c1v'): print(line.decode('utf-8')) 大部分情况下，你拥有一个单方法类的原因是需要存储某些额外的状态来给方法使用。 比如，定义UrlTemplate类的唯一目的就是先在某个地方存储模板值，以便将来可以在open()方法中使用。 使用一个内部函数或者闭包的方案通常会更优雅一些。简单来讲，一个闭包就是一个函数， 只不过在函数内部带上了一个额外的变量环境。闭包关键特点就是它会记住自己被定义时的环境。 因此，在我们的解决方案中，opener() 函数记住了 template 参数的值，并在接下来的调用中使用它。 任何时候只要你碰到需要给某个函数增加额外的状态信息的问题，都可以考虑使用闭包。 相比将你的函数转换成一个类而言，闭包通常是一种更加简洁和优雅的方案。 带额外状态信息的回调函数 带额外状态信息的回调函数 12345678910111213141516171819def apply_async(func, args, *, callback): # Compute the result result = func(*args) # Invoke the callback with the result callback(result)def print_result(result): print('Got: ', result)def add(a, b): return a + bapply_async(add, (2, 3), callback=print_result)# Got: 5apply_async(add, ('hello ', 'word'), callback=print_result)# Got: hello word 注意到 print_result() 函数仅仅只接受一个参数 result 。不能再传入其他信息。 而当你想让回调函数访问其他变量或者特定环境的变量值的时候就会遇到麻烦。 为了让回调函数访问外部信息，一种方法是使用一个绑定方法来代替一个简单函数。 12345678class ResultHandler: def __init__(self): self.sequence = 0 def handler(self, result): self.sequence += 1 print('[&#123;&#125;] Got: &#123;&#125;'.format(self.sequence, result)) 使用这个类的时候，你先创建一个类的实例，然后用它的 handler() 绑定方法来做为回调函数：123456&gt;&gt;&gt; r = ResultHandler()&gt;&gt;&gt; apply_async(add, (2, 3), callback=r.handler)[1] Got: 5&gt;&gt;&gt; apply_async(add, ('hello', 'world'), callback=r.handler)[2] Got: helloworld&gt;&gt;&gt; 第二种方式，作为类的替代，可以使用一个闭包捕获状态值。 1234567def make_handler(): sequence = 0 def handler(result): nonlocal sequence sequence += 1 print('[&#123;&#125;] Got: &#123;&#125;'.format(sequence, result)) return handler 使用闭包的例子： 123456&gt;&gt;&gt; handler = make_handler()&gt;&gt;&gt; apply_async(add, (2, 3), callback=handler)[1] Got: 5&gt;&gt;&gt; apply_async(add, ('hello', 'world'), callback=handler)[2] Got: helloworld&gt;&gt;&gt; 或者使用协程的方式： 1234567891011121314def make_handler(): sequence = 0 while True: result = yield sequence += 1 print('[&#123;&#125;] Got; &#123;&#125;'.format(sequence, result))handler = make_handler()next(handler)apply_async(add, (2, 3), callback=handler.send)# [1] Got; 5apply_async(add, ('lalala ', 'hehehe'), callback=handler.send)# [2] Got; lalala hehehe 基于回调函数的软件通常都有可能变得非常复杂。一部分原因是回调函数通常会跟请求执行代码断开。 因此，请求执行和处理结果之间的执行环境实际上已经丢失了。如果你想让回调函数连续执行多步操作， 那你就必须去解决如何保存和恢复相关的状态信息了。 至少有两种主要方式来捕获和保存状态信息，你可以在一个对象实例(通过一个绑定方法)或者在一个闭包中保存它。 两种方式相比，闭包或许是更加轻量级和自然一点，因为它们可以很简单的通过函数来构造。 它们还能自动捕获所有被使用到的变量。因此，你无需去担心如何去存储额外的状态信息(代码中自动判定)。 如果使用闭包，你需要注意对那些可修改变量的操作。在上面的方案中， nonlocal 声明语句用来指示接下来的变量会在回调函数中被修改。如果没有这个声明，代码会报错。 python知识 什么是非局部语句 而使用一个协程来作为一个回调函数就更有趣了，它跟闭包方法密切相关。 某种意义上来讲，它显得更加简洁，因为总共就一个函数而已。 并且，你可以很自由的修改变量而无需去使用 nonlocal 声明。 这种方式唯一缺点就是相对于其他Python技术而言或许比较难以理解。 另外还有一些比较难懂的部分，比如使用之前需要调用 next() ，实际使用时这个步骤很容易被忘记。 尽管如此，协程还有其他用处，比如作为一个内联回调函数的定义。 内联回调函数 内联回调函数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051from queue import Queuefrom functools import wrapsdef apply_async(func, args, *, callback): # Compute the result result = func(*args) # Invoke the callback with the result callback(result)class Async: def __init__(self, func, args): self.func = func self.args = argsdef inlined_async(func): @wraps(func) def wrapper(*args): f = func(*args) result_queue = Queue() result_queue.put(None) while True: result = result_queue.get() try: a = f.send(result) apply_async(a.func, a.args, callback=result_queue.put) except StopIteration: break return wrapperdef add(a, b): return a+b@inlined_asyncdef lala_test(): r = yield Async(add, (2, 3)) print(r) r = yield Async(add, ('hello', 'world')) print(r) for n in range(10): r = yield Async(add, (n, n)) print(r) print('Goodbye')if __name__ == '__main__': lala_test() 首先，在需要使用到回调的代码中，关键点在于当前计算工作会挂起并在将来的某个时候重启(比如异步执行)。 当计算重启时，回调函数被调用来继续处理结果。apply_async() 函数演示了执行回调的实际逻辑， 尽管实际情况中它可能会更加复杂(包括线程、进程、事件处理器等等)。 计算的暂停与重启思路跟生成器函数的执行模型不谋而合。 具体来讲，yield 操作会使一个生成器函数产生一个值并暂停。 接下来调用生成器的 __next__() 或 send() 方法又会让它从暂停处继续执行。 根据这个思路，这一小节的核心就在 inline_async() 装饰器函数中了。 关键点就是，装饰器会逐步遍历生成器函数的所有 yield 语句，每一次一个。 为了这样做，刚开始的时候创建了一个 result 队列并向里面放入一个 None 值。 然后开始一个循环操作，从队列中取出结果值并发送给生成器，它会持续到下一个 yield 语句， 在这里一个 Async 的实例被接受到。然后循环开始检查函数和参数，并开始进行异步计算 apply_async() 。 然而，这个计算有个最诡异部分是它并没有使用一个普通的回调函数，而是用队列的 put() 方法来回调。 主循环立即返回顶部并在队列上执行 get() 操作。 如果数据存在，它一定是 put() 回调存放的结果。如果没有数据，那么先暂停操作并等待结果的到来。 这个具体怎样实现是由 apply_async() 函数来决定的。 访问闭包中定义的变量 类与对象让对象支持上下文管理协议为了让一个对象兼容 with 语句，你需要实现 __enter__() 和 __exit__() 方法。 一个网络连接的例子： 1234567891011121314151617181920212223242526272829303132from socket import socket, AF_INET, SOCK_STREAMfrom functools import partialclass LazyConnection: def __init__(self, address, family=AF_INET, type=SOCK_STREAM): self.address = address self.family = family self.type = type self.sock = None def __enter__(self): if self.sock is not None: raise RuntimeError('Already connected') self.sock = socket(self.family, self.type) self.sock.connect(self.address) return self.sock def __exit__(self, exc_ty, exc_val, tb): self.sock.close() self.sock = Noneconn = LazyConnection(('www.python.org', 80))# Connection closedwith conn as s: # conn.__enter__() executes: connection open s.send(b'GET /index.html HTTP/1.0\r\n') s.send(b'Host: www.python.org\r\n') s.send(b'\r\n') resp = b''.join(iter(partial(s.recv, 8192), b'')) # conn.__exit__() executes: connection closed 编写上下文管理器的主要原理是你的代码会放到 with 语句块中执行。 当出现 with 语句的时候，对象的 __enter__() 方法被触发， 它返回的值(如果有的话)会被赋值给 as 声明的变量。然后，with 语句块里面的代码开始执行。 最后，__exit__() 方法被触发进行清理工作。 不管 with 代码块中发生什么，上面的控制流都会执行完，就算代码块中发生了异常也是一样的。 事实上，__exit__() 方法的第三个参数包含了异常类型、异常值和追溯信息(如果有的话)。 __exit__() 方法能自己决定怎样利用这个异常信息，或者忽略它并返回一个None值。 如果 __exit__() 返回 True ，那么异常会被清空，就好像什么都没发生一样， with 语句后面的程序继续在正常执行。 在需要管理一些资源比如文件、网络连接和锁的编程环境中，使用上下文管理器是很普遍的。 这些资源的一个主要特征是它们必须被手动的关闭或释放来确保程序的正确运行。 例如，如果你请求了一个锁，那么你必须确保之后释放了它，否则就可能产生死锁。 通过实现 __enter__() 和 __exit__() 方法并使用 with 语句可以很容易的避免这些问题， 因为 __exit__() 方法可以让你无需担心这些了。 slots主要是用来当成简单的数据结构的类而言，你可以通过给类添加 __slots__ 属性来极大的减少实例所占的内存。 1234567class Date: __slots__ = ['year', 'month', 'day'] def __init__(self, year, month, day): self.year = year self.month = month self.day = day 当你定义 __slots__ 后，Python就会为实例使用一种更加紧凑的内部表示。 实例通过一个很小的固定大小的数组来构建，而不是为每个实例定义一个字典，这跟元组或列表很类似。 在 __slots__ 中列出的属性名在内部被映射到这个数组的指定小标上。 使用slots一个不好的地方就是我们不能再给实例添加新的属性了，只能使用在 __slots__ 中定义的那些属性名。 使用slots后节省的内存会跟存储属性的数量和类型有关。 不过，一般来讲，使用到的内存总量和将数据存储在一个元组中差不多。 为了给你一个直观认识，假设你不使用slots直接存储一个Date实例， 在64位的Python上面要占用428字节，而如果使用了slots，内存占用下降到156字节。 如果程序中需要同时创建大量的日期实例，那么这个就能极大的减小内存使用量了。 尽管slots看上去是一个很有用的特性，很多时候你还是得减少对它的使用冲动。 Python的很多特性都依赖于普通的基于字典的实现。 另外，定义了slots后的类不再支持一些普通类特性了，比如多继承。 大多数情况下，你应该只在那些经常被使用到的用作数据结构的类上定义slots (比如在程序中需要创建某个类的几百万个实例对象)。 关于 __slots__ 的一个常见误区是它可以作为一个封装工具来防止用户给实例增加新的属性。 尽管使用slots可以达到这样的目的，但是这个并不是它的初衷。 __slots__ 更多的是用来作为一个内存优化工具。 在类中封装属性名 在类中封装属性名 大多数而言，你应该让你的非公共名称以单下划线开头。但是，如果你清楚你的代码会涉及到子类， 并且有些内部属性应该在子类中隐藏起来，那么才考虑使用双下划线方案。 创建可管理的属性 创建可管理的属性 1234567891011121314151617181920class Person: def __init__(self, first_name): self.first_name = first_name # Getter function @property def first_name(self): return self._first_name # Setter function @first_name.setter def first_name(self, value): if not isinstance(value, str): raise TypeError('Expected a string') self._first_name = value # Deleter function (optional) @first_name.deleter def first_name(self): raise AttributeError("Can't delete attribute") 上述代码中有三个相关联的方法，这三个方法的名字都必须一样。 第一个方法是一个 getter 函数，它使得 first_name 成为一个属性。 其他两个方法给 first_name 属性添加了 setter 和 deleter 函数。 需要强调的是只有在 first_name 属性被创建后， 后面的两个装饰器 @first_name.setter 和 @first_name.deleter 才能被定义。 在实现一个property的时候，底层数据(如果有的话)仍然需要存储在某个地方。 因此，在get和set方法中，你会看到对 _first_name 属性的操作，这也是实际数据保存的地方。 另外，你可能还会问为什么 __init__() 方法中设置了 self.first_name 而不是 self._first_name 。 在这个例子中，我们创建一个property的目的就是在设置attribute的时候进行检查。 因此，你可能想在初始化的时候也进行这种类型检查。通过设置 self.first_name ，自动调用 setter 方法， 这个方法里面会进行参数的检查，否则就是直接访问 self._first_name 了。 Properties还是一种定义动态计算attribute的方法。 这种类型的attributes并不会被实际的存储，而是在需要的时候计算出来。 类的继承对于你定义的每一个类，Python会计算出一个所谓的方法解析顺序(MRO)列表。 这个MRO列表就是一个简单的所有基类的线性顺序表。 12345678910111213141516171819202122class Base: def __init__(self): print('Base.__init__')class A(Base): def __init__(self): super().__init__() print('A.__init__')class B(Base): def __init__(self): super().__init__() print('B.__init__')class C(A,B): def __init__(self): super().__init__() # Only one call to super() here print('C.__init__')# c = C()print(C.__mro__)# (&lt;class '__main__.C'&gt;, &lt;class '__main__.A'&gt;, &lt;class '__main__.B'&gt;, &lt;class '__main__.Base'&gt;, &lt;class 'object'&gt;) 为了实现继承，Python会在MRO列表上从左到右开始查找基类，直到找到第一个匹配这个属性的类为止。 而这个MRO列表的构造是通过一个C3线性化算法来实现的。 它实际上就是合并所有父类的MRO列表并遵循如下三条准则： 子类会先于父类被检查 多个父类会根据它们在列表中的顺序被检查 如果对下一个类存在两个合法的选择，选择第一个父类 老实说，你所要知道的就是MRO列表中的类顺序会让你定义的任意类层级关系变得有意义。 当你使用 super() 函数时，Python会在MRO列表上继续搜索下一个类。 只要每个重定义的方法统一使用 super() 并只调用它一次， 那么控制流最终会遍历完整个MRO列表，每个方法也只会被调用一次。 子类中扩展property 在子类中扩展父类的功能，需要函数前面加上装饰器。 123456789101112131415class SubPerson(Person): @property def name(self): print('Getting name') return super(SubPerson, self).name @name.setter def name(self, value): print('Setting name') super(SubPerson, SubPerson).name.__set__(self, value) @name.deleter def name(self): print('Deleting name') super(SubPerson, SubPerson).name.__delete__(self) 如果只是扩展其中的一个方法： 123456789101112class SubPerson1(Person): @Person.name.getter def name(self): print('Lalala') return super().nameclass SubPerson(Person): @Person.name.setter def name(self, value): print('Setting name to', value) super(SubPerson, SubPerson).name.__set__(self, value) 在子类中扩展一个property可能会引起很多不易察觉的问题， 因为一个property其实是 getter、setter 和 deleter 方法的集合，而不是单个方法。 因此，当你扩展一个property的时候，你需要先确定你是否要重新定义所有的方法还是说只修改其中某一个。 在第一个例子中，所有的property方法都被重新定义。 在每一个方法中，使用了 super() 来调用父类的实现。 在 setter 函数中使用 super(SubPerson, SubPerson).name.__set__(self, value) 的语句是没有错的。 为了委托给之前定义的setter方法，需要将控制权传递给之前定义的name属性的 __set__() 方法。 不过，获取这个方法的唯一途径是使用类变量而不是实例变量来访问它。 这也是为什么我们要使用 super(SubPerson, SubPerson) 的原因。 Python: super 没那么简单 创建新的类或实例属性 创建新的类或实例属性 1234567891011121314151617class Integer: def __init__(self, name): self.name = name def __get__(self, instance, cls): if instance is None: return self else: return instance.__dict__[self.name] def __set__(self, instance, value): if not isinstance(value, int): raise TypeError('Expected an int') instance.__dict__[self.name] = value def __delete__(self, instance): del instance.__dict__[self.name] 一个描述器就是一个实现了三个核心的属性访问操作(get, set, delete)的类， 分别为 __get__() 、__set__() 和 __delete__() 这三个特殊的方法。 这些方法接受一个实例作为输入，之后相应的操作实例底层的字典。 1234567class Point: x = Integer('x') y = Integer('y') def __init__(self, x, y): self.x = x self.y = y 描述器可实现大部分Python类特性中的底层魔法， 包括 @classmethod 、@staticmethod 、@property ，甚至是 __slots__ 特性。 通过定义一个描述器，你可以在底层捕获核心的实例操作(get, set, delete)，并且可完全自定义它们的行为。 这是一个强大的工具，有了它你可以实现很多高级功能，并且它也是很多高级库和框架中的重要工具之一。 描述器的一个比较困惑的地方是它只能在类级别被定义，而不能为每个实例单独定义。 使用延迟计算属性你想将一个只读属性定义成一个property，并且只在访问的时候才会计算结果。 但是一旦被访问后，你希望结果值被缓存起来，不用每次都去计算。 123456789101112131415161718192021222324252627282930313233343536373839404142434445import mathclass lazyproperty: def __init__(self, func): self.func = func def __get__(self, instance, owner): if instance is None: return self else: value = self.func(instance) setattr(instance, self.func.__name__, value) # 设置属性值 return valueclass Circle: def __init__(self, radius): self.radius = radius @lazyproperty def area(self): print('Computing area') return math.pi * self.radius ** 2 @lazyproperty def perimeter(self): print('Computing permeter') return 2 * math.pi * self.radiusc = Circle(4.0)print(c.radius)# 4.0print(c.area)# Computing area# 50.26548245743669print(c.area)# 50.26548245743669print(c.perimeter)# Computing permeter# 25.132741228718345print(c.perimeter)# 25.132741228718345 Computing area 和 Computing perimeter 仅仅出现一次。 很多时候，构造一个延迟计算属性的主要目的是为了提升性能。 例如，你可以避免计算这些属性值，除非你真的需要它们。 这里演示的方案就是用来实现这样的效果的， 只不过它是通过以非常高效的方式使用描述器的一个精妙特性来达到这种效果的。 当一个描述器被放入一个类的定义时， 每次访问属性时它的 __get__() 、__set__() 和 __delete__() 方法就会被触发。 不过，如果一个描述器仅仅只定义了一个 __get__() 方法的话，它比通常的具有更弱的绑定。 特别地，只有当被访问属性不在实例底层的字典中时 __get__() 方法才会被触发。 lazyproperty 类利用这一点，使用 __get__() 方法在实例中存储计算出来的值， 这个实例使用相同的名字作为它的property。 这样一来，结果值被存储在实例字典中并且以后就不需要再去计算这个property了。 简化数据结构的初始化 简化数据结构的初始化 写一个公共的类，定义__init__方法，之后的类继承该类。 1234567891011121314151617181920212223242526import mathclass Structure1: # Class variable that specifies expected fields _fields = [] def __init__(self, *args): if len(args) != len(self._fields): raise TypeError('Expected &#123;&#125; arguments'.format(len(self._fields))) # Set the arguments for name, value in zip(self._fields, args): setattr(self, name, value)# Example class definitionsclass Stock(Structure1): _fields = ['name', 'shares', 'price']class Point(Structure1): _fields = ['x', 'y']class Circle(Structure1): _fields = ['radius'] def area(self): return math.pi * self.radius ** 2 abc定义接口或者抽象基类 1234567891011from abc import ABCMeta, abstractmethodclass IStream(metaclass=ABCMeta): @abstractmethod def read(self, maxbytes=-1): pass @abstractmethod def write(self, data): pass 抽象基类的一个主要用途是在代码中检查某些类是否为特定类型，实现了特定接口。 尽管ABCs可以让我们很方便的做类型检查，但是我们在代码中最好不要过多的使用它。 因为Python的本质是一门动态编程语言，其目的就是给你更多灵活性， 强制类型检查或让你代码变得更复杂，这样做无异于舍本求末。 实现数据模型的类型约束 实现数据模型的类型约束 定义某些在属性赋值上面有限制的数据结构。 collectionscollections 定义了很多抽象基类，当你想自定义容器类的时候它们会非常有用。 实现自定义容器 functools.total_ordering 让类支持比较操作 让某个类的实例支持标准的比较运算(比如&gt;=,!=,&lt;=,&lt;等)，但是又不想去实现那一大丢的特殊方法。 装饰器 functools.total_ordering 就是用来简化这个处理的。 使用它来装饰一个来，你只需定义一个 __eq__() 方法， 外加其他方法(__lt__, __le__, __gt__, or __ge__)中的一个即可。 然后装饰器会自动为你填充其它比较方法。 123456789101112131415161718192021222324252627282930313233from functools import total_orderingclass Room: def __init__(self, name, length, width): self.name = name self.length = length self.width = width self.square_feet = self.length * self.width@total_orderingclass House: def __init__(self, name, style): self.name = name self.style = style self.rooms = list() @property def living_space_footage(self): return sum(r.square_feet for r in self.rooms) def add_room(self, room): self.rooms.append(room) def __str__(self): return '&#123;&#125;: &#123;&#125; square foot &#123;&#125;'.format(self.name, self.living_space_footage, self.style) def __eq__(self, other): return self.living_space_footage == other.living_space_footage def __lt__(self, other): return self.living_space_footage &lt; other.living_space_footage 元编程 深入浅出Python装饰器 wraps 简单聊聊Python中的wraps修饰器 简单的说，就是使得我们自定的修饰起函数的一些函数属性更加符合我们的预期。 在我们使用函数的类似于 __doc__ 和 __name__ 等，需要获得函数的一些属性的时候，如果直接使用，就会输出修饰函数的信息： 12345678910111213def wrapper(f): def wrapper_function(*args, **kwargs): """这个是修饰函数""" return f(*args, **kwargs) return wrapper_function@wrapperdef wrapped(): """这个是被修饰的函数""" print('wrapped')print(wrapped.__doc__) # 输出`这个是修饰函数`print(wrapped.__name__) # 输出`wrapper_function` 这并不符合我们的预期，我们应该想知道的是 wrapped 的信息才对，所以就需要 wraps 修饰器，将原本 wrapped 的信息复制到 wrapper 中，从源码中也可以发现，源码中使用了 partial 和 update_wrapper 这两个函数，其中 update_wrapper 就是将信息复制使用的，而 partial 是填充 update_wrapper 的。 任何时候你定义装饰器的时候，都应该使用 functools 库中的 @wraps 装饰器来注解底层包装函数。 装饰器（修饰器） 在函数上添加包装器 使用修饰器，增加额外的操作，如日志，计时等。 12345678910111213141516171819202122232425import timefrom functools import wrapsdef timethis(func): @wraps(func) def wrapper(*args, **kwargs): start = time.time() result = func(*args, **kwargs) end = time.time() print(func.__name__, end-start) return result return wrapper@timethisdef countdown(n): while n &gt; 0: n -= 1countdown(1000000)# countdown 0.09182381629943848countdown(9999999)# countdown 0.823084831237793 一个装饰器就是一个函数，它接受一个函数作为参数并返回一个新的函数。 123@timethisdef countdown(n): pass 和下面的效果等同。 123def countdown(n): passcountdown = timethis(countdown) python 自带的一些装饰器也是同样的道理。 在上面的 wrapper() 函数中， 装饰器内部定义了一个使用 *args 和 **kwargs 来接受任意参数的函数。 在这个函数里面调用了原始函数并将其结果返回，不过你还可以添加其他额外的代码(比如计时)。 然后这个新的函数包装器被作为结果返回来代替原始函数。 需要强调的是装饰器并不会修改原始函数的参数签名以及返回值。 使用 *args 和 **kwargs 目的就是确保任何参数都能适用。 而返回结果值基本都是调用原始函数 func(*args, **kwargs) 的返回结果，其中func就是原始函数。 定义一个带参数的装饰器 定义一个带参数的装饰器 定义了多个包裹的函数，最外层的函数负责接收参数，里面的两层负责接收函数，对函数进行处理。 12345678910111213141516171819202122232425262728from functools import wrapsimport loggingdef logged(level, name=None, message=None): def decorate(func): logname = name if name else func.__module__ log = logging.getLogger(logname) logmsg = message if message else func.__name__ @wraps(func) def wrapper(*args, **kwargs): log.log(level, logmsg) return func(*args, **kwargs) return wrapper return decorate@logged(logging.DEBUG)def add(x: int, y: int) -&gt; int: return x+y@logged(logging.CRITICAL, 'example')def spam(): print('Spam!')print(add(1, 2)) 最外层的函数 logged() 接受参数并将它们作用在内部的装饰器函数上面。 内层的函数 decorate() 接受一个函数作为参数，然后在函数上面放置一个包装器。 这里的关键点是包装器是可以使用传递给 logged() 的参数的。 简单的说可以概括为： 123@decorator(x, y, z)def func(a, b): pass 可以等价为下面： 123def func(a, b): passfunc = decorator(x, y, z)(func) decorator(x, y, z) 的返回结果必须是一个可调用对象，它接受一个函数作为参数并包装它。 可自定义属性的装饰器12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758from functools import wraps, partialimport logginglogging.basicConfig(level=logging.DEBUG)def attach_wrapper(obj, func=None): if func is None: return partial(attach_wrapper, obj) setattr(obj, func.__name__, func) return funcdef logged(level, name=None, message=None): def decorate(func): logname = name if name else func.__module__ log = logging.getLogger(logname) logmsg = message if message else func.__name__ @wraps(func) def wrapper(*args, **kwargs): log.log(level, logmsg) return func(*args, **kwargs) @attach_wrapper(wrapper) def set_level(newlevle): nonlocal level level = newlevle @attach_wrapper(wrapper) def set_message(newmsg): nonlocal logmsg logmsg = newmsg return wrapper return decorate@logged(logging.DEBUG)def add(x: int, y: int) -&gt; int: return x+y@logged(logging.CRITICAL, 'example')def spam(): print('Spam!')add(1, 2)# DEBUG:__main__:addadd.set_message('add called')add(2, 3)# DEBUG:__main__:add calledadd.set_level(logging.WARNING)add(4, 5)# WARNING:__main__:add calledspam()# Spam!# CRITICAL:example:spam 其中，在函数 set_message() 和 set_level() 中，作为属性赋值给包装器，每个函数里面，允许使用 nonlocal 来访问上一层包裹的函数（闭包），修改函数内部的变量。 如果有多个装饰器，调用的顺序是从里到外调用，最先调用最里面的装饰器，最后调用最外层的装饰器： 12345@a@b@bdef f(): pass 等效于： 1f = a(b(c(f))) 带可选参数的装饰器自定义一个装饰器，可以选择接收参数，@decorator(x, y, z) ， 也可以选择不接收参数，直接 @decorator 。 12345678910111213141516171819202122232425262728293031from functools import wraps, partialimport logginglogging.basicConfig(level=logging.DEBUG)def logged(func=None, *, level=logging.DEBUG, name=None, message=None): if func is None: return partial(logged, level=level, name=name, message=message) logname = name if name else func.__module__ log = logging.getLogger(logname) logmsg = message if message else func.__name__ @wraps(func) def wrapper(*args, **kwargs): log.log(level, logmsg) return func(*args, **kwargs) return wrapper@loggeddef add(x, y): return x+y@logged(level=logging.DEBUG, name='example')def spam(): print('Spam !')add(1, 3)# DEBUG:__main__:addspam()# Spam !# DEBUG:example:spam 对于不加参数的装饰器的调用。 1234# Example use@loggeddef add(x, y): return x + y 上面的调用次序可以和下面的等同。 1234def add(x, y): return x + yadd = logged(add) 这时候，被装饰函数会被当做第一个参数直接传递给 logged 装饰器。 因此，logged() 中的第一个参数就是被包装函数本身。所有其他参数都必须有默认值。 而对于带有参数的装饰器的调用。 123@logged(level=logging.CRITICAL, name='example')def spam(): print('Spam!') 可以和下面的调用次序等同。 123def spam(): print('Spam!')spam = logged(level=logging.CRITICAL, name='example')(spam) 初始调用 logged() 函数时，被包装函数并没有传递进来。 因此在装饰器内，它必须是可选的。这个反过来会迫使其他参数必须使用关键字来指定。 并且，但这些参数被传递进来后，装饰器要返回一个接受一个函数参数并包装它的函数。 为了这样做，我们使用了一个技巧，就是利用 functools.partial 。 它会返回一个未完全初始化的自身，除了被包装函数外其他参数都已经确定下来了。 原本如果没有参数的时候，默认装饰器会将函数作为第一个参数传入，但是如果有参数的话，被包装的函数就没有传递进来，又因为使用了通配符的关系，后面的参数就全都需要关键字参数的形式传递进来，之后使用的 partial 函数，又将自身 logged 返回，使得又再一次调用自己的这个装饰器，只不过就带上了参数，返回自身。 利用装饰器强制函数上的类型检查作为函数的规范，希望在函数的参数上加上参数的类型检查。 一般来说，python 的设计思想是不需要类型检查的，这样不仅会增加代码量，而且也使得python哲学失去意义，站在python的角度来说，不需要对变量进行类型的设定，同样也不需要对变量进行类型检查，python 有很强的自省，如果有什么异常会直接抛出，它认定我们是已经长大的成人了，不需要对这些进行而外的限制，使得我们能更加关注于逻辑的开发，而不是把焦点放在不必要的类型检查，而这所有的前提就是我们能处理自己的错误，或者说不会乱搞。 有时候我们需要对参数进行检查的时候，我们可以写一个装饰器，对函数进行参数的检查。 1234567891011121314151617181920212223242526from inspect import signaturefrom functools import wrapsdef typeassert(*ty_args, **ty_kwargs): def decorate(func): # If in optimized mode, disable type checking if not __debug__: return func # Map function argument names to supplied types sig = signature(func) bound_types = sig.bind_partial(*ty_args, **ty_kwargs).arguments @wraps(func) def wrapper(*args, **kwargs): bound_values = sig.bind(*args, **kwargs) # Enforce type assertions across supplied arguments for name, value in bound_values.arguments.items(): if name in bound_types: if not isinstance(value, bound_types[name]): raise TypeError( 'Argument &#123;&#125; must be &#123;&#125;'.format(name, bound_types[name]) ) return func(*args, **kwargs) return wrapper return decorate 使用的时候就按照正常的装饰器的调用。 123456789@typeassert(int, int)def add(x, y): return x+yif __name__ == '__main__': print(add(1, 4)) print(add('1233', 23)) 首先，装饰器只会在函数定义时被调用一次。 有时候你去掉装饰器的功能，那么你只需要简单的返回被装饰函数即可。 下面的代码中，如果全局变量 __debug__ 被设置成了False(当你使用-O或-OO参数的优化模式执行程序时)， 那么就直接返回未修改过的函数本身： 1234def decorate(func): # If in optimized mode, disable type checking if not __debug__: return func 其次，这里还对被包装函数的参数签名进行了检查，我们使用了 inspect.signature() 函数。 简单来讲，它运行你提取一个可调用对象的参数签名信息。 123456789101112131415from inspect import signaturedef spam(x, y, z=42): passsig = signature(spam)print(sig)# (x, y, z=42)print(sig.parameters)# OrderedDict([('x', &lt;Parameter "x"&gt;), ('y', &lt;Parameter "y"&gt;), ('z', &lt;Parameter "z=42"&gt;)])print(sig.parameters['z'].name)# zprint(sig.parameters['z'].default)# 42print(sig.parameters['z'].kind)# POSITIONAL_OR_KEYWORD 这个模块的功能主要是获得其他函数的参数信息。 装饰器的开始部分，我们使用了 bind_partial() 方法来执行从指定类型到名称的部分绑定。 下面是例子演示： 123456&gt;&gt;&gt; bound_types = sig.bind_partial(int,z=int)&gt;&gt;&gt; bound_types&lt;inspect.BoundArguments object at 0x10069bb50&gt;&gt;&gt;&gt; bound_types.argumentsOrderedDict([('x', &lt;class 'int'&gt;), ('z', &lt;class 'int'&gt;)])&gt;&gt;&gt; 在这个部分绑定中，你可以注意到缺失的参数被忽略了(比如并没有对y进行绑定)。 不过最重要的是创建了一个有序字典 bound_types.arguments 。 这个字典会将参数名以函数签名中相同顺序映射到指定的类型值上面去。 在我们的装饰器例子中，这个映射包含了我们要强制指定的类型断言。 在装饰器创建的实际包装函数中使用到了 sig.bind() 方法。 bind() 跟 bind_partial() 类似，但是它不允许忽略任何参数。因此有了下面的结果： 1234&gt;&gt;&gt; bound_values = sig.bind(1, 2, 3)&gt;&gt;&gt; bound_values.argumentsOrderedDict([('x', 1), ('y', 2), ('z', 3)])&gt;&gt;&gt; 综合来说 123456&gt;&gt;&gt; for name, value in bound_values.arguments.items():... if name in bound_types.arguments:... if not isinstance(value, bound_types.arguments[name]):... raise TypeError()...&gt;&gt;&gt; 不过对于一些有默认值的参数并不适用。 12345678910111213141516&gt;&gt;&gt; @typeassert(int, list)... def bar(x, items=None):... if items is None:... items = []... items.append(x)... return items&gt;&gt;&gt; bar(2)[2]&gt;&gt;&gt; bar(2,3)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "contract.py", line 33, in wrapperTypeError: Argument items must be &lt;class 'list'&gt;&gt;&gt;&gt; bar(4, [1, 2, 3])[1, 2, 3, 4]&gt;&gt;&gt; 使用元类控制实例的创建 使用元类控制实例的创建 通过改变实例创建方式来实现单例、缓存或其他类似的特性。 主要使用 __call__() 元类来操作，通过限制这个元类，来限制类的实例的创建。 123456789class NoInstances(type): def __call__(self, *args, **kwargs): raise TypeError("Can't instantiate directly")# Exampleclass Spam(metaclass=NoInstances): @staticmethod def grok(x): print('Spam.grok') 或者实现单例模式。 12345678910111213141516class Singleton(type): def __init__(self, *args, **kwargs): self.__instance = None super().__init__(*args, **kwargs) def __call__(self, *args, **kwargs): if self.__instance is None: self.__instance = super().__call__(*args, **kwargs) return self.__instance else: return self.__instance# Exampleclass Spam(metaclass=Singleton): def __init__(self): print('Creating Spam') 测试： 123456789&gt;&gt;&gt; a = Spam()Creating Spam&gt;&gt;&gt; b = Spam()&gt;&gt;&gt; a is bTrue&gt;&gt;&gt; c = Spam()&gt;&gt;&gt; a is cTrue&gt;&gt;&gt; 也可以创建弱引用的缓存实例。 1234567891011121314151617181920import weakrefclass Cached(type): def __init__(self, *args, **kwargs): super().__init__(*args, **kwargs) self.__cache = weakref.WeakValueDictionary() def __call__(self, *args): if args in self.__cache: return self.__cache[args] else: obj = super().__call__(*args) self.__cache[args] = obj return obj# Exampleclass Spam(metaclass=Cached): def __init__(self, name): print('Creating Spam(&#123;!r&#125;)'.format(name)) self.name = name 测试： 12345678910&gt;&gt;&gt; a = Spam('Guido')Creating Spam('Guido')&gt;&gt;&gt; b = Spam('Diana')Creating Spam('Diana')&gt;&gt;&gt; c = Spam('Guido') # Cached&gt;&gt;&gt; a is bFalse&gt;&gt;&gt; a is c # Cached value returnedTrue&gt;&gt;&gt; 如果没有使用元类的方式，也可以在全局里面定义变量保存类的实例，在写函数，全局引用这个实例，如果有这个对象的话，就返回这个对象本身，没有的话，就创建一个新的实例，赋值给变量。 定义有可选参数的元类定义一个元类，允许类定义时提供可选参数，这样可以控制或配置类型的创建过程。 1234567891011from abc import ABCMeta, abstractmethodclass IStream(metaclass=ABCMeta): @abstractmethod def reada(self, maxsize=None): pass @abstractmethod def write(self, data): pass 然而，在自定义元类中我们还可以提供其他的关键字参数。 12class Spam(metaclass=MyMeta, debug=True, synchronize=True): pass 为了使元类支持这些关键字参数，你必须确保在 __prepare__() , __new__() 和 __init__() 方法中 都使用强制关键字参数。 12345678910111213141516171819class MyMeta(type): # Optional @classmethod def __prepare__(cls, name, bases, *, debug=False, synchronize=False): # Custom processing pass return super().__prepare__(name, bases) # Required def __new__(cls, name, bases, ns, *, debug=False, synchronize=False): # Custom processing pass return super().__new__(cls, name, bases, ns) # Required def __init__(self, name, bases, ns, *, debug=False, synchronize=False): # Custom processing pass super().__init__(name, bases, ns) 给一个元类添加可选关键字参数需要你完全弄懂类创建的所有步骤， 因为这些参数会被传递给每一个相关的方法。 __prepare__() 方法在所有类定义开始执行前首先被调用，用来创建类命名空间。 通常来讲，这个方法只是简单的返回一个字典或其他映射对象。 __new__() 方法被用来实例化最终的类对象。它在类的主体被执行完后开始执行。 __init__() 方法最后被调用，用来执行其他的一些初始化工作。 当我们构造元类的时候，通常只需要定义一个 __new__() 或 __init__() 方法，但不是两个都定义。 但是，如果需要接受其他的关键字参数的话，这两个方法就要同时提供，并且都要提供对应的参数签名。 默认的 __prepare__() 方法接受任意的关键字参数，但是会忽略它们， 所以只有当这些额外的参数可能会影响到类命名空间的创建时你才需要去定义 __prepare__() 方法。 将这些属性定义为参数的好处在于它们不会污染类的名称空间， 这些属性仅仅只从属于类的创建阶段，而不是类中的语句执行阶段。 另外，它们在 __prepare__() 方法中是可以被访问的，因为这个方法会在所有类主体执行前被执行。 但是类变量只能在元类的 __new__() 和 __init__() 方法中可见。 inspect args和*kwargs的强制参数签名 你有一个函数或方法，它使用args和*kwargs作为参数，这样使得它比较通用， 但有时候你想检查传递进来的参数是不是某个你想要的类型。 对任何涉及到操作函数调用签名的问题，你都应该使用 inspect 模块中的签名特性。 我们最主要关注两个类：Signature 和 Parameter 。 123456789101112from inspect import Signature, Parameterparms = [ Parameter('x', Parameter.POSITIONAL_OR_KEYWORD), Parameter('y', Parameter.POSITIONAL_OR_KEYWORD, default=42), Parameter('z', Parameter.KEYWORD_ONLY, default=None)]sig = Signature(parms)print(sig)# (x, y=42, *, z=None) 一旦你有了一个签名对象，你就可以使用它的 bind() 方法很容易的将它绑定到 *args 和 **kwargs 上去。 123456789def func(*args, **kwargs): bound_values = sig.bind(*args, **kwargs) for name, value in bound_values.arguments.items(): print(name, value)func(1, 2, z=3)# x 1# y 2# z 3 可以看出来，通过将签名和传递的参数绑定起来，可以强制函数调用遵循特定的规则，比如必填、默认、重复等等。 一个例子： 1234567891011121314151617181920from inspect import Signature, Parameterdef make_sig(*names): parms = [Parameter(name, Parameter.POSITIONAL_OR_KEYWORD) for name in names] return Signature(parms)class Structure: __signature__ = make_sig() def __init__(self, *args, **kwargs): bound_values = self.__signature__.bind(*args, **kwargs) for name, value in bound_values.arguments.items(): setattr(self, name, value)# Example useclass Stock(Structure): __signature__ = make_sig('name', 'shares', 'price')class Point(Structure): __signature__ = make_sig('x', 'y') 测试： 12345678910111213&gt;&gt;&gt; import inspect&gt;&gt;&gt; print(inspect.signature(Stock))(name, shares, price)&gt;&gt;&gt; s1 = Stock('ACME', 100, 490.1)&gt;&gt;&gt; s2 = Stock('ACME', 100)Traceback (most recent call last):...TypeError: 'price' parameter lacking default value&gt;&gt;&gt; s3 = Stock('ACME', 100, 490.1, shares=50)Traceback (most recent call last):...TypeError: multiple values for argument 'shares'&gt;&gt;&gt; types.new_class 以编程方式定义类 以字符串的方式去创建一个新的类。 123456789101112131415161718192021222324def __init__(self, name, shares, price): self.name = name self.shares = shares self.price = price def cost(self): return self.shares * self.pricecls_dict = &#123; '__init__' : __init__, 'cost' : cost,&#125;# Make a classimport typesStock = types.new_class('Stock', (), &#123;&#125;, lambda ns: ns.update(cls_dict))Stock.__module__ = __name__s = Stock('ACME', 50, 91.1)print(s)# &lt;__main__.Stock object at 0x10409af60&gt;print(s.cost())# 4555.0 这种方法中，一个比较难理解的地方是在调用完 types.new_class() 对 Stock.__module__ 的赋值。 每次当一个类被定义后，它的 __module__ 属性包含定义它的模块名。 这个名字用于生成 __repr__() 方法的输出。它同样也被用于很多库，比如 pickle 。 因此，为了让你创建的类是“正确”的，你需要确保这个属性也设置正确了。 new_class() 第四个参数最神秘，它是一个用来接受类命名空间的映射对象的函数。 通常这是一个普通的字典，但是它实际上是 __prepare__() 方法返回的任意对象。 避免重复的属性方法 避免重复的属性方法 当我们在类中有需要重复的去执行相同逻辑的操作，可以采用闭包的形式去简化代码。 123456789101112131415161718192021222324class Person: def __init__(self, name ,age): self.name = name self.age = age @property def name(self): return self._name @name.setter def name(self, value): if not isinstance(value, str): raise TypeError('name must be a string') self._name = value @property def age(self): return self._age @age.setter def age(self, value): if not isinstance(value, int): raise TypeError('age must be an int') self._age = value 如果有更多的变量的值的话，我们就需要写更多的代码，而这样是个不可取的。为此，我们可以采用闭包的形式，将有相似操作的内容都用闭包处理。 1234567891011121314151617181920212223def typed_property(name, expected_type): storage_name = '_' + name @property def prop(self): return getattr(self, storage_name) @prop.setter def prop(self, value): if not isinstance(value, expected_type): raise TypeError('&#123;&#125; must be a &#123;&#125;'.format(name, expected_type)) setattr(self, storage_name, value) return prop# Example useclass Person: name = typed_property('name', str) age = typed_property('age', int) def __init__(self, name, age): self.name = name self.age = age 例子中的函数 typed_property() 看上去有点难理解，其实它所做的仅仅就是为你生成属性并返回这个属性对象。 因此，当在一个类中使用它的时候，效果跟将它里面的代码放到类定义中去是一样的。 尽管属性的 getter 和 setter 方法访问了本地变量如 name , expected_type 以及 storate_name ，这个很正常，这些变量的值会保存在闭包当中。 ast 解析与分析Python源码 ast 模块能被用来将Python源码编译成一个可被分析的抽象语法树（AST）。 1234567891011121314151617181920&gt;&gt;&gt; import ast&gt;&gt;&gt; ex = ast.parse('2 + 3*4 + x', mode='eval')&gt;&gt;&gt; ex&lt;_ast.Expression object at 0x1007473d0&gt;&gt;&gt;&gt; ast.dump(ex)"Expression(body=BinOp(left=BinOp(left=Num(n=2), op=Add(),right=BinOp(left=Num(n=3), op=Mult(), right=Num(n=4))), op=Add(),right=Name(id='x', ctx=Load())))"&gt;&gt;&gt; top = ast.parse('for i in range(10): print(i)', mode='exec')&gt;&gt;&gt; top&lt;_ast.Module object at 0x100747390&gt;&gt;&gt;&gt; ast.dump(top)"Module(body=[For(target=Name(id='i', ctx=Store()),iter=Call(func=Name(id='range', ctx=Load()), args=[Num(n=10)],keywords=[], starargs=None, kwargs=None),body=[Expr(value=Call(func=Name(id='print', ctx=Load()),args=[Name(id='i', ctx=Load())], keywords=[], starargs=None,kwargs=None))], orelse=[])])"&gt;&gt;&gt; 模块与包__all__如果定义了 __all__ , 那么只有被列举出的东西会被导出。 如果你将 __all__ 定义成一个空列表, 没有东西将被导入。 如果 __all__ 包含未定义的名字, 在导入时引起AttributeError。 12345678910# somemodule.pydef spam(): passdef grok(): passblah = 42# Only export 'spam' and 'grok'__all__ = ['spam', 'grok'] 将模块分割成多个文件 将模块分割成多个文件 想将一个模块分割成多个文件。但是你不想将分离的文件统一成一个逻辑模块时使已有的代码遭到破坏。 一个类似于这样的文件，可以尝试将一个模块分为两个类，方便对不同内容的功能分开管理。 12345678# mymodule.pyclass A: def spam(self): print('A.spam')class B(A): def bar(self): print('B.bar') 这时候需要将这两个类（A和B）分成两个文件，并且需要在 python 模块中将这两个文件的内容导入。 首先用mymodule目录来替换文件mymodule.py。 这这个目录下，创建以下文件： 1234mymodule/ __init__.py a.py b.py 最后，在 init.py 中，将2个文件粘合在一起： 123# __init__.pyfrom .a import Afrom .b import B 有时候，如果需要导入的模块很大的话，我们就可以考虑延时导入，对于一些很大的模块，我们可以在需要的时候才导入所需要的模块。 __init__.py文件一次导入所有必需的组件的。但是对于一个很大的模块，可能你只想组件在需要时被加载。 要做到这一点，__init__.py有细微的变化： 12345678# __init__.pydef A(): from .a import A return A()def B(): from .b import B return B() 在这个版本中，类A和类B被替换为在第一次访问时加载所需的类的函数。对于用户，这看起来不会有太大的不同。 12345&gt;&gt;&gt; import mymodule&gt;&gt;&gt; a = mymodule.A()&gt;&gt;&gt; a.spam()A.spam&gt;&gt;&gt; 延迟加载的主要缺点是继承和类型检查可能会中断。 12345if isinstance(x, mymodule.A): # Error...if isinstance(x, mymodule.a.A): # Ok... 利用命名空间导入目录分散的代码你可能有大量的代码，由不同的人来分散地维护。每个部分被组织为文件目录，如一个包。然而，你希望能用共同的包前缀将所有组件连接起来，不是将每一个部分作为独立的包来安装。 从本质上讲，你要定义一个顶级Python包，作为一个大集合分开维护子包的命名空间。这个问题经常出现在大的应用框架中，框架开发者希望鼓励用户发布插件或附加包。 在统一不同的目录里统一相同的命名空间，但是要删去用来将组件联合起来的__init__.py文件。假设你有Python代码的两个不同的目录如下： 1234567foo-package/ spam/ blah.pybar-package/ spam/ grok.py 在这2个目录里，都有着共同的命名空间spam。在任何一个目录里都没有__init__.py文件。 我们可以在另外的文件中导入所需。 1234import syssys.path.extend(['foo-package', 'bar-package'])import spam.blahimport spam.grok 在这里工作的机制被称为“包命名空间”的一个特征。从本质上讲，包命名空间是一种特殊的封装设计，为合并不同的目录的代码到一个共同的命名空间。对于大的框架，这可能是有用的，因为它允许一个框架的部分被单独地安装下载。它也使人们能够轻松地为这样的框架编写第三方附加组件和其他扩展。 包命名空间的关键是确保顶级目录中没有__init__.py文件来作为共同的命名空间。缺失__init__.py文件使得在导入包的时候会发生有趣的事情：这并没有产生错误，解释器创建了一个由所有包含匹配包名的目录组成的列表。特殊的包命名空间模块被创建，只读的目录列表副本被存储在其__path__变量中。 12345678import syssys.path.extend(['foo-package', 'bar-package'])# import spam.blah# import spam.grokimport spamprint(spam.__path__)# _NamespacePath(['foo-package/spam', 'bar-package/spam']) 一个包是否被作为一个包命名空间的主要方法是检查其__file__属性。如果没有，那包是个命名空间。这也可以由其字符表现形式中的“namespace”这个词体现出来。 12print(spam)# &lt;module 'spam' (namespace)&gt; __main__ 运行目录或压缩文件 您有一个已成长为包含多个文件的应用，它已远不再是一个简单的脚本，你想向用户提供一些简单的方法运行这个程序。 如果你的应用程序已经有多个文件，你可以把你的应用程序放进它自己的目录并添加一个__main__.py文件。 12345myapplication/ spam.py bar.py grok.py __main__.py 如果__main__.py存在，就可以简单地在顶级目录运行Python解释器： 1bash % python3 myapplication importlib.import_module 通过字符串名导入模块 使用importlib.import_module()函数来手动导入名字为字符串给出的一个模块或者包的一部分。 1234567&gt;&gt;&gt; import importlib&gt;&gt;&gt; math = importlib.import_module(&apos;math&apos;)&gt;&gt;&gt; math.sin(2)0.9092974268256817&gt;&gt;&gt; mod = importlib.import_module(&apos;urllib.request&apos;)&gt;&gt;&gt; u = mod.urlopen(&apos;http://www.python.org&apos;)&gt;&gt;&gt; import_module只是简单地执行和import相同的步骤，但是返回生成的模块对象。你只需要将其存储在一个变量，然后像正常的模块一样使用。 如果你正在使用的包，import_module()也可用于相对导入。但是，你需要给它一个额外的参数。 123import importlib# Same as &apos;from . import b&apos;b = importlib.import_module(&apos;.b&apos;, __package__) 使用import_module()手动导入模块的问题通常出现在以某种方式编写修改或覆盖模块的代码时候。例如，也许你正在执行某种自定义导入机制，需要通过名称来加载一个模块，通过补丁加载代码。 在旧的代码，有时你会看到用于导入的内建函数__import__()。尽管它能工作，但是importlib.import_module() 通常更容易使用。 安装私有的包安装一个包，只是提供给自己使用，而不是系统上的所有用户使用。 Python有一个用户安装目录，通常类似”~/.local/lib/python3.3/site-packages”。 要强制在这个目录中安装包，可使用安装选项“–user”。 1python3 setup.py install --user 或者 1pip install --user packagename pyvenv使用 pyvenv 命令创建一个新的“虚拟”环境。 这个命令被安装在Python解释器同一目录，或Windows上面的Scripts目录中。 12bash % pyvenv Spambash % 这个解释器的特点就是他的site-packages目录被设置为新创建的环境。 如果你要安装第三方包，它们会被安装在那里，而不是通常系统的site-packages目录。 创建虚拟环境通常是为了安装和管理第三方包。 正如你在例子中看到的那样，sys.path 变量包含来自于系统Python的目录， 而 site-packages目录已经被重定位到一个新的目录。 有了一个新的虚拟环境，下一步就是安装一个包管理器，比如distribute或pip。 但安装这样的工具和包的时候，你需要确保你使用的是虚拟环境的解释器。 它会将包安装到新创建的site-packages目录中去。 尽管一个虚拟环境看上去是Python安装的一个复制， 不过它实际上只包含了少量几个文件和一些符号链接。 所有标准库函文件和可执行解释器都来自原来的Python安装。 因此，创建这样的环境是很容易的，并且几乎不会消耗机器资源。 默认情况下，虚拟环境是空的，不包含任何额外的第三方库。如果你想将一个已经安装的包作为虚拟环境的一部分， 可以使用“–system-site-packages”选项来创建虚拟环境，例如： 12bash % pyvenv --system-site-packages Spambash % 网络与Web编程urllib.request 作为客户端与HTTP服务交互 发送一个简单的HTTP GET请求到远程的服务上。 1234567891011121314151617from urllib import request, parse# Base URL being accessedurl = 'http://httpbin.org/get'# Dictionary of query parameters (if any)parms = &#123; 'name1' : 'value1', 'name2' : 'value2'&#125;# Encode the query stringquerystring = parse.urlencode(parms)# Make a GET request and read the responseu = request.urlopen(url+'?' + querystring)resp = u.read() 使用POST方法在请求主体中发送查询参数，可以将参数编码后作为可选参数提供给 urlopen() 函数。 1234567891011121314151617from urllib import request, parse# Base URL being accessedurl = 'http://httpbin.org/post'# Dictionary of query parameters (if any)parms = &#123; 'name1' : 'value1', 'name2' : 'value2'&#125;# Encode the query stringquerystring = parse.urlencode(parms)# Make a POST request and read the responseu = request.urlopen(url, querystring.encode('ascii'))resp = u.read() 如果你需要在发出的请求中提供一些自定义的HTTP头，例如修改 user-agent 字段,可以创建一个包含字段值的字典，并创建一个Request实例然后将其传给 urlopen() 。 1234567891011121314from urllib import request, parse...# Extra headersheaders = &#123; 'User-agent' : 'none/ofyourbusiness', 'Spam' : 'Eggs'&#125;req = request.Request(url, querystring.encode('ascii'), headers=headers)# Make a request and read the responseu = request.urlopen(req)resp = u.read() 使用 requests 库。 123456789101112131415161718192021import requests# Base URL being accessedurl = 'http://httpbin.org/post'# Dictionary of query parameters (if any)parms = &#123; 'name1' : 'value1', 'name2' : 'value2'&#125;# Extra headersheaders = &#123; 'User-agent' : 'none/ofyourbusiness', 'Spam' : 'Eggs'&#125;resp = requests.post(url, data=parms, headers=headers)# Decoded text returned by the requesttext = resp.text get 请求 12345import requestsurl = 'http://gank.io/api/xiandu/categories'resp = requests.get(url)print(resp.text) 关于requests库，一个值得一提的特性就是它能以多种方式从请求中返回响应结果的内容。从上面的代码来看， resp.text 带给我们的是以Unicode解码的响应文本。但是，如果去访问 resp.content ，就会得到原始的二进制数据。另一方面，如果访问 resp.json ，那么就会得到JSON格式的响应内容。 网络与web创建TCP服务器12345678910111213141516from socketserver import BaseRequestHandler, TCPServerclass EchoHandler(BaseRequestHandler): def handle(self): print('Got connection from', self.client_address) while True: msg = self.request.recv(8192) if not msg: break self.request.send(msg)if __name__ == '__main__': serv = TCPServer(('', 20000), EchoHandler) serv.serve_forever() 定义了一个特殊的处理类，实现了一个 handle() 方法，用来为客户端连接服务。 request 属性是客户端socket，client_address 有客户端地址。 1234567891011121314Last login: Tue Jun 19 10:07:25 on ttys001JaelynLim:~ Jaelyn$ pythonPython 2.7.11 (v2.7.11:6d1b6a68f775, Dec 5 2015, 12:54:16) [GCC 4.2.1 (Apple Inc. build 5666) (dot 3)] on darwinType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; from socket import socket&gt;&gt;&gt; from socket import AF_INET, SOCK_STREAM&gt;&gt;&gt; s = socket(AF_INET, SOCK_STREAM)&gt;&gt;&gt; s.connect((&apos;localhost&apos;, 20000))&gt;&gt;&gt; s.send(b&apos;Hello&apos;)5&gt;&gt;&gt; s.recv(8192)&apos;Hello&apos;&gt;&gt;&gt; 上面的代码进行访问测试，Got connection from (&#39;127.0.0.1&#39;, 53691) 。 socketserver 可以让我们很容易的创建简单的TCP服务器。 但是，你需要注意的是，默认情况下这种服务器是单线程的，一次只能为一个客户端连接服务。 如果你想处理多个客户端，可以初始化一个 ForkingTCPServer 或者是 ThreadingTCPServer 对象。 123456from socketserver import ThreadingTCPServerif __name__ == '__main__': serv = ThreadingTCPServer(('', 20000), EchoHandler) serv.serve_forever() Python Socket 编程详细介绍 python socket编程详细介绍 ipaddress 通过CIDR地址生成对应的IP地址集 12345678910111213import ipaddressnet = ipaddress.ip_network('123.45.67.64/27')print(net)# 123.45.67.64/27for a in net: print(a)# 123.45.67.64# 123.45.67.65# 123.45.67.66# 123.45.67.67# 123.45.67.68# ...... cgi 网关协议学习：CGI、FastCGI、WSGI 并发编程启动与停止线程12345678910111213import timedef countdown(n): while n &gt; 0: print('T-minus', n) n -= 1 time.sleep(2)from threading import Threadt = Thread(target=countdown, args=(10,), daemon=True)t.start()time.sleep(1)t.join()print('123123') 判断线程是否已经启动 判断线程是否已经启动 123456789101112131415161718192021from threading import Thread, Eventimport timedef countdown(n, started_evt): print('countdown starting') # started_evt.set() while n &gt; 0: print('T-mius', n) n -= 1 if n == 6: started_evt.set() time.sleep(5)started_evt = Event()print('launching countdown')t = Thread(target=countdown, args=(10, started_evt))t.start()started_evt.wait()print('countdown is runing') 当我们需要判断某个线程的状态，进而来进行不同的操作的时候，我们可以使用 Event() 事件来判断，这个对象有一个信号标志，开始为假，如果线程中需要等待一个 event 对象，而这个标志为假的话 ，就会一直等待。直到标志位为真，而标志位的设定，可以通过 set() 方法来设定，这将会唤醒所有等待这个对象的线程。如果遇到的 event 对象的标志位为真的话，会直接忽略，继续其他操作。 书籍原话： 线程的一个关键特性是每个线程都是独立运行且状态不可预测。如果程序中的其他线程需要通过判断某个线程的状态来确定自己下一步的操作，这时线程同步问题就会变得非常棘手。为了解决这些问题，我们需要使用 threading 库中的 Event 对象。 Event 对象包含一个可由线程设置的信号标志，它允许线程等待某些事件的发生。在初始情况下，event 对象中的信号标志被设置为假。如果有线程等待一个 event 对象，而这个 event 对象的标志为假，那么这个线程将会被一直阻塞直至该标志为真。一个线程如果将一个 event 对象的信号标志设置为真，它将唤醒所有等待这个 event 对象的线程。如果一个线程等待一个已经被设置为真的 event 对象，那么它将忽略这个事件，继续执行。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546from threading import Conditionimport threadingimport timeclass PeriodicTimer: def __init__(self, interval): self._initerval = interval self._flag = 0 self._cv = Condition() def start(self): t = threading.Thread(target=self.run) t.daemon = True t.start() def run(self): while True: time.sleep(self._initerval) with self._cv: self._flag ^= 1 self._cv.notify_all() def wait_for_tick(self): with self._cv: last_flag = self._flag while last_flag == self._flag: self._cv.wait()ptimer = PeriodicTimer(5)ptimer.start()def countdown(nticks): while nticks &gt; 0: ptimer.wait_for_tick() print('T-minus', nticks) nticks -= 1def countup(last): n = 0 while n &lt; last: ptimer.wait_for_tick() print('counting', n) n += 1threading.Thread(target=countdown, args=(10,)).start()threading.Thread(target=countup, args=(5,)).start() Condition 是处理多个线程同步的模块。具体要用再查资料去吧。 进程间通信 进程间通信 从一个线程向另一个线程发送数据最安全的方式可能就是使用 queue 库中的队列了。创建一个被多个线程共享的 Queue 对象，这些线程通过使用 put() 和 get() 操作来向队列中添加或者删除元素。 123456789101112131415161718192021222324from queue import Queuefrom threading import Thread# A thread that produces datadef producer(out_q): while True: # Produce some data ... out_q.put(data)# A thread that consumes datadef consumer(in_q): while True:# Get some data data = in_q.get() # Process the data ...# Create the shared queue and launch both threadsq = Queue()t1 = Thread(target=consumer, args=(q,))t2 = Thread(target=producer, args=(q,))t1.start()t2.start() Queue 对象已经包含了必要的锁，所以你可以通过它在多个线程间多安全地共享数据。 当使用队列时，协调生产者和消费者的关闭问题可能会有一些麻烦。一个通用的解决方法是在队列中放置一个特殊的值，当消费者读到这个值的时候，终止执行。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python3</tag>
        <tag>Python CookBook</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Supervisor 指令学习]]></title>
    <url>%2F2018%2F05%2F15%2Fsupervisor-learn%2F</url>
    <content type="text"><![CDATA[参考资料 * Python 进程管理工具 Supervisor 使用教程 Supervisor 使用简介 supervisor 安装、配置、常用命令 Supervisor重新加载配置启动新的进程 简介Supervisor 是一个进程管理工具，可以简单的进行进程的控制（启动，重启，停止等），可以设置网址，直接在浏览器上可视化的操作进程。 一般情况下，当我们需要以守护进程的方式启动某些进程的时候，例如后台任务（备份数据，同步数据，日志处理，消息推送等）和Web服务进程，经常被用来管理和启动一组Tornado进程实现负载均衡。 有两个重要的组成部分：supervisord和supervisorctl。 安装sudo pip install supervisor 创建配置文件这个命令可以将supervisor的默认配置输出到一个文件中，到时候直接在那上面修改会方便很多， echo_supervisord_conf &gt; /etc/supervisord.conf 箭头后面指向路径，如果出现没有权限的问题，可以使用这条命令 sudo su - root -c &quot;echo_supervisord_conf &gt; /etc/supervisord.conf&quot; 配置文件说明在默认的配置文件中，会将 supervisord.pid 以及 supervisor.sock 是放在 /tmp 目录下，但是 /tmp 目录是存放临时文件，里面的文件是会被 Linux 系统删除的，一旦这些文件丢失，就无法再通过 supervisorctl 来执行 restart 和 stop 命令了，将只会得到 unix:///tmp/supervisor.sock 不存在的错误 。（引用） 12345678910111213141516171819202122232425262728293031323334...unix_http_server];file=/tmp/supervisor.sock ; (the path to the socket file);修改为 /home/supervisor 目录，避免被系统删除file=/home/supervisor/supervisor.sock ; (the path to the socket file)...[supervisord];logfile=/tmp/supervisord.log ; (main log file;default $CWD/supervisord.log);修改为 /var/log 目录，避免被系统删除logfile=/var/log/supervisor/supervisord.log ; (main log file;default $CWD/supervisord.log);日志文件多大时进行分割logfile_maxbytes=50MB ; (max main logfile bytes b4 rotation;default 50MB);最多保留多少份日志文件logfile_backups=10 ; (num of main logfile rotation backups;default 10)loglevel=info ; (log level;default info; others: debug,warn,trace);pidfile=/tmp/supervisord.pid ; (supervisord pidfile;default supervisord.pid);修改为 /home/supervisor 目录，避免被系统删除pidfile=/home/supervisor/supervisord.pid ; (supervisord pidfile;default supervisord.pid)...;设置启动supervisord的用户，一般情况下不要轻易用root用户来启动，除非你真的确定要这么做;user=chrism ; (default is current user, required if root)...[supervisorctl]; 必须和&apos;unix_http_server&apos;里面的设定匹配;serverurl=unix:///tmp/supervisor.sock ; use a unix:// URL for a unix socket;修改为 /home/supervisor 目录，避免被系统删除serverurl=unix:///home/supervisor/supervisor.sock ; use a unix:// URL for a unix socket;serverurl=http://127.0.0.1:9001 ; use an http:// url to specify an inet socket;username=chris ; should be same as http_username if set;password=123 ; should be same as http_password if set... 使用浏览器来管理supervisor 同时提供了通过浏览器来管理进程的方法，只需要注释掉如下几行就可以了。 123456789;[inet_http_server] ; inet (TCP) server disabled by default;port=127.0.0.1:9001 ; (ip_address:port specifier, *:port for ;all iface);username=user ; (default is no username (open server));password=123 ; (default is no password (open server))[supervisorctl]...;serverurl=http://127.0.0.1:9001 ; use an http:// url to specify an inet socket;username=chris ; should be same as http_username if set;password=123 ; should be same as http_password if set 使用 include在配置文件的最后，有一个 [include] 的配置项，跟 Nginx 一样，可以 include 某个文件夹下的所有配置文件，这样我们就可以为每个进程或相关的几个进程的配置单独写成一个文件。 12[include]files = /etc/supervisor.d/*.ini 进程的配置样例123456789101112; 设置进程的名称，使用 supervisorctl 来管理进程时需要使用该进程名[program:your_program_name]command=python server.py --port=9000;numprocs=1 ; 默认为1;process_name=%(program_name)s ; 默认为 %(program_name)s，即 [program:x] 中的 xdirectory=/home/python/tornado_server ; 执行 command 之前，先切换到工作目录user=oxygen ; 使用 oxygen 用户来启动该进程; 程序崩溃时自动重启，重启次数是有限制的，默认为3次autorestart=true redirect_stderr=true ; 重定向输出的日志stdout_logfile = /var/log/supervisor/tornado_server.logloglevel=info 启动 supervisord123456# 使用默认的配置文件 /etc/supervisord.confsupervisord# 明确指定配置文件supervisord -c /etc/supervisord.conf# 使用 user 用户启动 supervisordsupervisord -u user supervisorctl 命令介绍12345678910111213141516# 停止某一个进程，program_name 为 [program:x] 里的 xsupervisorctl stop program_name# 启动某个进程supervisorctl start program_name# 重启某个进程supervisorctl restart program_name# 结束所有属于名为 groupworker 这个分组的进程 (start，restart 同理)supervisorctl stop groupworker:# 结束 groupworker:name1 这个进程 (start，restart 同理)supervisorctl stop groupworker:name1# 停止全部进程，注：start、restart、stop 都不会载入最新的配置文件supervisorctl stop all# 载入最新的配置文件，停止原有进程并按新的配置启动、管理所有进程supervisorctl reload# 根据最新的配置文件，启动新配置或有改动的进程，配置没有改动的进程不会受影响而重启supervisorctl update 更新配置文件12supervisorctl reread (只更新配置文件)supervisorctl update (只启动有改动的进程)]]></content>
      <categories>
        <category>工具集</category>
      </categories>
      <tags>
        <tag>Supervisor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu 指令学习]]></title>
    <url>%2F2018%2F05%2F02%2Fubuntu-code-learning%2F</url>
    <content type="text"><![CDATA[Ubuntu 指令学习显示端口对应的信息12# 显示8081端口信息lsof -i:8081 杀死进程12# 杀死23919进程kill -9 23919 查询信息12# 在进程中查询新信息ps -aux | grep &quot;basic.py&quot; 显示结尾的信息12# 显示信息，并且在之间查询tail -f -n -10000 uwsgi.log | grep &quot;ERROR&quot; 更新信息，升级12345apt-get updateapt-get upgradeapt-get dist-upgrade upgrade:系统将现有的Package升级,如果有相依性的问题,而此相依性需要安装其它新的Package或影响到其它Package的相依性时,此Package就不会被升级,会保留下来. dist-upgrade:可以聪明的解决相依性的问题,如果有相依性问题,需要安装/移除新的Package,就会试着去安装/移除它. (所以通常这个会被认为是有点风险的升级) 查看磁盘空间大小12345678910111213141516171819202122232425262728293031323334# 查看磁盘剩余空间df -hl# 查看每个根路径的分区大小 df -h# 返回该目录的大小du -sh [目录名] # 返回该文件夹总M数du -sm [文件夹] # 查看更多功能df --help # 查看硬盘的分区sudo fdisk -l# 查看IDE硬盘信息 sudo hdparm -i /dev/hda# 查看STAT硬盘信息 sudo hdparm -I /dev/sda sudo apt-get install blktool sudo blktool /dev/sda id# 查看硬盘剩余空间 df -h #df -H# 查看目录占用空间 du -hs 目录名# 优盘没法卸载 sync fuser -km /media/usbdisk ubuntu 终端常用命令ctrl + l - 清屏 ctrl + c - 终止命令 ctrl + d - 退出 shell，好像也可以表示EOF ctrl + z - 将当前进程置于后台，fg还原。 ctrl + r - 从命令历史中找 ctrl + a - 光标移到行首 ctrl + e - 光标移到行尾 ctrl + u - 清除光标到行首的字符 ctrl + w - 清除光标之前一个单词 ctrl + k - 清除光标到行尾的字符 ctrl + t - 交换光标前两个字符 ctrl + y - 粘贴前一ctrl+u类命令删除的字符 ctrl + p - 上一条命令 ctrl + n - 下一条命令 ctrl + v - 输入控制字符 如ctrl+v ,会输入^M ctrl + f - 光标后移一个字符 ctrl + b - 光标前移一个字符 ctrl + h - 删除光标前一个字符]]></content>
      <categories>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的vim配置]]></title>
    <url>%2F2018%2F04%2F13%2Fmyvim%2F</url>
    <content type="text"><![CDATA[在这里保留下自己的vim配置 12345678910111213141516171819202122232425262728293031323334set nusyntax onset nocompatibleset confirmset mouse=aset tabstop=4set shiftwidth=4set expandtabset smarttabset autoindentset smartindentset hlsearchset showmatchset rulerset foldenableset foldmethod=manualautocmd InsertLeave * se noculautocmd InsertEnter * se culif version &gt;= 603 set helplang=cn set encoding=utf-8endif 需要在 vim ~/.vimrc 中配置，配置完成之后需要应用 source ~/.bashrc]]></content>
      <categories>
        <category>vim</category>
      </categories>
      <tags>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学习Django过程中遇到的问题及解决方案]]></title>
    <url>%2F2018%2F04%2F03%2Fproblem-solving%2F</url>
    <content type="text"><![CDATA[​ 在学习过程中，遇到的一些问题和最后找的解决方案，在此记录保存，不定期更新。这其中的问题可能涉及到Django框架的操作，python语言的编写错误，或着uwsgi的一些错误，都在此记录。 UWSGI 出现 “invalid request block size: xxxx (max 4096)”的错误​ 对于uwsgi来说，默认会设置一个比较小的缓存（buffer 4k）来接收来接收每个请求的头信息,如果在日志中看见”invalid request block size”,它意味着你需要一个大一点的buffer。 ​ 简单的来说，就是URL的地址长度超过了4096个字符，而4096就是uwsgi配置中buffer-size的默认值，所以只需要将buffer-size改大一点即可。 可以在命令中加上buffer-size指出需要的大小 1uwsgi -x uwsgi.ini --buffer-size 32768 或者在配置文件中添加buffer-size = 8192 注意：如果你的日志中接收到了请求块大小为‘21573’，那这可能意味着你使用HTTP协议与一个使用uwsgi协议的实例进行通信。 ​ 问题基本解决，至于为什么这个问题是偶尔出现？那是因为openid登陆的时候会携带一个参数叫next_url，这个地址是用来指定登陆成功之后返回到哪里地址，如果这个next_url太长就会导致url地址超过4096，有时候next_url=/，即网站根地址，url地址长度就不会超过4096。另外还和openid返回的登陆人信息长度有关系，导致有些人从来不会出现这个错误，有些人偶尔出现这个问题。 参考：uwsgi部署到nginx出现invalid request block size: 4161 (max 4096) Django 数据库初始化时出现 django.core.exceptions.AppRegistryNotReady: Apps aren’t loaded yet.主要的报错原因是因为在数据库中使用了 12from django.contrib.auth import get_user_modelUser = get_user_model() ​ 来获得当前用户，这个是一个先查询的，就是说系统运行到这的时候，会先去查询这个用户类是否已经加载好，如果没有加载好就会出现这个错误。 目前没有想打一个比较好的办法解决，就初始阶段的解决方法有两个： 适当调整setting.py中INSTALLED_APPS的先后顺序，使得设计的AUTH_USER_MODEL比较先加载。 修改数据库代码，不这样获得用户，而是直接用字符串的方式获得 1from Project.settings import AUTH_USER_MODEL 之后在外键中直接使用 1base_info = models.OneToOneField(AUTH_USER_MODEL) Django中文编码错误问题​ 编码报错UnicodeDecodeError: ‘ascii’ codec can’t decode byte 0xb0 in position 1······ ​ 这类的问题，其中一个原因可能是在对方调用该接口的时候，传递过来的数据编码于本系统的编码格式不一致问题，在商量好双方的接口编码规则之后，可以尝试直接在出错问题的文件中修改系统的默认编码。 12345import sysdefaultencoding = 'utf-8'if sys.getdefaultencoding() != defaultencoding: reload(sys) sys.setdefaultencoding(defaultencoding)]]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WARNING REMOTE HOST IDENTIFICATION HAS CHANGED!]]></title>
    <url>%2F2018%2F03%2F17%2Fssh-remote%2F</url>
    <content type="text"><![CDATA[在SSH连接云主机的时候出现 WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!在我们连接云主机的时候，相关的配置会保存在/Users/apple/.ssh中的known_hosts文件内，如果云主机修改等操作后，就有可能会出现在这个问题。 解决方式很简单，进入到这个文件内，将相关的IP删除，之后在重新连接，即可。 进入到相关文件 1cd ~/.ssh vim 操作 1vim known_hosts 删除对应的行 重新连接 也可以使用ssh-keygen -R &quot;IP&quot;命令，直接删除相关远程连接的云主机IP 不推荐直接删除这个文件 known_hosts是记录远程主机的公钥的文件]]></content>
      <categories>
        <category>ubuntu</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python 虚拟环境]]></title>
    <url>%2F2018%2F03%2F10%2Fpython-vertualenv%2F</url>
    <content type="text"><![CDATA[python 虚拟环境设置virtualenv安装pip install virtualenv 创建虚拟环境virtualenv [新环境名] 使用source ./bin/activate 执行所创建的虚拟环境下的根目录的activate文件 退出deactivate 删除直接删除创建的文件夹就行 virtualenvwrapper安装pip install virtualenvwrapper 配置 创建虚拟环境管理目录: mkdir $HOME/.local/virtualenvs 在~/.bashrc中添加行： 12345678910export VIRTUALENV_USE_DISTRIBUTE=1export WORKON_HOME=$HOME/.local/virtualenvsif [ -e $HOME/.local/bin/virtualenvwrapper.sh ];then source $HOME/.local/bin/virtualenvwrapper.shelse if [ -e /usr/local/bin/virtualenvwrapper.sh ];then source /usr/local/bin/virtualenvwrapper.sh fifiexport PIP_VIRTUALENV_BASE=$WORKON_HOMEexport PIP_RESPECT_VIRTUALENV=true 启动 virtualenvwrapper: source ~/.bashrc 使用 创建虚拟环境 mkvirtualenv [环境名] 也可以在创建的时候加上参数，确定python版本，workon [环境名] --python=python3 删除 rmvirtualenv [环境名] 激活 workon [环境名] 退出 deactivate 列出所有环境 workon 或者 lsvirtualenv -b 查看所有指令virtualenvwrapper —help]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>virtualenv</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django Rest framework 学习笔记 05]]></title>
    <url>%2F2018%2F02%2F23%2Fdjango-rest-vue05%2F</url>
    <content type="text"><![CDATA[分类 view 123456789class CategoryViewset(mixins.ListModelMixin, mixins.RetrieveModelMixin, viewsets.GenericViewSet): """ list: 商品分类列表数据 retrieve: 获取商品分类详情 """ queryset = GoodsCategory.objects.filter(category_type=1) serializer_class = CategorySerializer Serializer 1234class CategorySerializer(serializers.ModelSerializer): class Meta: model = GoodsCategory fields = "__all__" url 12#配置category的urlrouter.register(r'categorys', CategoryViewset, base_name="categorys") 跨域问题django-cors-headers 官网 下载安装1pip install django-cors-headers 配置 INSTALLED_APPS 12345INSTALLED_APPS = ( ... 'corsheaders', ...) middleware 123456MIDDLEWARE = [ # Or MIDDLEWARE_CLASSES on Django &lt; 1.10 ... 'corsheaders.middleware.CorsMiddleware', # 只要添加这个 'django.middleware.common.CommonMiddleware', ...] 要放在CommonMiddleware前面 设置CORS_ORIGIN_ALLOW_ALL 1CORS_ORIGIN_ALLOW_ALL = True 用户登录和注册权限认证（DRF自带的token认证） Authentication setting123456REST_FRAMEWORK = &#123; 'DEFAULT_AUTHENTICATION_CLASSES': ( 'rest_framework.authentication.BasicAuthentication', 'rest_framework.authentication.SessionAuthentication', )&#125; 对应的Authentication也有三种，TokenAuthentication在前后端分离的系统中比较常见 TokenAuthentication 1234INSTALLED_APPS = ( ... 'rest_framework.authtoken') 创建对应的Token1234from rest_framework.authtoken.models import Tokentoken = Token.objects.create(user=...)print token.key 获取token的URL配置1234from rest_framework.authtoken import viewsurlpatterns += [ url(r'^api-token-auth/', views.obtain_auth_token)] 在输入用户名密码后会返回对应的token，用于前端保存使用，并且在提交的时候将这个token附加在httpheader中，确保用户的登录并且用于权限认证 在httpheader中添加token1Authorization: Token 9944b09199c62bcf9418ad846dd0e4bbdfc6ee4b 在setting中配置token的认证方式1234567REST_FRAMEWORK = &#123; 'DEFAULT_AUTHENTICATION_CLASSES': ( 'rest_framework.authentication.BasicAuthentication', 'rest_framework.authentication.SessionAuthentication', 'rest_framework.authentication.TokenAuthentication', )&#125; 将token认证放到view中 将setting中的&#39;rest_framework.authentication.TokenAuthentication&#39;去除 在view中添加认证authentication_classes = (TokenAuthentication, ) 1234567891011from rest_framework.authentication import TokenAuthenticationclass GoodsListViewSet(CacheResponseMixin, mixins.ListModelMixin, mixins.RetrieveModelMixin, viewsets.GenericViewSet): """ 商品列表页 """ queryset = Goods.objects.all() serializer_class = GoodsSerializer pagination_class = GoodsPagination authentication_classes = (TokenAuthentication, ) JWT方式用户认证参考： 什么是 JWT – JSON WEB TOKEN JSON Web Token - 在Web应用间安全地传递信息 前后端分离之JWT用户认证 REST framework JWT Auth 安装1pip install djangorestframework-jwt 支持 Python (2.7, 3.3, 3.4, 3.5) Django (1.8, 1.9, 1.10) Django REST Framework (3.0, 3.1, 3.2, 3.3, 3.4, 3.5) setting12345678910REST_FRAMEWORK = &#123; 'DEFAULT_PERMISSION_CLASSES': ( 'rest_framework.permissions.IsAuthenticated', ), 'DEFAULT_AUTHENTICATION_CLASSES': ( 'rest_framework_jwt.authentication.JSONWebTokenAuthentication', 'rest_framework.authentication.SessionAuthentication', 'rest_framework.authentication.BasicAuthentication', ),&#125; url123456789from rest_framework_jwt.views import obtain_jwt_token#...urlpatterns = [ '', # ... url(r'^api-token-auth/', obtain_jwt_token),] 请求1curl -H "Authorization: JWT &lt;your_token&gt;" http://localhost:8000/protected-url/ 配置12345import datetimeJWT_AUTH = &#123; 'JWT_EXPIRATION_DELTA': datetime.timedelta(days=7), 'JWT_AUTH_HEADER_PREFIX': 'JWT',&#125; 自定义用户认证 setting 123AUTHENTICATION_BACKENDS = ( 'users.views.CustomBackend',) view 中的逻辑 1234567891011121314151617from django.contrib.auth.backends import ModelBackendfrom django.contrib.auth import get_user_modelfrom django.db.models import QUser = get_user_model()class CustomBackend(ModelBackend): """ 自定义用户验证 """ def authenticate(self, username=None, password=None, **kwargs): try: user = User.objects.get(Q(username=username)|Q(mobile=username)) if user.check_password(password): return user except Exception as e: return None 简单的信息发送12345678910111213141516171819202122232425import jsonimport requestsclass YunPian(object): def __init__(self, api_key): self.api_key = api_key self.single_send_url = "******" def send_sms(self, code, mobile): parmas = &#123; "apikey": self.api_key, "mobile": mobile, "text": "&#123;code&#125;。如非本人操作，请忽略本短信".format(code=code) &#125; response = requests.post(self.single_send_url, data=parmas) re_dict = json.loads(response.text) return re_dictif __name__ == "__main__": yun_pian = YunPian("****") yun_pian.send_sms("2017", "****") 可以直接在百度搜索本地ip，就能获得本机对外的ip地址 Serializer信息验证12345678code = serializers.CharField(required=True, write_only=True, max_length=4, min_length=4,label="验证码", error_messages=&#123; "blank": "请输入验证码", "required": "请输入验证码", "max_length": "验证码格式错误", "min_length": "验证码格式错误" &#125;, help_text="验证码") Validators123456from rest_framework.validators import UniqueValidatorslug = SlugField( max_length=100, validators=[UniqueValidator(queryset=BlogPost.objects.all())]) 例子： 1username = serializers.CharField(label="用户名", help_text="用户名", required=True, allow_blank=False, validators=[UniqueValidator(queryset=User.objects.all(), message="用户已经存在")]) 信号量post_save signal123456789from django.conf import settingsfrom django.db.models.signals import post_savefrom django.dispatch import receiverfrom rest_framework.authtoken.models import Token@receiver(post_save, sender=settings.AUTH_USER_MODEL)def create_auth_token(sender, instance=None, created=False, **kwargs): if created: Token.objects.create(user=instance) 例子： 12345678910111213from django.db.models.signals import post_savefrom django.dispatch import receiverfrom rest_framework.authtoken.models import Tokenfrom django.contrib.auth import get_user_modelUser = get_user_model()@receiver(post_save, sender=User)def create_user(sender, instance=None, created=False, **kwargs): if created: password = instance.password instance.set_password(password) instance.save() CurrentUserDefault 获取当前用户 123owner = serializers.HiddenField( default=serializers.CurrentUserDefault()) UniqueTogetherValidator 联合索引 123456789101112131415from rest_framework.validators import UniqueTogetherValidatorclass ExampleSerializer(serializers.Serializer): # ... class Meta: # ToDo items belong to a parent list, and have an ordering defined # by the 'position' field. No two items in a given list may share # the same position. validators = [ UniqueTogetherValidator( queryset=ToDoItem.objects.all(), fields=('list', 'position') message="巴拉巴拉" ) ] 也可以在数据库中添加联合索引 123456789101112131415class UserFav(models.Model): """ 用户收藏 """ user = models.ForeignKey(User, verbose_name="用户") goods = models.ForeignKey(Goods, verbose_name="商品", help_text="商品id") add_time = models.DateTimeField(default=datetime.now, verbose_name=u"添加时间") class Meta: verbose_name = '用户收藏' verbose_name_plural = verbose_name unique_together = ("user", "goods") def __str__(self): return self.user.username 用户权限认证IsAuthenticated123456789101112from rest_framework.permissions import IsAuthenticatedfrom rest_framework.response import Responsefrom rest_framework.views import APIViewclass ExampleView(APIView): permission_classes = (IsAuthenticated,) def get(self, request, format=None): content = &#123; 'status': 'request was permitted' &#125; return Response(content) 自定义权限12345678910111213141516from rest_framework import permissionsclass IsOwnerOrReadOnly(permissions.BasePermission): """ Object-level permission to only allow owners of an object to edit it. Assumes the model instance has an `owner` attribute. """ def has_object_permission(self, request, view, obj): # Read permissions are allowed to any request, # so we'll always allow GET, HEAD or OPTIONS requests. if request.method in permissions.SAFE_METHODS: return True # Instance must have an attribute named `owner`. return obj.owner == request.user view: 12345678class UserFavViewset(mixins.CreateModelMixin, mixins.ListModelMixin, mixins.RetrieveModelMixin, mixins.DestroyModelMixin, viewsets.GenericViewSet): permission_classes = (IsAuthenticated, IsOwnerOrReadOnly) serializer_class = UserFavSerializer def get_queryset(self): return UserFav.objects.filter(user=self.request.user) 缓存DRF增强安装1pip install drf-extensions 在view中添加CacheResponseMixin 12class GoodsListViewSet(CacheResponseMixin, mixins.ListModelMixin, mixins.RetrieveModelMixin, viewsets.GenericViewSet): pass setting的一些配置（过期时间） 123REST_FRAMEWORK_EXTENSIONS = &#123; 'DEFAULT_CACHE_RESPONSE_TIMEOUT': 60 * 15&#125; django redisdjango-redis 中文文档 API限速 Throttling 在setting中配置 12345678910REST_FRAMEWORK = &#123; 'DEFAULT_THROTTLE_CLASSES': ( 'rest_framework.throttling.AnonRateThrottle', 'rest_framework.throttling.UserRateThrottle' ), 'DEFAULT_THROTTLE_RATES': &#123; 'anon': '100/day', 'user': '1000/day' &#125;&#125; 在view中 123456789101112from rest_framework.response import Responsefrom rest_framework.throttling import UserRateThrottlefrom rest_framework.views import APIViewclass ExampleView(APIView): throttle_classes = (UserRateThrottle,) def get(self, request, format=None): content = &#123; 'status': 'request was permitted' &#125; return Response(content) sentry错误日志 sentry sentry github django sentry 1pip install raven --upgrade setting 12345678910INSTALLED_APPS = ( 'raven.contrib.django.raven_compat',)import osimport ravenRAVEN_CONFIG = &#123; 'dsn': 'https://&lt;key&gt;:&lt;secret&gt;@sentry.io/&lt;project&gt;',&#125; celery异步 django通过celery添加异步任务]]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>Django</tag>
        <tag>Django Rest Framework</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django Rest framework 学习笔记 04]]></title>
    <url>%2F2018%2F02%2F20%2Fdjango-rest-vue04%2F</url>
    <content type="text"><![CDATA[使用类继承View的方式写接口导入基础view1from django.views.generic.base import View 在类中继承12class GoodsListView(View): pass 数据字典化的方式（序列化）传统查询-循环-赋值方式12345678910111213json_list = []goods = Goods.objects.all()[:10]for good in goods: json_dict = &#123;&#125; json_dict["name"] = good.name json_dict["category"] = good.category.name json_dict["market_price"] = good.market_price json_dict["add_time"] = good.add_time # 这里会出现错误，报错原因是时间格式不能序列化成json json_list.append(json_dict)from django.http import HttpResponseimport jsonreturn HttpResponse(json.dumps(json_list), content_tyoe="application/json") 使用Django自带的model_to_dict12345678from django.forms.models import model_to_dict for good in goods: json_dict = model_to_dict(good) # 这里也有可能报错，有些字段不能序列化 json_list.append(json_dict)from django.http import HttpResponseimport jsonreturn HttpResponse(json.dumps(json_list), content_tyoe="application/json") 使用serializers12345678import jsonfrom django.core import serializersjson_data = serializers.serialize('json', goods)json_data = json.loads(json_data)from django.http import JsonResponsereturn JsonResponse(json_data, safe=False) Django rest Framework Django REST framework 一些依赖包The following packages are optional: coreapi (1.32.0+) - Schema generation support. Markdown (2.1.0+) - Markdown support for the browsable API. django-filter (1.0.1+) - Filtering support. django-crispy-forms - Improved HTML display for filtering. django-guardian (1.1.1+) - Object level permissions support. 安装12345pip install django-guardianpip install coreapipip install django-filterpip install --upgrade django-crispy-formspip install markdown 注意这些包一定要装，不然后面有些依赖会报错 使用文档（documentation） 在url.py文件中引入 1from rest_framework.documentation import include_docs_urls 导入该url，注意结尾不要有“/” 1234urlpatterns = [ # ... url(r'docs/', include_docs_urls(title="doc")),] 一些初始化setting.py文件12345INSTALLED_APPS = [ # ... 'rest_framework', 'crispy_forms',] url.py文件123urlpatterns = [ url(r'^api-auth/', include('rest_framework.urls', namespace='rest_framework')),] 使用 class-based views（基础的view）使用自己的Serializer（参考） 在对应的app下新建文件，serializers.py 基本内容内容 1234567from rest_framework import serializersclass SnippetSerializer(serializers.Serializer): id = serializers.IntegerField(read_only=True) title = serializers.CharField(required=False, allow_blank=True, max_length=100) code = serializers.CharField(style=&#123;'base_template': 'textarea.html'&#125;) linenos = serializers.BooleanField(required=False) 在view文件中 1234567891011121314from snippets.models import Snippetfrom snippets.serializers import SnippetSerializerfrom rest_framework.views import APIViewfrom rest_framework.response import Responseclass SnippetList(APIView): """ List all snippets, or create a new snippet. """ def get(self, request, format=None): snippets = Snippet.objects.all() serializer = SnippetSerializer(snippets, many=True) return Response(serializer.data) 备用： 123456789STATIC_URL = '/static/'MEDIA_URL = "/media/"STATICFILES_DIRS = ( os.path.join(BASE_DIR, "static"),)MEDIA_ROOT = os.path.join(BASE_DIR, "media") 在setting.py中如果配置了这个媒体路径，Django rest framework 就会在媒体路径之上加上这个路径，这样就能获得图片路径的完整地址 将数据保存到数据库中 在serializers.py文件中，需要保存的字段中，覆写create方法 作为给前端添加数据的一个接口 12345678910111213from rest_framework import serializersfrom snippets.models import Snippetclass SnippetSerializer(serializers.Serializer): id = serializers.IntegerField(read_only=True) title = serializers.CharField(required=False, allow_blank=True, max_length=100) code = serializers.CharField(style=&#123;'base_template': 'textarea.html'&#125;) def create(self, validated_data): """ Create and return a new `Snippet` instance, given the validated data. """ return Snippet.objects.create(**validated_data) 在view中添加一个post方法 1234567891011121314151617181920212223from snippets.models import Snippetfrom snippets.serializers import SnippetSerializerfrom django.http import Http404from rest_framework.views import APIViewfrom rest_framework.response import Responsefrom rest_framework import statusclass SnippetList(APIView): """ List all snippets, or create a new snippet. """ def get(self, request, format=None): snippets = Snippet.objects.all() serializer = SnippetSerializer(snippets, many=True) return Response(serializer.data) def post(self, request, format=None): serializer = SnippetSerializer(data=request.data) if serializer.is_valid(): serializer.save() return Response(serializer.data, status=status.HTTP_201_CREATED) return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST) 使用ModelSerializers 在serializer中 1234567from rest_framework import serializersfrom snippets.models import Snippetclass SnippetSerializer(serializers.ModelSerializer): class Meta: model = Snippet fields = ('id', 'title', 'code', 'linenos', 'language', 'style') 注意：名字要和model中的一致，包括一开始使用的验证，名字也要相同 取出所有字段123class Meta: model = Snippet fields = "__all__" serializers的“外键” 只要在对应的serializers中添加字段覆盖对应的字段就行 1234567891011121314from rest_framework import serializersfrom snippets.models import Snippet, Categoryclass CategorySerializer(serializers.ModelSerializer): class Meta: model = GoodsCategory fields = "__all__"class SnippetSerializer(serializers.ModelSerializer): Category = CategorySerializer() class Meta: model = Snippet fields = ('id', 'title', 'code', 'linenos', 'language', 'style') 使用 mixins 和 GenericAPIViewGenericAPIView这是用的非常多的一个view，也是非常重要的view 1234567891011121314from rest_framework import mixinsfrom rest_framework import genericsclass SnippetList(mixins.ListModelMixin, mixins.CreateModelMixin, generics.GenericAPIView): queryset = Snippet.objects.all() serializer_class = SnippetSerializer def get(self, request, *args, **kwargs): return self.list(request, *args, **kwargs) def post(self, request, *args, **kwargs): return self.create(request, *args, **kwargs) 同样的，在listapiview中也有上面的方法，可以直接继承这个view，减少代码量 1234567from snippets.models import Snippetfrom snippets.serializers import SnippetSerializerfrom rest_framework import genericsclass SnippetList(generics.ListCreateAPIView): queryset = Snippet.objects.all() serializer_class = SnippetSerializer 一共有以下的view可以继承 配置分页在setting中配置123REST_FRAMEWORK = &#123; 'PAGE_SIZE': 10,&#125; 在view中配置这个配置可以自定义自己的分页配置，这样的话就可以不用在setting中配置了，直接在view中配置 12345678910111213141516171819from rest_framework.pagination import PageNumberPaginationfrom rest_framework import genericsfrom .models import Goodsfrom goods.serializers import GoodsSerializerclass GoodsPagination(PageNumberPagination): page_size = 12 page_size_query_param = 'page_size' page_query_param = "page" max_page_size = 100 class GoodsListViewSet(generics.ListAPIView): """ 商品列表页, 分页， 搜索， 过滤， 排序 """ queryset = Goods.objects.all() serializer_class = GoodsSerializer pagination_class = GoodsPagination 使用viewsets1from rest_framework import viewsets 里面的view比较少 GenericViewSet 在view中继承ListModelMixin和GenericViewSet 12345678910from rest_framework import viewsetsfrom rest_framework import mixinsclass GoodsListViewSet(mixins.ListModelMixin, viewsets.GenericViewSet): """ 商品列表页, 分页， 搜索， 过滤， 排序 """ queryset = Goods.objects.all() serializer_class = GoodsSerializer pagination_class = GoodsPagination viewset的url配置方法 在url.py文件中配置url 12345678910from snippets.views import SnippetViewSetsnippet_list = SnippetViewSet.as_view(&#123; 'get': 'list', 'post': 'create'&#125;)urlpatterns = [ url(r'^snippets/$', snippet_list, name='snippet-list'),] 使用Routers 配置URL12345678910111213from django.conf.urls import url, includefrom rest_framework.routers import DefaultRouterfrom snippets import views# Create a router and register our viewsets with it.router = DefaultRouter()router.register(r'snippets', views.SnippetViewSet)router.register(r'users', views.UserViewSet)# The API URLs are now determined automatically by the router.urlpatterns = [ url(r'^', include(router.urls))] 一些view的继承 过滤功能 在view中添加 12345678910class GoodsListViewSet(mixins.ListModelMixin, viewsets.GenericViewSet): """ 商品列表页, 分页， 搜索， 过滤， 排序 """ # queryset = Goods.objects.all() serializer_class = GoodsSerializer pagination_class = GoodsPagination def get_queryset(self): return Goods.object.filter(shop_price__gt=100) FilteringDjangoFilterBackend官方文档 django-filter 步骤 首先安装 1pip install django-filter 将django-filter加到INSTALLED_APPS中 1234INSTALLED_APPS = [ # ... 'django_filters',] 设置个默认值（可以不设置） 123REST_FRAMEWORK = &#123; 'DEFAULT_FILTER_BACKENDS': ('django_filters.rest_framework.DjangoFilterBackend',)&#125; 使用 12345from django_filters.rest_framework import DjangoFilterBackendclass UserListView(generics.ListAPIView): # ... filter_backends = (DjangoFilterBackend,) 如果使用过滤器，就不需要使用get_queryset方法 例子： 123456789101112131415161718192021from rest_framework.pagination import PageNumberPaginationfrom rest_framework import genericsfrom .models import Goodsfrom goods.serializers import GoodsSerializerfrom django_filters.rest_framework import DjangoFilterBackendclass GoodsPagination(PageNumberPagination): page_size = 12 page_size_query_param = 'page_size' page_query_param = "page" max_page_size = 100 class GoodsListViewSet(mixins.ListModelMixin, viewsets.GenericViewSet): """ 商品列表页 """ queryset = Goods.objects.all() serializer_class = GoodsSerializer pagination_class = GoodsPagination filter_backends = (DjangoFilterBackend,) filter_fields = ('name', 'shop_price') 自定义Filters 新建filters.py文件 123456789101112from rest_framework import genericsfrom django_filters import rest_framework as filtersfrom myapp import Productclass ProductFilter(filters.FilterSet): min_price = filters.NumberFilter(name="price", lookup_expr='gte') max_price = filters.NumberFilter(name="price", lookup_expr='lte') class Meta: model = Product fields = ['category', 'in_stock', 'min_price', 'max_price'] 例子： 12345678910111213141516171819202122import django_filtersfrom django.db.models import Qfrom .models import Goodsclass GoodsFilter(django_filters.rest_framework.FilterSet): """ 商品的过滤类 """ pricemin = django_filters.NumberFilter(name='shop_price', help_text="最低价格",lookup_expr='gte') pricemax = django_filters.NumberFilter(name='shop_price', lookup_expr='lte') top_category = django_filters.NumberFilter(method='top_category_filter') def top_category_filter(self, queryset, name, value): return queryset.filter(Q(category_id=value)|Q(category__parent_category_id=value)|Q(category__parent_category__parent_category_id=value)) class Meta: model = Goods fields = ['pricemin', 'pricemax', 'is_hot', 'is_new'] 将view更改 1234567891011# ... class GoodsListViewSet(mixins.ListModelMixin, viewsets.GenericViewSet): """ 商品列表页 """ queryset = Goods.objects.all() serializer_class = GoodsSerializer pagination_class = GoodsPagination filter_backends = (DjangoFilterBackend,) # filter_fields = ('name', 'shop_price') filter_class = GoodsFilter 模糊查询 1name = django_filters.CharFilter(name='name', lookup_expr='icontains') 不加lookup_expr=’icontains’这个字段就是全匹配 SearchFilter12345class UserListView(generics.ListAPIView): queryset = User.objects.all() serializer_class = UserSerializer filter_backends = (filters.SearchFilter,) search_fields = ('username', 'email') 例子：(view.py) 1234567891011121314151617181920212223from rest_framework.pagination import PageNumberPaginationfrom rest_framework import genericsfrom .models import Goodsfrom goods.serializers import GoodsSerializerfrom django_filters.rest_framework import DjangoFilterBackendfrom rest_framework import filtersclass GoodsPagination(PageNumberPagination): page_size = 12 page_size_query_param = 'page_size' page_query_param = "page" max_page_size = 100 class GoodsListViewSet(mixins.ListModelMixin, viewsets.GenericViewSet): """ 商品列表页 """ queryset = Goods.objects.all() serializer_class = GoodsSerializer pagination_class = GoodsPagination filter_backends = (DjangoFilterBackend, filters.SearchFilter) filter_class = GoodsFilter search_fields = ('^name', 'goods_brief', 'goods_desc') 在不同字段上使用下面的一些符号可以达到不同的效果 ‘^’ Starts-with search. ‘=’ Exact matches. ‘@’ Full-text search. (Currently only supported Django’s MySQL backend.) ‘$’ Regex search. OrderingFilter12345class UserListView(generics.ListAPIView): queryset = User.objects.all() serializer_class = UserSerializer filter_backends = (filters.OrderingFilter,) ordering_fields = ('username', 'email') 例子： 123456789101112131415161718192021222324from rest_framework.pagination import PageNumberPaginationfrom rest_framework import genericsfrom .models import Goodsfrom goods.serializers import GoodsSerializerfrom django_filters.rest_framework import DjangoFilterBackendfrom rest_framework import filtersclass GoodsPagination(PageNumberPagination): page_size = 12 page_size_query_param = 'page_size' page_query_param = "page" max_page_size = 100 class GoodsListViewSet(mixins.ListModelMixin, viewsets.GenericViewSet): """ 商品列表页 """ queryset = Goods.objects.all() serializer_class = GoodsSerializer pagination_class = GoodsPagination filter_backends = (DjangoFilterBackend, filters.SearchFilter, filters.OrderingFilter) filter_class = GoodsFilter search_fields = ('^name', 'goods_brief', 'goods_desc') ordering_fields = ('sale', 'time') API GuideThe API guide is your complete reference manual to all the functionality provided by REST framework. Requests Responses Views Generic views Viewsets Routers Parsers Renderers Serializers Serializer fields Serializer relations Validators Authentication Permissions Throttling Filtering Pagination Versioning Content negotiation Metadata Schemas Format suffixes Returning URLs Exceptions Status codes Testing Settings]]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>Django</tag>
        <tag>Django Rest Framework</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django Rest framework 学习笔记 03]]></title>
    <url>%2F2018%2F02%2F17%2Fdjango-rest-vue03%2F</url>
    <content type="text"><![CDATA[前后端分离的优缺点优点 pc，app，pad多端适应 SPA开发模式开始流行 前后端开发职责不清 开发效率问题，前后端互相等待 前端一直配合着后端，能力受限 后端开发语言和模版高度耦合，导致开发语言依赖严重 缺点 前后端学习门槛增加 数据依赖导致文档重要性增加 前端工作量加大 SEO的难度加大 后端开发模式迁移增加成本 Restful API restful api目前是前后端分离最佳实践 轻量，直接通过http，不需要额外的协议，post/get/put/delete操作 面向资源，具有解释性 数据描述简单，一般通过json或者xml做数据通信 参考 理解RESTful架构 RESTful API 设计指南 几个概念前端工程化 浅析前端工程化 前端工程化小记 前端优化带来的思考，浅谈前端工程化 数据双向绑定 mvvm vue.js MVC，MVP 和 MVVM 的图示 组件化开发 前端组件化开发 什么叫组件化开发？ vue开发的几个概念webpack 本质上，webpack 是一个现代 JavaScript 应用程序的静态模块打包器(module bundler)。当 webpack 处理应用程序时，它会递归地构建一个依赖关系图(dependency graph)，其中包含应用程序需要的每个模块，然后将所有这些模块打包成一个或多个 bundle。 中文官网 vue，vuex，vue-router，axios vue全家桶 vue.js ES6，babel ES6语法，babel可以将ES6转换成ES5 《ECMAScript 6 入门》]]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django Rest framework 学习笔记 02]]></title>
    <url>%2F2018%2F02%2F16%2Fdjango-rest-vue02%2F</url>
    <content type="text"><![CDATA[参考： Unofficial Windows Binaries for Python Extension Packages Django REST framework 官网 安装进入到虚拟环境 pip install djangorestframework 安装Django，默认安装最新版本 pip install -i https://pypi.douban.com/simple django 安装markdown，Markdown support for the browsable API. pip install markdown 还需要安装 pip install django-filter 使用mysqlsetting.py 文件中修改：1234567891011121314DATABASES = &#123; 'default': &#123; 'ENGINE': 'django.db.backends.mysql', 'NAME': 'teacherAndStudentSystem', 'USER': 'root', 'PASSWORD': '', 'HOST': 'localhost', 'PORT': '3306', 'OPTIONS': &#123; 'charset': 'utf8mb4', 'init_command': 'SET default_storage_engine=INNODB;' &#125;, &#125;&#125; 在 MySQLWorkbench 中新建数据库 安装python的mysql驱动pip install mysqlclient 运行发现报错 “django.db.utils.OperationalError: (1193, “Unknown system variable ‘storage_engine’”)” 参考： 博客园 stackoverflow 因为版本的关系，所以只需要改为 SET default_storage_engine=INNODB; 即可 这个表示选择另一种连接方式，后面使用第三方登录的时候要用上 安装 pillowpip install pillow 这个是图形第三方插件 创建apps的package注意需要创建的是Python Package，而不是Directory 修改setting将apps加入到python的根搜索路径下 12345678import osimport sys# Build paths inside the project like this: os.path.join(BASE_DIR, ...)BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))sys.path.insert(0, BASE_DIR)sys.path.insert(0, os.path.join(BASE_DIR, 'apps'))sys.path.insert(0, os.path.join(BASE_DIR, 'extra_apps')) 目前项目目录： vue项目安装需要的包在vue项目的根目录下执行 cnpm install 或 npm install 会生成一个model_modules的文件夹 运行cnpm run dev 或使用 npm run dev 设计app和models富文本编辑器Django-UEditor 参考 Django集成百度富文本编辑器uEditor 对应代码应用 把这第三方包复制到项目中 在setting中设置，加入改包 123456789INSTALLED_APPS = [ 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'users.apps.UsersConfig', 'DjangoUeditor',] 在模型类中导入 1from DjangoUeditor.models import UEditorField 模型中使用 12345678goods_desc = UEditorField( verbose_name=u"内容", imagePath="goods/images/", width=1000, height=300, filePath="goods/files/", default='') 模型类例子在线购物平台的商品模型 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142from datetime import datetimefrom django.db import modelsfrom DjangoUeditor.models import UEditorField# Create your models here.class GoodsCategory(models.Model): """ 商品类别 """ CATEGORY_TYPE = ( (1, "一级类目"), (2, "二级类目"), (3, "三级类目"), ) name = models.CharField(default="", max_length=30, verbose_name="类别名", help_text="类别名") code = models.CharField(default="", max_length=30, verbose_name="类别code", help_text="类别code") desc = models.TextField(default="", verbose_name="类别描述", help_text="类别描述") category_type = models.IntegerField(choices=CATEGORY_TYPE, verbose_name="类目级别", help_text="类目级别") parent_category = models.ForeignKey("self", null=True, blank=True, verbose_name="父类目级别", help_text="父目录", related_name="sub_cat") is_tab = models.BooleanField(default=False, verbose_name="是否导航", help_text="是否导航") add_time = models.DateTimeField(default=datetime.now, verbose_name="添加时间") class Meta: verbose_name = "商品类别" verbose_name_plural = verbose_name def __str__(self): return self.nameclass GoodsCategoryBrand(models.Model): """ 品牌名 """ category = models.ForeignKey(GoodsCategory, related_name='brands', null=True, blank=True, verbose_name="商品类目") name = models.CharField(default="", max_length=30, verbose_name="品牌名", help_text="品牌名") desc = models.TextField(default="", max_length=200, verbose_name="品牌描述", help_text="品牌描述") image = models.ImageField(max_length=200, upload_to="brands/") add_time = models.DateTimeField(default=datetime.now, verbose_name="添加时间") class Meta: verbose_name = "品牌" verbose_name_plural = verbose_name db_table = "goods_goodsbrand" def __str__(self): return self.nameclass Goods(models.Model): """ 商品 """ category = models.ForeignKey(GoodsCategory, verbose_name="商品类目") goods_sn = models.CharField(max_length=50, default="", verbose_name="商品唯一货号") name = models.CharField(max_length=100, verbose_name="商品名") click_num = models.IntegerField(default=0, verbose_name="点击数") sold_num = models.IntegerField(default=0, verbose_name="商品销售量") fav_num = models.IntegerField(default=0, verbose_name="收藏数") goods_num = models.IntegerField(default=0, verbose_name="库存数") market_price = models.FloatField(default=0, verbose_name="市场价格") shop_price = models.FloatField(default=0, verbose_name="本店价格") goods_brief = models.TextField(max_length=500, verbose_name="商品简短描述") goods_desc = UEditorField(verbose_name=u"内容", imagePath="goods/images/", width=1000, height=300, filePath="goods/files/", default='') ship_free = models.BooleanField(default=True, verbose_name="是否承担运费") goods_front_image = models.ImageField(upload_to="goods/images/", null=True, blank=True, verbose_name="封面图") is_new = models.BooleanField(default=False, verbose_name="是否新品") is_hot = models.BooleanField(default=False, verbose_name="是否热销") add_time = models.DateTimeField(default=datetime.now, verbose_name="添加时间") class Meta: verbose_name = '商品' verbose_name_plural = verbose_name def __str__(self): return self.nameclass IndexAd(models.Model): category = models.ForeignKey(GoodsCategory, related_name='category',verbose_name="商品类目") goods =models.ForeignKey(Goods, related_name='goods') class Meta: verbose_name = '首页商品类别广告' verbose_name_plural = verbose_name def __str__(self): return self.goods.nameclass GoodsImage(models.Model): """ 商品轮播图 """ goods = models.ForeignKey(Goods, verbose_name="商品", related_name="images") image = models.ImageField(upload_to="", verbose_name="图片", null=True, blank=True) add_time = models.DateTimeField(default=datetime.now, verbose_name="添加时间") class Meta: verbose_name = '商品图片' verbose_name_plural = verbose_name def __str__(self): return self.goods.nameclass Banner(models.Model): """ 轮播的商品 """ goods = models.ForeignKey(Goods, verbose_name="商品") image = models.ImageField(upload_to='banner', verbose_name="轮播图片") index = models.IntegerField(default=0, verbose_name="轮播顺序") add_time = models.DateTimeField(default=datetime.now, verbose_name="添加时间") class Meta: verbose_name = '轮播商品' verbose_name_plural = verbose_name def __str__(self): return self.goods.nameclass HotSearchWords(models.Model): """ 热搜词 """ keywords = models.CharField(default="", max_length=20, verbose_name="热搜词") index = models.IntegerField(default=0, verbose_name="排序") add_time = models.DateTimeField(default=datetime.now, verbose_name="添加时间") class Meta: verbose_name = '热搜词' verbose_name_plural = verbose_name def __str__(self): return self.keywords 自定义User类 在模型类中导入 1from django.contrib.auth.models import AbstractUser 继承该AbstractUser类 12class UserProfile(AbstractUser): pass 引用外键 在另一个模型类中导入 1from django.contrib.auth import get_user_model 在外键中使用 1234567User = get_user_model()class ShoppingCart(models.Model): """ 购物车 """ user = models.ForeignKey(User, verbose_name=u"用户") 独立使用Django的model进行一些初始化123456789import sysimport ospwd = os.path.dirname(os.path.realpath(__file__))sys.path.append(pwd+"../")os.environ.setdefault("DJANGO_SETTINGS_MODULE", "Project.settings")import djangodjango.setup() 调用123from goods.models import GoodsCategoryall_categorys = GoodsCategory.objects.all() 顺序不能错 让Django识别媒体文件在settings.py中设置12MEDIA_URL = "/media/"MEDIA_ROOT = os.path.join(BASE_DIR, "media") 在urls.py中配置1234567from Project.settings import MEDIA_ROOTfrom django.views.static import serveurlpatterns = [ # ...more url(r'^media/(?P&lt;path&gt;.*)$', serve, &#123;"document_root": MEDIA_ROOT&#125;),] 目前项目目录]]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django Rest framework 学习笔记 01]]></title>
    <url>%2F2018%2F02%2F14%2Fdjango-rest-vue01%2F</url>
    <content type="text"><![CDATA[需要下载的资源 Pycharm WebStorm Node.js Mysql Workbench Pycharm 快捷启动（Linux） vim ~/.bashrc alias pycharm=&quot;bash /hom/bobby/Downloads/pycharm-2016.3.2/bin/pycharm.sh&quot; source ~/.bashrc pycharm Mysql 管理工具 Navicat Mysql Workbench Mysql 安装（Linux）获取安装包sudo apt-get install mysql-server 查看mysql的状态ps aux|grep mysqld 看是否有启动成功，并且可以查看端口地址 进入mysql shell中mysql -uroot -p 之后输入登录密码 mysql shell 的一些操作显示数据库show databases; 退出exit; 配置mysqlvim /etc/mysql/mysql.conf.d/mysqld.cnf 修改其中的 bind-address 配置，将IP改为0.0.0.0 重启mysqlsudo service mysql restart 修改用户权限GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;%&#39; IDENTIFIED BY &#39;root&#39; WITH GRANT OPTION; 刷新用户权限 flush privileges; 字符集及排序规则 使用 utf8 -- UTF-8 Unicode 以及 utf8_general_ci 安装python（Linux） 安装的时候可以使用 python 豆瓣镜像 -i https://pypi.douban.com/simple 获取python3版本sudo apt-get install python3.5 虚拟环境安装sudo apt-get install python-virtualenv 使用虚拟环境virtualenv py2_env 会创建目录为py2_env的文件夹在该目录下 ps: 移除文件夹 rm -r py2_env/或 rm -f py2_env移除文件，慎用rm -rf py2_env 进入虚拟环境source py2_env/bin/activate 退出虚拟环境deactivate 创建python3的虚拟环境virtualenv -p python3 py3_env 安装pip3版本sudo apt-get install python3-pip 遇到 “OSError: Command /home/ubuntu/Myvirtualenv/py2_env/bin/python2 - setuptools pkg_resources pip wheel failed with error code 1”这个问题，解决方法： export LC_ALL=&quot;en_US.UTF-8&quot; export LC_CTYPE=&quot;en_US.UTF-8&quot; pip install setuptools 参考： setuptools pkg_resources pip wheel failed with error code 1 更新pip版本pip install --upgrade pip 虚拟环境管理安装pip install virtualenvwrapper 查找路径sudo find / -name virtualenvwrapper.sh /home/ubuntu/.local/bin/virtualenvwrapper.sh 配置 进入vim ~/.bashrc 在最后一行添加 export WORKON_HOME=$HOME/.virtualenvssource /home/ubuntu/.local/bin/virtualenvwrapper.sh ESC :wq保存 source ~/.bashrc 运行生效 创建虚拟环境mkvirtualenv py2_workon_env 目录安装所在地cd ~/.virtualenvs 使用 workon 查找全部的虚拟目录 workon py2_workon_env 使用该虚拟目录 deactivate 退出虚拟环境 创建python3的虚拟环境mkvirtualenv --python=python3 py3_workon_env ubuntu@VM-65-204-ubuntu:~$ workonpy2_workon_envpy3_workon_env 安装 Node.js参考： https://nodejs.org/dist/v8.9.3/ nodejs download Linux（Ubuntu）下安装NodeJs linux下安装nodejs+express(最新版) Linux下nodejs的安装配置 安装依赖包 sudo apt-get install g++ sudo apt-get install libssl-dev sudo apt-get install build-essential 下载压缩包wget https://nodejs.org/dist/v8.9.3/node-v8.9.3.tar.gz 解压tar zxvf node-v8.9.3.tar.gz 移动文件 mv source_file new_file 编译文件 进入到node-v8.9.3文件里 ./configure make 安装make install 修改环境配置参考 尝试 sudo apt-get install nodejs-legacy sudo apt-get install npm cnpm 淘宝 NPM 镜像 可以使用这个代替npm，国内镜像，下载速度可以更快 安装htopsudo apt-get install htop 可以查看系统运行的状态]]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Httpie]]></title>
    <url>%2F2018%2F02%2F08%2Fhttpie%2F</url>
    <content type="text"><![CDATA[关于 HTTPie （读aych-tee-tee-pie）是一个 HTTP 的命令行客户端。 其目标是让 CLI 和 web 服务之间的交互尽可能的人性化。 这个工具提供了简洁的 http 命令，允许通过自然的语法发送任意 HTTP 请求数据，展示色彩化的输出。 HTTPie 可用于与 HTTP 服务器做测试、调试和常规交互。 特点 直观的语法 格式化和色彩化的终端输出 内置 JSON 支持 支持上传表单和文件 HTTPS、代理和认证 任意请求数据 自定义头部 持久性会话 类 Wget 下载 支持 Python 2.6, 2.7 和 3.x 支持 Linux, Mac OS X 和 Windows 插件 文档 测试覆盖率 安装pip install httpie 参考 HTTPie 工具使用入门 官方文档]]></content>
      <categories>
        <category>工具集</category>
      </categories>
      <tags>
        <tag>httpie</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Byobu "多窗口"的Terminal]]></title>
    <url>%2F2018%2F02%2F07%2Fbyobu%2F</url>
    <content type="text"><![CDATA[测试密码工具，密码是： lim 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]]></content>
      <categories>
        <category>工具集</category>
      </categories>
      <tags>
        <tag>byobu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django 学习笔记—基础01]]></title>
    <url>%2F2018%2F01%2F27%2FDjangoLearning1%2F</url>
    <content type="text"><![CDATA[参考 Django 1.8.2中文文档 Django 2.0 官方文档 Django 中文教学 自强学院 所需指令用指令创建项目django-admin startproject project 一般不用，直接用pycharm创建就行 运行应用python manage.py runserver 8080 运行后，才能根据所生成的网址，访问服务器，后面填写服务器的端口 也可以不写端口，如果没写端口，默认使用8000端口 创建一个应用python manage.py startapp djangoAppName(这里填写所需创建应用的名字)或django-admin startapp djangoAppName可以直接在apps目录下创建 有点类似于模块的意思，分模块开发项目，一个模块对应了view, model等内容，需要创建新的模块的时候，需要使用这个指令。 生成迁移（makemigrations）创建迁移文件 python manage.py makemigrations 创建之后，在所对应的migrations文件夹下面会多出一个.py文件 如果使用的是Django2.0 并且数据库model中使用了ForeignKey，需要在后面添加 on_delete 关键字 在使用这个命令的时候，需要在settings.py文件中的INSTALLED_APPS注册应用信息 执行迁移根据迁移文件，形成sql语句，创建对应的表 python manage.py migrate 创建超级管理员python manage.py createsuperuser 接下来按照提示填写用户名、邮箱、密码 后台URL: 在网址后面添加admin 显示所有的指令python manage.py 会显示所有的指令，并且在后面输入help name就可以查看对应指令的具体信息 Model创建 在对应的模版项目下的models.py文件下创建数据库模型文件 创建模型的时候不用创建主键id，系统会自动生成这个主键的列 Models.py1234567891011121314151617181920212223242526272829303132333435from django.db import modelsclass ModelName1(models.Model): title = models.CharField(max_length=20) date = models.DateTimeField() def __repr__(self): return 'title name is &#123;&#125;, crate at &#123;&#125;'.format(self.title, self.date) def __str__(self): return self.titleclass ModelName2(models.Model): hname = models.CharField(max_length=10) hgender = models.BooleanField() content = models.CharField(max_length=1000) modelName1ForeignKey = models.ForeignKey(ModelName1, on_delete=models.CASCADE) #外键 def __str__(self): return self.name def gender(self): if self.hgender: return '男' else: return '女' gender.short_description = '性别' def name(self): return self.hname name.short_description = '名字' Django2.0 ForeignKey 变化在创建外键的时候遇到报错： TypeError: __init__() missing 1 required positional argument: &#39;on_delete&#39; 查询一番后发现Django2.0版本创建外键时需要在后面加上on_delete 12345class Car(models.Model): manufacturer = models.ForeignKey( 'Manufacturer', on_delete=models.CASCADE, ) 站点管理界面本地化修改settings.py 12LANGUAGE_CODE = 'zh-Hans'TIME_ZONE = 'Asia/Shanghai' 修改语言和时区 向admin中注册应用在 booktest/admin.py 文件，注册模型 123from django.contrib import adminfrom models import ModelNameadmin.site.register(ModelName) 导入model 类 在admin中注册该模型类 admin.site.register(ModelName) 自定义管理页面 Django提供了admin.ModelAdmin类 通过定义ModelAdmin的子类，来定义模型在Admin界面的显示方式 1234567891011class ModelNameAdmin(admin.ModelAdmin): list_display = ['id', 'title', 'date'] list_filter = ['title'] search_fields = ['title'] list_per_page = 10 fieldsets = [ ('base',&#123;'fields':['title']&#125;), ('super',&#123;'fields':['date']&#125;) ]admin.site.register(BookInfo, BookInfoAdmin) 列表页属性list_display 显示字段，可以点击列头进行排序 1list_display = ['pk', 'title', 'date'] 列表里面填写的是字段的列表名字，表示要在后台页面中显示什么列表字段，先后顺序决定显示顺序 list_filter 过滤字段，过滤框会出现在右侧 1list_filter = ['title'] search_fields 搜索字段，搜索框会出现在上侧 1search_fields = ['title'] 支持模糊查询，根据列表中的字段进行查询 list_per_page 分页，分页框会出现在下侧 1list_per_page = 10 添加、修改页属性fields 属性的先后顺序 1fields = ['date', 'title'] fieldsets 属性分组 1234fieldsets = [ ('basic',&#123;'fields': ['title']&#125;), ('more', &#123;'fields': ['date']&#125;),] 关联对象 对于模型类，有两种注册方式 方式一：与传统模型类相同 方式二：关联注册 按照BookInfor的注册方式完成HeroInfo的注册 接下来实现关联注册 12345678910111213141516171819202122232425262728from django.contrib import adminfrom .models import *# StackedInline TabularInlineclass ModelName2Line(admin.TabularInline): model = HeroInfo extra = 1class ModelName1Admin(admin.ModelAdmin): list_display = ['id', 'title', 'date'] list_filter = ['title'] search_fields = ['title'] list_per_page = 10 fieldsets = [ ('base', &#123;'fields': ['title']&#125;), ('super', &#123;'fields': ['date']&#125;) ] inlines = [ModelName2Line]class ModelName2Admin(admin.ModelAdmin): list_display = ['id', 'name', 'gender', 'content', 'modelName1ForeignKey'] list_filter = ['hgender']admin.site.register(ModelName1, ModelName1Admin)admin.site.register(ModelName2, ModelName2Admin) 可以将内嵌的方式改为表格 1class ModelName2Line(admin.TabularInline) 布尔值的显示 发布性别的显示不是一个直观的结果，可以使用方法进行封装 123456def gender(self): if self.hgender: return '男' else: return '女'gender.short_description = '性别' 在admin注册中使用gender代替hgender 12class ModelName2Admin(admin.ModelAdmin): list_display = ['id', 'name', 'gender', 'content'] 视图 在django中，视图对WEB请求进行回应 视图接收reqeust对象作为第一个参数，包含了请求的信息 视图就是一个Python函数，被定义在views.py中 123456from django.http import HttpResponsedef index(request): return HttpResponse("index")def detail(request,id): return HttpResponse("detail %s" % id) 定义完成视图后，需要配置urls.py，否则无法处理请求 urls.py12345678from django.contrib import adminfrom django.urls import pathfrom DjangoLearn1 import viewsurlpatterns = [ path('admin/', admin.site.urls), path('',views.index)] 此时，就可以访问了，不过考虑到如果这样填写，模块一多，URL的量一大的话，就会出现多个路由，不方便配置，所以推荐如下 在对应模块里面创建一个 urls.py 的文件，将路由信息写到里面 1234567from django.urls import pathfrom . import viewsurlpatterns = [ path('', views.index, name='index'),] 之后，在向主urls.py文件中include进去 1234567from django.urls import include, pathfrom django.contrib import adminurlpatterns = [ path('', include('DjangoLearn1.urls')), path('admin/', admin.site.urls),] 模板 模板是html页面，可以根据视图中传递的数据填充值 在模板中访问视图传递的数据 12&#123;&#123; 输出值，可以是变量，也可以是对象.属性 &#125;&#125;&#123;% 执行代码段 %&#125; 定义HTML模板123456789101112131415161718&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;首页&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;列表&lt;/h1&gt;&lt;ul&gt;&#123;%for ModeleName1 in ModeleName1List%&#125;&lt;li&gt; &lt;a href="&#123;&#123;ModeleName1.id&#125;&#125;"&gt; &#123;&#123;ModeleName1.title&#125;&#125; &lt;/a&gt;&lt;/li&gt;&#123;%endfor%&#125;&lt;/ul&gt;&lt;/body&gt;&lt;/html&gt; 在模板中访问对象成员时，都以属性的方式访问，即方法也不能加括号 1234567891011121314&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;详细&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;&#123;&#123;ModeleName1.title&#125;&#125;&lt;/h1&gt;&lt;ul&gt; &#123;%for Modele in ModeleName1.ModelName2_set.all%&#125; &lt;li&gt;&#123;&#123;Modele.name&#125;&#125;---&#123;&#123;Modele.content&#125;&#125;&lt;/li&gt; &#123;%endfor%&#125;&lt;/ul&gt;&lt;/body&gt;&lt;/html&gt; 使用模板 编辑views.py文件，在方法中调用模板 Django提供了函数Render()简化视图调用模板、构造上下文 1234567891011from django.shortcuts import renderfrom models import ModeleName1def index(reqeust): ModeleName1List = ModeleName1.objects.all() return render(reqeust, 'booktest/index.html', &#123;'ModeleName1List': ModeleName1List&#125;)def detail(reqeust, id): ModeleName1 = ModeleName1.objects.get(pk=id) return render(reqeust, 'booktest/detail.html', &#123;'ModeleName1': ModeleName1&#125;) 总结 视图 Views： 接受请求，逻辑处理，调用数据，输出响应 配置ulr在自己的应用中匹配url 模型Model：负责与数据库交互 面向对象：模型对象，列表 定义模型类：指出属性及类型，以确定表的结构，迁移 后台管理：创建管理员，启动服务器，admin，注册admin.py 模版：定义显示的样子 加载：读取文件内容到内存 渲染：填内容]]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo + nexT 学习笔记]]></title>
    <url>%2F2017%2F12%2F30%2FHexoLearn-re%2F</url>
    <content type="text"><![CDATA[前言 本文内容主要是个人在学习hexo和next中所遇到的一些“坑”和解决方法,而详细的流程网上有很多，在文章的结尾我会贴出我在学习中查找到的比较好的文章。 注意本文不是详细操作步骤，如果需要详细步骤，请直接翻到文章结尾。 官方文档 Hexo nexT Hexo 和 nexT 的安装 在安装 Hexo 之前，需要确保电脑环境要有 Node.js 和 Git 环境, 当然，为了更好的安装 Hexo 还需要 npm. 下面是我所使用的版本： 安装之后，最常使用的指令如下： 生成静态页面 1hexo g 在本地运行 1hexo s 部署到GitHub pages（coding） 1hexo d 清除生成的静态文件 1hexo clean 打开 GitHub Pages在第一次创建完仓库之后，打开settings选项，向下翻到GitHub Pages选项会发现不能打开，会有一个提示信息： GitHub Pages is currently disabled. You must first add content to your repository before you can publish a GitHub Pages site 是因为该GitHub Pages没有内容，此时只要点击下面的Choose a theme按钮选择一个主题就可以打开和访问了。 SSH 配置 先查看本机用户home目录下是否存在.ssh目录 1cd ~/.ssh 如果有就不用再创建了，如果想重新创建，可以创建一个不同名字的，也可以将原来的删除，再创建。 使用下面指令删除已存在的SSH： 12ssh-add -Drm -r ~/.ssh 再创建新的SSH密钥(keys) 1$ssh-keygen -t rsa -C &quot;your_email@example.com&quot; 这将按照你提供的邮箱地址，创建一对密钥 将生成的id_rsa.pub文件里面的内容拷贝到GitHub 项目中添加公钥，这里推荐在对应 xxx.github.io 项目中加。（settings-&gt;deploy keys） 最后再用下面指令测试是否连接成功 1ssh -T git@github.com 可参考github提示Permission denied (publickey)，如何才能解决？ 同步到GitHub 配置站点文件下的_config.xml文件下的deploy信息。 安装hexo-deployer-git插件 1npm install hexo-deployer-git --save 关于 https 的问题，如果需要使用自己的域名的话，GitHub pages 是不能打开 Enforce HTTPS 的。所以在配置deploy信息的时候就推荐使用 Clone with SSH 的链接。 绑定域名 在source文件夹下面创建CNAME文件（没有后缀），里面填上自己的域名。 之后在自己的域名商将自己的域名用CNAME方式指向自己GitHub pages的域名。 个人使用的是腾讯云 最后需要注意，需要在站点文件的_config.xml文件配置中的skip_render添加: 12skip_render: - CNAME 表示跳过该文件的渲染。 nexT 主题配置一些我觉得比较实用的效果，参考hexo的next主题个性化配置教程. 添加 README.md在站点文件的source目录下添加一个README.md文件，之后修改站点文件下的_config.xml，将skip_render添加README.md，跳过该文件的渲染。 123skip_render: - CNAME - README.md Schemes个人比较喜欢Gemini样式，相比Pisces样式，该样式不会每篇文章相连过于紧密，会以分块的形式显示出来，比较好看，特别在手机端上效果更显著。具体可以亲自去设置去看看效果。 live2d就是网站右下角的萌物”小人，具体可以参考hexo-helper-live2d。下面简要介绍我的做法： 在站点文件打开终端输入 1npm install --save hexo-helper-live2d 在站点文件下的_config.xml最后配置： 12live2d: model: z16 具体的配置可以看文档，可以修改挺多内容的。模型外观参考截图预览. 动态背景在主题文件的_config.xml中搜索Canvas-nest可以发现有4个动态背景，可以逐个尝试，也可以同时设置为true，个人只选择了Canvas-nest。 footer可以将网站最下的不想要显示的内容设置为false，在主题文件的_config.xml中搜索footer，我的设置如下： 12345678910111213141516171819footer: # Specify the date when the site was setup. # If not defined, current year will be used. since: 2017 # Icon between year and copyright info. icon: user # If not defined, will be used `author` from Hexo main config. copyright: # ------------------------------------------------------------- # Hexo link (Powered by Hexo). powered: false theme: # Theme &amp; scheme info link (Theme - NexT.scheme). enable: false # Version info of NexT after scheme info (vX.X.X). version: false busuanzi访问人数在主题文件的_config.xml中搜索busuanzi_count，修改配置，可以在网站底部和文章中显示访问的人数，我的配置如下： 123456789101112131415busuanzi_count: # count values only if the other configs are false enable: true # custom uv span for the whole site site_uv: true site_uv_header: &lt;i class=&quot;fa fa-user&quot;&gt;&lt;/i&gt; 访问人数 site_uv_footer: | # custom pv span for the whole site site_pv: true site_pv_header: &lt;i class=&quot;fa fa-eye&quot;&gt;&lt;/i&gt; 访问总量 site_pv_footer: # custom pv span for one page only page_pv: true page_pv_header: &lt;i class=&quot;fa fa-file-o&quot;&gt;&lt;/i&gt; 阅读次数 page_pv_footer: 显示统计字数在主题文件的_config.xml中搜索post_wordcount，修改配置，可以在网站底部和文章中显示所统计的字数，我的配置如下： 123456post_wordcount: item_text: true wordcount: true min2read: true totalcount: true separated_meta: true 增加本地搜索功能在主题文件的_config.xml中搜索local_search，设置为true。 参考： Hexo博客无法搜索的终极解决方法 在文章底部增加版权信息在主题文件的_config.xml中搜索post_copyright，设置为true。 给文章加密参考： hexo-blog-encrypt 安装： npm install hexo-blog-encrypt 首先在 _config.yml 中启用该插件 123# Securityencrypt: enable: true 在你的文章的头部添加上对应的字段，如 password, abstract, message 123456789---title: hello worlddate: 2016-03-30 21:18:02tags: - fdsafsdafpassword: Mikeabstract: Welcome to my blog, enter password to read.message: Welcome to my blog, enter password to read.--- 写文章一般使用 1hexo new xxx xxx表示文件的名字，同时也会自动设置为文章标题（后面可改）以之间创建.md文件，添加文章头信息 1234567title: // 文章标题date: // 创建时间updated: //跟新文章的时间tags: // 文章的标签，如果有多个，[tags1, tags2, ...]categories: // 文章分类keywords: // 文章关键词，如果有多个，[key1, key2, ...]description: //文章描述 其中需要注意： 如果想要有updated，需要在主题文件下的_config.xml文件中配置post_meta，将updated_at设置为true。 12345post_meta: item_text: true created_at: true updated_at: true categories: true keywords和description的作用是为了搜索引擎寻找关键字。 其中description关键字，在主页上显示的时候就会显示这里面的内容，而不是显示前150个字符。还有另一种方法推荐，就是不写description，而是在文章中插入&lt;!-- more --&gt;注释，这样主页就会显示该注释前的内容。 可添加内容下面的内容是推广和维护网站相关。 网站分析个人使用的是腾讯移动分析，而且nexT也可以直接支持，在主题文件的_config.xml中搜索Tencent MTA ID，将自己在网站上注册的 ID 填写上去就可以统计了。 seo推广这里推荐参考Hexo+nexT主题搭建个人博客中seo推广部分。 参考百度搜索资源平台 推荐阅读 Hexo+nexT主题搭建个人博客 hexo初探—让写作飞起来 史上最详细的Hexo博客搭建图文教程 Hexo + GitHub (Coding) Pages 搭建博客 基于 Hexo 和 GitHub Pages 搭建博客 Hexo搭建独立博客，托管到Github和Coding上教程 让更多人看到你的博客 在github上搭建个人网站 如何解决百度爬虫无法爬取搭建在Github上的个人博客的问题？ Hexo+Next主题集成Algolia搜索]]></content>
      <categories>
        <category>博客技术</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[今天算是把我的博客网站建立起来了]]></title>
    <url>%2F2017%2F12%2F27%2Fhellomyblog%2F</url>
    <content type="text"><![CDATA[花了三天时间，终于搞定了，这也表示我的文章之旅要开始了。enjoy it !]]></content>
      <categories>
        <category>diary</category>
      </categories>
      <tags>
        <tag>diary</tag>
      </tags>
  </entry>
</search>
